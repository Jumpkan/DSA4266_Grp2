{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "2024-04-10 13:08:13.460059: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-04-10 13:08:14.627862: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from functions import *\n",
    "# import wordninja\n",
    "import requests\n",
    "import random\n",
    "import pandas as pd\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Torch cannot work properly in jupyter notebook\n",
    "# import os\n",
    "# count = 0 \n",
    "# if count == 0:\n",
    "#     os.chdir(\"test_dir\")\n",
    "#     count += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/root/DSA4266_Grp2'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.read_pickle(DF_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "## CONFIG\n",
    "\n",
    "DF_PATH = \"Data/full_df_2.pkl\"\n",
    "X_NAME = 'clean_msg'\n",
    "Y_NAME = 'class'\n",
    "EMBEDDINGS_FOLDER = 'embeddings_2'\n",
    "\n",
    "#### For preprocessing\n",
    "MAXLEN_PER_SENT = 150\n",
    "ALL_TOKEN_MAX_WORDS = 5000\n",
    "INPUT_LENGTH = 150\n",
    "UNDERSAMPLE = True\n",
    "EPOCHS = 3\n",
    "BATCH_SIZE = 125\n",
    "NUM_CLASSES = 2\n",
    "HIDDEN_SIZE = 75\n",
    "LEARNING_RATE = 0.001\n",
    "VERBOSE = True\n",
    "NUM_LAYERS = 1\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "DEVICE = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "print(DEVICE)\n",
    "torch.manual_seed(13)\n",
    "torch.set_default_device(DEVICE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Semantic Dictionaries\n",
    "\n",
    "def get_synonyms_conceptnet(word):\n",
    "    synonyms = []\n",
    "    url = f'http://api.conceptnet.io/c/en/{word}?filter=/c/en'\n",
    "    response = requests.get(url)\n",
    "    data = response.json()\n",
    "    for edge in data['edges']:\n",
    "        if edge['rel']['label'] == 'Synonym' and edge['start']['language'] == 'en' and edge['end']['language'] == 'en':\n",
    "            start = edge['start']['label']\n",
    "            end = edge['end']['label']\n",
    "            synonyms.append(end if start == word else start)\n",
    "\n",
    "    if synonyms != []:\n",
    "        synonym = random.choice(synonyms)\n",
    "    else:\n",
    "        synonym = synonyms\n",
    "    return synonym\n",
    "\n",
    "def get_synonyms_wordnet(word):\n",
    "    synonyms = []\n",
    "    synsets = wordnet.synsets(word)\n",
    "    for synset in synsets:\n",
    "        synonyms.extend([lemma.name() for lemma in synset.lemmas() if lemma.name() != word])\n",
    "\n",
    "    if synonyms != []:\n",
    "        synonym = random.choice(synonyms)\n",
    "    else:\n",
    "        synonym = synonyms\n",
    "    return synonym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataPrep():\n",
    "    def __init__(self, subset = None, text_prep = 'lem', token_max_words = ALL_TOKEN_MAX_WORDS, maxlen_per_sent = MAXLEN_PER_SENT, undersample = UNDERSAMPLE):\n",
    "        \"\"\"\n",
    "        subset: X[:subset]\n",
    "        \"\"\"\n",
    "        self.df = pd.read_pickle(DF_PATH)\n",
    "        self.subset = subset\n",
    "        self.maxlen_per_sent = maxlen_per_sent\n",
    "\n",
    "\n",
    "        self.remove_duplicates()\n",
    "        print('Dupes removed')\n",
    "        self.X = self.df[X_NAME]\n",
    "        self.y = self.df[Y_NAME].apply(lambda x: 1 if x == 'spam' else 0)\n",
    "        self.token_max_words = token_max_words\n",
    "\n",
    "        if self.subset:\n",
    "            self.X = self.X[:self.subset]\n",
    "            self.y = self.y[:self.subset]\n",
    "        \n",
    "        print('Tokenizing..')\n",
    "        self.tokenize()\n",
    "        print('Finished Tokenizing')\n",
    "\n",
    "        print('Initialising word2vec')\n",
    "        self.word_to_vec_map = self.word2vec()\n",
    "\n",
    "        print('lemm/stemm')\n",
    "        if text_prep == 'lem':\n",
    "            self.X = self.lemming()\n",
    "        if text_prep == 'stem':\n",
    "            self.X = self.stemming()\n",
    "\n",
    "        print('Embedding...')\n",
    "        self.pre_embed()\n",
    "        path = f'{EMBEDDINGS_FOLDER}/emb_matrix_x{self.subset}_tok_{self.maxlen_per_sent}_len{self.token_max_words}.pkl'\n",
    "        if os.path.exists(path):\n",
    "            self.emb_matrix = pd.read_pickle(path)\n",
    "        else:\n",
    "            self.emb_matrix = self.tok_embedding_mat(alternative = [get_synonyms_conceptnet, get_synonyms_wordnet])\n",
    "            print('Finished embedding')\n",
    "\n",
    "        print('Padding')\n",
    "        X_pad = self.pad()\n",
    "        print('Finished padding')\n",
    "\n",
    "        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(X_pad, self.y, test_size=0.20, random_state=42)\n",
    "        self.X_train, self.X_val, self.y_train, self.y_val = train_test_split(self.X_train, self.y_train, test_size = 0.2, random_state=42 )\n",
    "\n",
    "        if undersample:\n",
    "            print('Undersampling..')\n",
    "            print(Counter(self.y_train))\n",
    "            self.X_train, self.y_train = self.undersample()\n",
    "            print(Counter(self.y_train))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def remove_duplicates(self):\n",
    "    \n",
    "        ## First remove all those X values with differing binary y values\n",
    "        occurrences = self.df.groupby([X_NAME, Y_NAME]).size().reset_index(name='count')\n",
    "        duplicates = occurrences[occurrences.duplicated(subset=X_NAME, keep=False)]\n",
    "        for index, row in duplicates.iterrows():\n",
    "            x_value = row[X_NAME]\n",
    "            max_count = occurrences[(occurrences[X_NAME] == x_value)].max()['count']\n",
    "            occurrences.drop(occurrences[(occurrences[X_NAME] == x_value) & (occurrences['count'] != max_count)].index, inplace=True)\n",
    "\n",
    "        ## Remove duplicates\n",
    "        self.df = occurrences.drop_duplicates(subset = X_NAME).reset_index(drop = True)\n",
    "    \n",
    "    def tokenize(self, join = False):\n",
    "        def tokenize_helper(text, join = False):\n",
    "            stop_words = set(stopwords.words('english'))\n",
    "            tokens = word_tokenize(text)\n",
    "            tokens = [word.lower() for word in tokens if word.lower() not in stop_words]\n",
    "\n",
    "            if join:\n",
    "                tokens = ' '.join([''.join(c for c in word if c not in string.punctuation) for word in tokens if word])\n",
    "        \n",
    "            return tokens\n",
    "        \n",
    "        self.X = self.X.apply(lambda x: tokenize_helper(x, join))\n",
    "\n",
    "    ## Embedders\n",
    "        \n",
    "    def word2vec(self):\n",
    "        from gensim.models.word2vec import Word2Vec\n",
    "        import gensim.downloader as api\n",
    "\n",
    "        word_to_vec_map = api.load(\"word2vec-google-news-300\")\n",
    "\n",
    "        return word_to_vec_map\n",
    "    \n",
    "    \n",
    "    ## Stemming/ Lemmetization\n",
    "\n",
    "    def stemming(self):\n",
    "        ps = PorterStemmer()\n",
    "\n",
    "        def stem(row):\n",
    "            print(row)\n",
    "            stemmed = []\n",
    "            for word in row:\n",
    "                stemmed += [ps.stem(word)]\n",
    "            print('STEMMED:', stemmed)\n",
    "\n",
    "            return stemmed\n",
    "\n",
    "        return self.X.apply(stem)\n",
    "    \n",
    "\n",
    "    def lemming(self):\n",
    "\n",
    "        def lem(row):\n",
    "            lemmatizer = WordNetLemmatizer()\n",
    "            lemmed = [lemmatizer.lemmatize(word) for word in row]\n",
    "            # print(row)\n",
    "            # print(lemmed,\"\\n\")\n",
    "            return lemmed\n",
    "\n",
    "        return self.X.apply(lem)\n",
    "    \n",
    "    def pre_embed(self):\n",
    "        self.tokenizer = text.Tokenizer(num_words=self.token_max_words)\n",
    "        self.tokenizer.fit_on_texts(self.X)\n",
    "\n",
    "        self.sequences = self.tokenizer.texts_to_sequences(self.X)\n",
    "\n",
    "        self.word_index = self.tokenizer.word_index\n",
    "        self.vocab_len = len(self.word_index) + 1\n",
    "        self.embed_vector_len = self.word_to_vec_map['moon'].shape[0]\n",
    "    \n",
    "    def tok_embedding_mat(self, alternative):\n",
    "        \"\"\"\n",
    "        embedder: word2vec\n",
    "        alternative: list of callable to find synonyms from, inorder of precedence\n",
    "        \"\"\"\n",
    "        synonyms = {} #Dict to store synonyms\n",
    "\n",
    "        emb_matrix = np.zeros((self.vocab_len, self.embed_vector_len))\n",
    "\n",
    "\n",
    "        for word, index in tqdm.tqdm(self.word_index.items(), total = len(self.word_index)):\n",
    "            try: # Try to find in word2vec\n",
    "                embedding_vector = self.word_to_vec_map[word]\n",
    "                emb_matrix[index-1, :] = embedding_vector\n",
    "            except: # Word2vec dont have, find in own synonym dict\n",
    "                synonym = synonyms.get(word, None) \n",
    "                if (synonym) and (synonym in self.word_to_vec_map.index_to_key):\n",
    "                    emb_matrix[index-1,:] = self.word_to_vec_map[synonym]\n",
    "                else: # If word2vec, own synonym dict dont have, find from dictionaries\n",
    "                    for dictionary in alternative:\n",
    "                        try: \n",
    "                            synonym = dictionary(word)\n",
    "                            if synonym:\n",
    "                                # print(f'Found synonym: {synonym} for word: {word}')\n",
    "                                embedding_vector = self.word_to_vec_map[synonym] \n",
    "                                emb_matrix[index-1, :] = embedding_vector\n",
    "                                synonyms[word] = synonym\n",
    "                        except:\n",
    "                            continue\n",
    "        self.syn = synonyms\n",
    "        \n",
    "        try:\n",
    "            pd.to_pickle(emb_matrix, f\"{EMBEDDINGS_FOLDER}/emb_matrix_x{self.subset}_tok_{self.maxlen_per_sent}_len{self.token_max_words}.pkl\")\n",
    "        except:\n",
    "            print('Saved unsuccessfully')\n",
    "            return emb_matrix\n",
    "\n",
    "        return emb_matrix\n",
    "\n",
    "\n",
    "    def pad(self):\n",
    "        X_pad = pad_sequences(self.sequences, maxlen = self.maxlen_per_sent)\n",
    "        return X_pad\n",
    "\n",
    "    def undersample(self):\n",
    "        undersampler = RandomUnderSampler(random_state=42)\n",
    "        X_resampled, y_resampled = undersampler.fit_resample(self.X_train, self.y_train)\n",
    "\n",
    "        return X_resampled, y_resampled\n",
    "\n",
    "\n",
    "class Train(DataPrep):\n",
    "    def __init__(self, subset = None, text_prep = 'lem', token_max_words = 5000, maxlen_per_sent = 150, undersample = True):\n",
    "        super().__init__(subset, text_prep, token_max_words, maxlen_per_sent, undersample)\n",
    "        \n",
    "        use_cuda = torch.cuda.is_available()\n",
    "        self.device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "        self.X_train_tensor = torch.as_tensor(self.X_train, dtype = torch.float)\n",
    "        self.y_train_tensor = torch.as_tensor(self.y_train, dtype = torch.int8)\n",
    "\n",
    "\n",
    "    def lstm(self, nodes):\n",
    "\n",
    "        self.model = Sequential().to(device = self.device)\n",
    "        self.model.add(Embedding(input_dim= self.vocab_len, output_dim= self.embed_vector_len, input_shape = (self.maxlen_per_sent,), trainable=False, embeddings_initializer = initializers.Constant(self.emb_matrix)))\n",
    "        self.model.add(LSTM(nodes))\n",
    "        self.model.add(Dense(1, activation = 'sigmoid'))\n",
    "\n",
    "        self.model.compile(optimizer='adam',\n",
    "                    loss='binary_crossentropy',\n",
    "                    metrics=['accuracy'])\n",
    "\n",
    "        # Train model\n",
    "        self.model.fit(self.X_train, self.y_train, epochs=10, batch_size=1, verbose=1)  \n",
    "    \n",
    "    # def lstm_op(self):\n",
    "    #     import math\n",
    "\n",
    "    #     def objective(trial):\n",
    "    #         units = trial.suggest_categorical(\"units\", [32, 64, 128, 256])\n",
    "    #         units2 = units//2\n",
    "    #         epochs = trial.suggest_categorical(\"epochs\", [10, 20, 30])\n",
    "    #         batch_size = trial.suggest_categorical(\"batch_size\", [32, 64, 128])\n",
    "    #         dropout = trial.suggest_float(\"dropout\", low = 0.1, high = 0.5)\n",
    "            \n",
    "    #         self.model = Sequential()\n",
    "    #         self.model.add(Embedding(input_dim= self.vocab_len, output_dim= self.embed_vector_len, input_shape = (self.maxlen_per_sent,), trainable=False, embeddings_initializer = initializers.Constant(self.emb_matrix)))\n",
    "    #         self.model.add(LSTM(units))\n",
    "    #         self.model.add(Dropout(dropout))\n",
    "    #         self.model.add(Dense(units2))\n",
    "    #         self.model.add(Dense(1, activation = 'sigmoid'))\n",
    "\n",
    "    #         self.model.compile(optimizer='adam',\n",
    "    #                         loss='binary_crossentropy',\n",
    "    #                         metrics=['accuracy'])\n",
    "\n",
    "    #         self.model.fit(self.X_train, self.y_train, epochs= epochs, batch_size= batch_size, verbose=1)  \n",
    "    #         _, accuracy = self.model.evaluate(self.X_test, self.y_test, verbose=0)\n",
    "\n",
    "    #         return accuracy\n",
    "\n",
    "    #     study = optuna.create_study(direction=\"maximize\")\n",
    "    #     study.optimize(objective, n_trials=10)\n",
    "\n",
    "    #     self.best_trial = study.best_trial\n",
    "    #     self.best_params = self.best_trial.params\n",
    "    #     self.best_accuracy = self.best_trial.value\n",
    "\n",
    "    #     print(\"Best hyperparameters:\", self.best_params)\n",
    "    #     print(\"Best accuracy:\", self.best_accuracy)\n",
    "\n",
    "\n",
    "    def predict(self, verbose = False):\n",
    "\n",
    "        loss, accuracy = self.model.evaluate(self.X_test, self.y_test)\n",
    "        print(\"Test Accuracy:\", accuracy)\n",
    "\n",
    "        # Make predictions\n",
    "        predictions = self.model.predict(self.X_test)\n",
    "\n",
    "        y_hat = [1 if i> 0.5 else 0 for i in predictions]\n",
    "\n",
    "        if verbose:\n",
    "            print(\"Classification Report:\")\n",
    "            print(classification_report(self.y_test, y_hat))\n",
    "\n",
    "            print(\"Confusion Matrix:\")\n",
    "            print(confusion_matrix(self.y_test, y_hat))\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dupes removed\n",
      "Tokenizing..\n",
      "Finished Tokenizing\n",
      "Initialising word2vec\n",
      "lemm/stemm\n",
      "Embedding...\n",
      "Padding\n",
      "Finished padding\n",
      "Undersampling..\n",
      "Counter({0: 19480, 1: 5672})\n",
      "Counter({0: 5672, 1: 5672})\n"
     ]
    }
   ],
   "source": [
    "test = Train()\n",
    "## the test.X_train is not embedded\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0,    0,    0, ..., 1501, 1126,   25],\n",
       "       [   0,    0,    0, ...,  205, 2790, 4265],\n",
       "       [   0,    0,    0, ...,  274,  581, 4183],\n",
       "       ...,\n",
       "       [   0,    0,    0, ...,  867,   73,   28],\n",
       "       [   0,    0,    0, ..., 1565, 1977, 2873],\n",
       "       [   0,    0,    0, ...,   24,   73,   39]], dtype=int32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input tensor shape: torch.Size([11344, 150])\n",
      "Embedded output shape: torch.Size([11344, 150, 150])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.0607,  0.3815,  0.3934,  ..., -0.2935,  0.4256, -0.1617],\n",
       "         [ 1.0607,  0.3815,  0.3934,  ..., -0.2935,  0.4256, -0.1617],\n",
       "         [ 1.0607,  0.3815,  0.3934,  ..., -0.2935,  0.4256, -0.1617],\n",
       "         ...,\n",
       "         [ 0.3236, -0.4857, -0.6464,  ...,  0.8669,  1.8450, -0.7716],\n",
       "         [ 1.6670,  1.1885, -0.0464,  ...,  2.1215,  0.0046, -0.5499],\n",
       "         [ 0.6553, -1.5342,  0.5770,  ...,  0.2437, -1.3944,  0.1840]],\n",
       "\n",
       "        [[ 1.0607,  0.3815,  0.3934,  ..., -0.2935,  0.4256, -0.1617],\n",
       "         [ 1.0607,  0.3815,  0.3934,  ..., -0.2935,  0.4256, -0.1617],\n",
       "         [ 1.0607,  0.3815,  0.3934,  ..., -0.2935,  0.4256, -0.1617],\n",
       "         ...,\n",
       "         [-2.3411, -1.0062, -0.8563,  ..., -0.9615,  1.3050, -0.1689],\n",
       "         [-1.3110,  0.6002,  1.7048,  ..., -0.2773, -2.0583,  1.4835],\n",
       "         [-0.4248, -0.2866,  1.7164,  ...,  1.1965, -0.3353, -1.8403]],\n",
       "\n",
       "        [[ 1.0607,  0.3815,  0.3934,  ..., -0.2935,  0.4256, -0.1617],\n",
       "         [ 1.0607,  0.3815,  0.3934,  ..., -0.2935,  0.4256, -0.1617],\n",
       "         [ 1.0607,  0.3815,  0.3934,  ..., -0.2935,  0.4256, -0.1617],\n",
       "         ...,\n",
       "         [-1.6711,  0.8811,  1.0756,  ...,  0.7442, -1.1589, -0.8047],\n",
       "         [-1.6058,  0.8132, -1.0971,  ...,  2.1831, -0.8262,  1.7611],\n",
       "         [ 0.9355,  0.6156,  0.0322,  ...,  0.4033, -0.0864, -2.2573]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 1.0607,  0.3815,  0.3934,  ..., -0.2935,  0.4256, -0.1617],\n",
       "         [ 1.0607,  0.3815,  0.3934,  ..., -0.2935,  0.4256, -0.1617],\n",
       "         [ 1.0607,  0.3815,  0.3934,  ..., -0.2935,  0.4256, -0.1617],\n",
       "         ...,\n",
       "         [ 0.2367, -0.0270, -1.2817,  ...,  1.0179,  0.4781,  0.3639],\n",
       "         [ 0.1700, -0.1574, -0.6845,  ...,  0.3744, -0.7781,  0.0264],\n",
       "         [ 1.1377,  2.2310,  0.7642,  ...,  1.1401,  0.8995,  1.4556]],\n",
       "\n",
       "        [[ 1.0607,  0.3815,  0.3934,  ..., -0.2935,  0.4256, -0.1617],\n",
       "         [ 1.0607,  0.3815,  0.3934,  ..., -0.2935,  0.4256, -0.1617],\n",
       "         [ 1.0607,  0.3815,  0.3934,  ..., -0.2935,  0.4256, -0.1617],\n",
       "         ...,\n",
       "         [ 1.4249, -1.0619, -0.7695,  ...,  1.5525, -1.0030, -0.7707],\n",
       "         [ 0.1891, -1.0061,  1.0321,  ...,  1.1743, -0.5704, -0.5580],\n",
       "         [ 0.7875, -0.8443,  0.7406,  ...,  1.5146, -0.7507,  1.5915]],\n",
       "\n",
       "        [[ 1.0607,  0.3815,  0.3934,  ..., -0.2935,  0.4256, -0.1617],\n",
       "         [ 1.0607,  0.3815,  0.3934,  ..., -0.2935,  0.4256, -0.1617],\n",
       "         [ 1.0607,  0.3815,  0.3934,  ..., -0.2935,  0.4256, -0.1617],\n",
       "         ...,\n",
       "         [-0.2254, -1.0659,  1.2681,  ..., -0.3285,  0.8312,  0.6983],\n",
       "         [ 0.1700, -0.1574, -0.6845,  ...,  0.3744, -0.7781,  0.0264],\n",
       "         [ 0.9200, -0.0584, -1.3690,  ..., -0.9284, -0.6020,  0.3040]]],\n",
       "       device='cuda:0', grad_fn=<EmbeddingBackward0>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class TokenEmbedding(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_size):\n",
    "        super(TokenEmbedding, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        embedded = self.embedding(x)\n",
    "        return embedded\n",
    "        \n",
    "\n",
    "embedding_layer = TokenEmbedding(vocab_size = ALL_TOKEN_MAX_WORDS, embed_size = MAXLEN_PER_SENT)\n",
    "input_tensor_train = torch.as_tensor(test.X_train, dtype=torch.int64)\n",
    "input_tensor_test = torch.as_tensor(test.X_test, dtype = torch.int64)\n",
    "input_tensor_val = torch.as_tensor(test.X_val, dtype = torch.int64)\n",
    "\n",
    "X_train = embedding_layer(input_tensor_train)\n",
    "X_test = embedding_layer(input_tensor_test)\n",
    "X_val = embedding_layer(input_tensor_val)\n",
    "\n",
    "print(\"Input tensor shape:\", input_tensor_train.shape)\n",
    "print(\"Embedded output shape:\", X_train.shape)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([11344])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.utils.data as Data\n",
    "\n",
    "y_train_tensor = torch.as_tensor(test.y_train, dtype=torch.float32)\n",
    "y_test_tensor = torch.as_tensor(test.y_test.to_numpy(dtype=np.single))\n",
    "y_val_tensor = torch.as_tensor(test.y_val.to_numpy(dtype=np.single))\n",
    "\n",
    "train_data = Data.TensorDataset(X_train, y_train_tensor)\n",
    "test_data = Data.TensorDataset(X_test, y_test_tensor)\n",
    "val_data = Data.TensorDataset(X_val, y_val_tensor)\n",
    "\n",
    "train_loader = Data.DataLoader(dataset=train_data,\n",
    "                               batch_size =BATCH_SIZE,\n",
    "                               shuffle=False)\n",
    "\n",
    "test_loader = Data.DataLoader(dataset=test_data,\n",
    "                              batch_size=BATCH_SIZE,\n",
    "                              shuffle=False)\n",
    "\n",
    "val_loader = Data.DataLoader(dataset = val_data,\n",
    "                            batch_size = BATCH_SIZE,\n",
    "                            shuffle = False)\n",
    "\n",
    "y_train_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_size):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.output_layer = nn.Linear(hidden_size, output_size)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        # self.hidden = nn.Linear(input_size, hidden_size)\n",
    "\n",
    "    def forward(self, X):\n",
    "        ##  (num layers, batch_size, hidden_size)\n",
    "        hidden_states = torch.zeros(self.num_layers, X.size(0), self.hidden_size, device = DEVICE)\n",
    "        cell_states = torch.zeros(self.num_layers, X.size(0), self.hidden_size, device = DEVICE)\n",
    "\n",
    "        out, _ = self.lstm(X, (hidden_states, cell_states))\n",
    "        out = self.output_layer(out[:, -1, :])\n",
    "        return self.sigmoid(out)\n",
    "\n",
    "    def init_hidden(self, batch_size, device='cpu'):\n",
    "        # Initializes hidden state\n",
    "        # The hidden state is a tuple of (h_0, c_0) for LSTMs\n",
    "        # h_0: Initial hidden state for each element in the batch\n",
    "        # c_0: Initial cell state for each element in the batch\n",
    "        h_0 = torch.zeros(self.num_layers, batch_size, self.hidden_size).to(device)\n",
    "        c_0 = torch.zeros(self.num_layers, batch_size, self.hidden_size).to(device)\n",
    "        return (h_0, c_0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTMModel(\n",
      "  (lstm): LSTM(150, 75, batch_first=True)\n",
      "  (output_layer): Linear(in_features=75, out_features=1, bias=True)\n",
      "  (sigmoid): Sigmoid()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "lstm = LSTMModel(input_size = INPUT_LENGTH, hidden_size = HIDDEN_SIZE, num_layers = NUM_LAYERS, output_size = 1).to(DEVICE)\n",
    "print(lstm)\n",
    "loss_func = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(lstm.parameters(), lr = LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_fn(y_true,y_pred):\n",
    "    correct = torch.eq(y_true,y_pred).sum().item()\n",
    "    accuracy = (correct / len(y_pred)) * 100\n",
    "    return accuracy\n",
    "\n",
    "def precision_fn(y_true,y_pred):\n",
    "    true_positive = ((y_pred == 1.0) & (y_true == 1.0)).sum().item()\n",
    "    predicted_positive = (y_pred==1.0).sum().item()\n",
    "    return true_positive/(predicted_positive + 1e-7)\n",
    "\n",
    "def recall_fn(y_true,y_pred):\n",
    "    true_positive = ((y_pred == 1.0) & (y_true == 1.0)).sum().item()\n",
    "    actual_positive = (y_true==1.0).sum().item()\n",
    "    return true_positive/(actual_positive + 1e-7)\n",
    "\n",
    "def f1_score(y_true,y_pred):\n",
    "    prec = precision_fn(y_true,y_pred)\n",
    "    recall = recall_fn(y_true,y_pred)\n",
    "    return 2 * (prec * recall) / (prec + recall + 1e-7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_batch(model,loss_fn,xb,yb, opt=None):\n",
    "    yb_pred = model(xb)\n",
    "\n",
    "    print(yb_pred)\n",
    "    print(yb)\n",
    "    loss = loss_fn(yb_pred.squeeze(),yb)\n",
    "\n",
    "    yb_bin = (yb_pred.squeeze() > 0.5).float()\n",
    "    \n",
    "    accuracy = accuracy_fn(yb,yb_bin)\n",
    "    precision = precision_fn(yb,yb_bin)\n",
    "    recall = recall_fn(yb,yb_bin)\n",
    "    f1 = f1_score(yb,yb_bin)\n",
    "\n",
    "    if opt is not None:\n",
    "        opt.zero_grad()\n",
    "        loss.backward(retain_graph = True)\n",
    "        opt.step()\n",
    "        \n",
    "\n",
    "    return loss.item(), accuracy, precision, recall, f1, len(xb)\n",
    "    \n",
    "\n",
    "def train(num_epochs, model, train_dataloader, val_dataloader, opt = None):\n",
    "    total_steps = len(train_dataloader)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        for batch, (X_train_batch, y_train_batch) in tqdm.tqdm(enumerate(train_dataloader), total = len(train_loader), desc = f\"Epochs {epoch+1}/{num_epochs}\"):\n",
    "            X_train_batch = X_train_batch.to(DEVICE)\n",
    "            y_train_batch = y_train_batch.to(DEVICE)\n",
    "            loss_batch(model, loss_func, X_train_batch, y_train_batch, opt)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            losses, accuracy, precision,recall, f1_scores, nums = zip(*[loss_batch(model,loss_func,xb,yb) for xb,yb in val_dataloader]\n",
    "            )\n",
    "\n",
    "        val_loss = np.sum(np.multiply(losses,nums)) / np.sum(nums)\n",
    "        val_accuracy = np.sum(np.multiply(accuracy,nums)) / np.sum(nums)\n",
    "        val_precision = np.sum(np.multiply(precision,nums)) / np.sum(nums)\n",
    "        val_recall = np.sum(np.multiply(recall,nums)) / np.sum(nums)\n",
    "        val_f1_score = np.sum(np.multiply(f1_scores,nums)) / np.sum(nums)\n",
    "\n",
    "        if (epoch+1) % 100 == 0:\n",
    "            print(f\"Epoch: {epoch+1}\") \n",
    "            print(f\"Validation Loss: {val_loss}\")\n",
    "            print(f\"Validation Accuracy: {val_accuracy:.4f}% | Validation Recall: {val_recall:.4f} | Validation Precision: {val_precision:.4f} | Validation F1 Score: {val_f1_score:.4f}\")   \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs 1/3:   0%|          | 0/91 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5441],\n",
      "        [0.5123],\n",
      "        [0.4943],\n",
      "        [0.5128],\n",
      "        [0.5107],\n",
      "        [0.5149],\n",
      "        [0.5201],\n",
      "        [0.4992],\n",
      "        [0.5033],\n",
      "        [0.4830],\n",
      "        [0.5183],\n",
      "        [0.5581],\n",
      "        [0.4937],\n",
      "        [0.4859],\n",
      "        [0.4836],\n",
      "        [0.5183],\n",
      "        [0.5423],\n",
      "        [0.5240],\n",
      "        [0.5112],\n",
      "        [0.5039],\n",
      "        [0.5361],\n",
      "        [0.4965],\n",
      "        [0.5195],\n",
      "        [0.5046],\n",
      "        [0.5115],\n",
      "        [0.4635],\n",
      "        [0.5199],\n",
      "        [0.5519],\n",
      "        [0.5049],\n",
      "        [0.5153],\n",
      "        [0.5302],\n",
      "        [0.5460],\n",
      "        [0.5163],\n",
      "        [0.4964],\n",
      "        [0.4900],\n",
      "        [0.5200],\n",
      "        [0.5401],\n",
      "        [0.5309],\n",
      "        [0.5102],\n",
      "        [0.5215],\n",
      "        [0.5496],\n",
      "        [0.4909],\n",
      "        [0.5013],\n",
      "        [0.5179],\n",
      "        [0.4925],\n",
      "        [0.4888],\n",
      "        [0.4879],\n",
      "        [0.5463],\n",
      "        [0.5549],\n",
      "        [0.4819],\n",
      "        [0.4946],\n",
      "        [0.5331],\n",
      "        [0.4783],\n",
      "        [0.5102],\n",
      "        [0.5354],\n",
      "        [0.5026],\n",
      "        [0.5120],\n",
      "        [0.5265],\n",
      "        [0.5270],\n",
      "        [0.5327],\n",
      "        [0.5035],\n",
      "        [0.5115],\n",
      "        [0.5338],\n",
      "        [0.5152],\n",
      "        [0.5324],\n",
      "        [0.4799],\n",
      "        [0.5122],\n",
      "        [0.5207],\n",
      "        [0.5424],\n",
      "        [0.5264],\n",
      "        [0.4910],\n",
      "        [0.5262],\n",
      "        [0.5075],\n",
      "        [0.5378],\n",
      "        [0.4749],\n",
      "        [0.5137],\n",
      "        [0.5356],\n",
      "        [0.5764],\n",
      "        [0.5346],\n",
      "        [0.5228],\n",
      "        [0.4870],\n",
      "        [0.4974],\n",
      "        [0.5466],\n",
      "        [0.5100],\n",
      "        [0.5246],\n",
      "        [0.5608],\n",
      "        [0.5102],\n",
      "        [0.5151],\n",
      "        [0.5659],\n",
      "        [0.5092],\n",
      "        [0.5183],\n",
      "        [0.4984],\n",
      "        [0.4868],\n",
      "        [0.4654],\n",
      "        [0.5141],\n",
      "        [0.4761],\n",
      "        [0.5730],\n",
      "        [0.5267],\n",
      "        [0.5608],\n",
      "        [0.5085],\n",
      "        [0.5482],\n",
      "        [0.4877],\n",
      "        [0.4976],\n",
      "        [0.5537],\n",
      "        [0.4884],\n",
      "        [0.5456],\n",
      "        [0.5108],\n",
      "        [0.5121],\n",
      "        [0.4803],\n",
      "        [0.4928],\n",
      "        [0.5221],\n",
      "        [0.5376],\n",
      "        [0.4619],\n",
      "        [0.5305],\n",
      "        [0.5115],\n",
      "        [0.4965],\n",
      "        [0.5858],\n",
      "        [0.5128],\n",
      "        [0.4892],\n",
      "        [0.5392],\n",
      "        [0.5259],\n",
      "        [0.5209],\n",
      "        [0.5267],\n",
      "        [0.5578],\n",
      "        [0.4991]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0.], device='cuda:0')\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Trying to backward through the graph a second time (or directly access saved tensors after they have already been freed). Saved intermediate values of the graph are freed when you call .backward() or autograd.grad(). Specify retain_graph=True if you need to backward through the graph a second time or if you need to access saved tensors after calling backward.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[103], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m trained_model \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mEPOCHS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlstm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[102], line 31\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(num_epochs, model, train_dataloader, val_dataloader, opt)\u001b[0m\n\u001b[1;32m     29\u001b[0m     X_train_batch \u001b[38;5;241m=\u001b[39m X_train_batch\u001b[38;5;241m.\u001b[39mto(DEVICE)\n\u001b[1;32m     30\u001b[0m     y_train_batch \u001b[38;5;241m=\u001b[39m y_train_batch\u001b[38;5;241m.\u001b[39mto(DEVICE)\n\u001b[0;32m---> 31\u001b[0m     \u001b[43mloss_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m     34\u001b[0m     losses, accuracy, precision,recall, f1_scores, nums \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39m[loss_batch(model,loss_func,xb,yb) \u001b[38;5;28;01mfor\u001b[39;00m xb,yb \u001b[38;5;129;01min\u001b[39;00m val_dataloader]\n\u001b[1;32m     35\u001b[0m     )\n",
      "Cell \u001b[0;32mIn[102], line 17\u001b[0m, in \u001b[0;36mloss_batch\u001b[0;34m(model, loss_fn, xb, yb, opt)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m opt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     16\u001b[0m     opt\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 17\u001b[0m     \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m     opt\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\u001b[38;5;241m.\u001b[39mitem(), accuracy, precision, recall, f1, \u001b[38;5;28mlen\u001b[39m(xb)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py:513\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    466\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Computes the gradient of current tensor wrt graph leaves.\u001b[39;00m\n\u001b[1;32m    467\u001b[0m \n\u001b[1;32m    468\u001b[0m \u001b[38;5;124;03mThe graph is differentiated using the chain rule. If the tensor is\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    510\u001b[0m \u001b[38;5;124;03m        used to compute the attr::tensors.\u001b[39;00m\n\u001b[1;32m    511\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    512\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 513\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mhandle_torch_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    514\u001b[0m \u001b[43m        \u001b[49m\u001b[43mTensor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    515\u001b[0m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    516\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    517\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgradient\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    518\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    519\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    520\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    521\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    522\u001b[0m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mbackward(\n\u001b[1;32m    523\u001b[0m     \u001b[38;5;28mself\u001b[39m, gradient, retain_graph, create_graph, inputs\u001b[38;5;241m=\u001b[39minputs\n\u001b[1;32m    524\u001b[0m )\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/overrides.py:1604\u001b[0m, in \u001b[0;36mhandle_torch_function\u001b[0;34m(public_api, relevant_args, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1600\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _is_torch_function_mode_enabled():\n\u001b[1;32m   1601\u001b[0m     \u001b[38;5;66;03m# if we're here, the mode must be set to a TorchFunctionStackMode\u001b[39;00m\n\u001b[1;32m   1602\u001b[0m     \u001b[38;5;66;03m# this unsets it and calls directly into TorchFunctionStackMode's torch function\u001b[39;00m\n\u001b[1;32m   1603\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m _pop_mode_temporarily() \u001b[38;5;28;01mas\u001b[39;00m mode:\n\u001b[0;32m-> 1604\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mmode\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__torch_function__\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpublic_api\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtypes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1605\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m:\n\u001b[1;32m   1606\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/_device.py:77\u001b[0m, in \u001b[0;36mDeviceContext.__torch_function__\u001b[0;34m(self, func, types, args, kwargs)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m func \u001b[38;5;129;01min\u001b[39;00m _device_constructors() \u001b[38;5;129;01mand\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevice\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     76\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevice\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice\n\u001b[0;32m---> 77\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py:522\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    513\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    514\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    515\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    520\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    521\u001b[0m     )\n\u001b[0;32m--> 522\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    524\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py:266\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    261\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    263\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 266\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Trying to backward through the graph a second time (or directly access saved tensors after they have already been freed). Saved intermediate values of the graph are freed when you call .backward() or autograd.grad(). Specify retain_graph=True if you need to backward through the graph a second time or if you need to access saved tensors after calling backward."
     ]
    }
   ],
   "source": [
    "trained_model = train(EPOCHS, lstm, train_loader, val_loader, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(trained_model, 'model/model_epoch_10_bs_8.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('model/trained_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# _results = []\n",
    "# for epoch in range(EPOCHS):\n",
    "#     lstm.train()\n",
    "\n",
    "#     train_loss = 0\n",
    "#     for batch, (X_train_batch, y_train_batch) in enumerate(train_loader):\n",
    "\n",
    "#         lstm.zero_grad()\n",
    "#         out, prob = lstm(X_train_batch)\n",
    "\n",
    "#         print(out)\n",
    "\n",
    "#         loss = F.binary_cross_entropy(out, y_train_batch)\n",
    "\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "#         train_loss += loss.item() * X_train_batch.size(0)\n",
    "\n",
    "#     train_loss /= len(train_loader.dataset)\n",
    "\n",
    "#     if VERBOSE:\n",
    "#         print('Epoch: {}, Train Loss: {:4f}', format(epoch, train_loss))\n",
    "\n",
    "#     lstm.eval()\n",
    "\n",
    "#     with torch.no_grad():\n",
    "#         correct = 0; valid_loss = 0\n",
    "#         for i, (X_test_batch, y_test_batch) in enumerate(test_loader):\n",
    "#             out, prob = lstm(X_test_batch)\n",
    "#             loss = F.binary_cross_entropy(out, y_test_batch)\n",
    "\n",
    "#             valid_loss += loss.item() * X_test_batch.size(0)\n",
    "\n",
    "#             preds = prob.argmax(dim = 1, keepdim  = True)\n",
    "\n",
    "#             correct += preds.eq(y_test_batch.view_as(preds)).sum().item() #Count number of correct\n",
    "\n",
    "#         valid_loss /= len(test_loader.dataset)\n",
    "#         accuracy = correct / len(test_loader.dataset)\n",
    "\n",
    "#     if VERBOSE:\n",
    "#         print('Validation Loss: {}, Validation Accuracy: {:4f}', format(valid_loss, accuracy))\n",
    "\n",
    "#     _results.append([epoch, train_loss, valid_loss, accuracy])\n",
    "\n",
    "# results = np.array(_results)\n",
    "# print('Fin Train')\n",
    "# print('FInal validation error: ', 100.(1-accuracy), \"%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTMModel(\n",
       "  (lstm): LSTM(34256, 512, batch_first=True)\n",
       "  (fc): Linear(in_features=512, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.lstm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.train_lstm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device:  cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "print(\"Device: \",device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.lstm_op()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spam",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
