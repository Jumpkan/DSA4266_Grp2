{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functions import *\n",
    "import wordninja\n",
    "import requests\n",
    "import random\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Torch cannot work properly in jupyter notebook\n",
    "# import os\n",
    "# count = 0 \n",
    "# if count == 0:\n",
    "#     os.chdir(\"test_dir\")\n",
    "#     count += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\Zoe Lua\\\\DSA4266_Grp2'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.read_pickle(DF_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "## CONFIG\n",
    "\n",
    "DF_PATH = \"Data/full_df_2.pkl\"\n",
    "X_NAME = 'clean_msg'\n",
    "Y_NAME = 'class'\n",
    "EMBEDDINGS_FOLDER = 'embeddings_2'\n",
    "\n",
    "#### For preprocessing\n",
    "# ALL_MAXLEN_PER_SENT = [150]\n",
    "# ALL_TOKEN_MAX_WORDS = [5000]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Semantic Dictionaries\n",
    "\n",
    "def get_synonyms_conceptnet(word):\n",
    "    synonyms = []\n",
    "    url = f'http://api.conceptnet.io/c/en/{word}?filter=/c/en'\n",
    "    response = requests.get(url)\n",
    "    data = response.json()\n",
    "    for edge in data['edges']:\n",
    "        if edge['rel']['label'] == 'Synonym' and edge['start']['language'] == 'en' and edge['end']['language'] == 'en':\n",
    "            start = edge['start']['label']\n",
    "            end = edge['end']['label']\n",
    "            synonyms.append(end if start == word else start)\n",
    "\n",
    "    if synonyms != []:\n",
    "        synonym = random.choice(synonyms)\n",
    "    else:\n",
    "        synonym = synonyms\n",
    "    return synonym\n",
    "\n",
    "def get_synonyms_wordnet(word):\n",
    "    synonyms = []\n",
    "    synsets = wordnet.synsets(word)\n",
    "    for synset in synsets:\n",
    "        synonyms.extend([lemma.name() for lemma in synset.lemmas() if lemma.name() != word])\n",
    "\n",
    "    if synonyms != []:\n",
    "        synonym = random.choice(synonyms)\n",
    "    else:\n",
    "        synonym = synonyms\n",
    "    return synonym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataPrep():\n",
    "    def __init__(self, subset = None, text_prep = 'lem', token_max_words = 5000, maxlen_per_sent = 512, undersample = True):\n",
    "        \"\"\"\n",
    "        subset: X[:subset]\n",
    "        \"\"\"\n",
    "        self.df = pd.read_pickle(DF_PATH)\n",
    "        self.subset = subset\n",
    "        self.maxlen_per_sent = maxlen_per_sent\n",
    "\n",
    "        self.remove_duplicates()\n",
    "        print('Dupes removed')\n",
    "        self.X = self.df[X_NAME]\n",
    "        self.y = self.df[Y_NAME].apply(lambda x: 1 if x == 'spam' else 0)\n",
    "        self.token_max_words = token_max_words\n",
    "\n",
    "        if self.subset:\n",
    "            self.X = self.X[:self.subset]\n",
    "            self.y = self.y[:self.subset]\n",
    "        \n",
    "        print('Tokenizing..')\n",
    "        self.tokenize()\n",
    "        print('Finished Tokenizing')\n",
    "\n",
    "        print('Initialising word2vec')\n",
    "        self.word_to_vec_map = self.word2vec()\n",
    "\n",
    "        print('lemm/stemm')\n",
    "        if text_prep == 'lem':\n",
    "            self.X = self.lemming()\n",
    "        if text_prep == 'stem':\n",
    "            self.X = self.stemming()\n",
    "\n",
    "        print('Embedding...')\n",
    "        self.pre_embed()\n",
    "        path = f'{EMBEDDINGS_FOLDER}/emb_matrix_x{self.subset}_tok_{self.maxlen_per_sent}_len{self.token_max_words}.pkl'\n",
    "        if os.path.exists(path):\n",
    "            self.emb_matrix = pd.read_pickle(path)\n",
    "        else:\n",
    "            self.emb_matrix = self.tok_embedding_mat(alternative = [get_synonyms_conceptnet, get_synonyms_wordnet])\n",
    "            print('Finished embedding')\n",
    "\n",
    "        print('Padding')\n",
    "        X_pad = self.pad()\n",
    "        print('Finished padding')\n",
    "\n",
    "        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(X_pad, self.y, test_size=0.33, random_state=42)\n",
    "\n",
    "        if undersample:\n",
    "            print('Undersampling..')\n",
    "            print(Counter(self.y_train))\n",
    "            self.X_train, self.y_train = self.undersample()\n",
    "            print(Counter(self.y_train))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def remove_duplicates(self):\n",
    "    \n",
    "        ## First remove all those X values with differing binary y values\n",
    "        occurrences = self.df.groupby([X_NAME, Y_NAME]).size().reset_index(name='count')\n",
    "        duplicates = occurrences[occurrences.duplicated(subset=X_NAME, keep=False)]\n",
    "        for index, row in duplicates.iterrows():\n",
    "            x_value = row[X_NAME]\n",
    "            max_count = occurrences[(occurrences[X_NAME] == x_value)].max()['count']\n",
    "            occurrences.drop(occurrences[(occurrences[X_NAME] == x_value) & (occurrences['count'] != max_count)].index, inplace=True)\n",
    "\n",
    "        ## Remove duplicates\n",
    "        self.df = occurrences.drop_duplicates(subset = X_NAME).reset_index(drop = True)\n",
    "    \n",
    "    def tokenize(self, join = False):\n",
    "        def tokenize_helper(text, join = False):\n",
    "            stop_words = set(stopwords.words('english'))\n",
    "            tokens = word_tokenize(text)\n",
    "            tokens = [word.lower() for word in tokens if word.lower() not in stop_words]\n",
    "\n",
    "            if join:\n",
    "                tokens = ' '.join([''.join(c for c in word if c not in string.punctuation) for word in tokens if word])\n",
    "        \n",
    "            return tokens\n",
    "        \n",
    "        self.X = self.X.apply(lambda x: tokenize_helper(x, join))\n",
    "\n",
    "    ## Embedders\n",
    "        \n",
    "    def word2vec(self):\n",
    "        from gensim.models.word2vec import Word2Vec\n",
    "        import gensim.downloader as api\n",
    "\n",
    "        word_to_vec_map = api.load(\"word2vec-google-news-300\")\n",
    "\n",
    "        return word_to_vec_map\n",
    "    \n",
    "    \n",
    "    ## Stemming/ Lemmetization\n",
    "\n",
    "    def stemming(self):\n",
    "        ps = PorterStemmer()\n",
    "\n",
    "        def stem(row):\n",
    "            print(row)\n",
    "            stemmed = []\n",
    "            for word in row:\n",
    "                stemmed += [ps.stem(word)]\n",
    "            print('STEMMED:', stemmed)\n",
    "\n",
    "            return stemmed\n",
    "\n",
    "        return self.X.apply(stem)\n",
    "    \n",
    "\n",
    "    def lemming(self):\n",
    "\n",
    "        def lem(row):\n",
    "            lemmatizer = WordNetLemmatizer()\n",
    "            lemmed = [lemmatizer.lemmatize(word) for word in row]\n",
    "            # print(row)\n",
    "            # print(lemmed,\"\\n\")\n",
    "            return lemmed\n",
    "\n",
    "        return self.X.apply(lem)\n",
    "    \n",
    "    def pre_embed(self):\n",
    "        self.tokenizer = text.Tokenizer(num_words=self.token_max_words)\n",
    "        self.tokenizer.fit_on_texts(self.X)\n",
    "\n",
    "        self.sequences = self.tokenizer.texts_to_sequences(self.X)\n",
    "\n",
    "        self.word_index = self.tokenizer.word_index\n",
    "        self.vocab_len = len(self.word_index) + 1\n",
    "        self.embed_vector_len = self.word_to_vec_map['moon'].shape[0]\n",
    "    \n",
    "    def tok_embedding_mat(self, alternative):\n",
    "        \"\"\"\n",
    "        embedder: word2vec\n",
    "        alternative: list of callable to find synonyms from, inorder of precedence\n",
    "        \"\"\"\n",
    "        synonyms = {} #Dict to store synonyms\n",
    "\n",
    "        emb_matrix = np.zeros((self.vocab_len, self.embed_vector_len))\n",
    "\n",
    "\n",
    "        for word, index in tqdm.tqdm(self.word_index.items(), total = len(self.word_index)):\n",
    "            try: # Try to find in word2vec\n",
    "                embedding_vector = self.word_to_vec_map[word]\n",
    "                emb_matrix[index-1, :] = embedding_vector\n",
    "            except: # Word2vec dont have, find in own synonym dict\n",
    "                synonym = synonyms.get(word, None) \n",
    "                if (synonym) and (synonym in self.word_to_vec_map.index_to_key):\n",
    "                    emb_matrix[index-1,:] = self.word_to_vec_map[synonym]\n",
    "                else: # If word2vec, own synonym dict dont have, find from dictionaries\n",
    "                    for dictionary in alternative:\n",
    "                        try: \n",
    "                            synonym = dictionary(word)\n",
    "                            if synonym:\n",
    "                                # print(f'Found synonym: {synonym} for word: {word}')\n",
    "                                embedding_vector = self.word_to_vec_map[synonym] \n",
    "                                emb_matrix[index-1, :] = embedding_vector\n",
    "                                synonyms[word] = synonym\n",
    "                        except:\n",
    "                            continue\n",
    "        self.syn = synonyms\n",
    "        \n",
    "        try:\n",
    "            pd.to_pickle(emb_matrix, f\"{EMBEDDINGS_FOLDER}/emb_matrix_x{self.subset}_tok_{self.maxlen_per_sent}_len{self.token_max_words}.pkl\")\n",
    "        except:\n",
    "            print('Saved unsuccessfully')\n",
    "            return emb_matrix\n",
    "\n",
    "        return emb_matrix\n",
    "\n",
    "\n",
    "    def pad(self):\n",
    "        X_pad = pad_sequences(self.sequences, maxlen = self.maxlen_per_sent)\n",
    "        return X_pad\n",
    "\n",
    "    def undersample(self):\n",
    "        undersampler = RandomUnderSampler(random_state=42)\n",
    "        X_resampled, y_resampled = undersampler.fit_resample(self.X_train, self.y_train)\n",
    "\n",
    "        return X_resampled, y_resampled\n",
    "\n",
    "\n",
    "class Train(DataPrep):\n",
    "    def __init__(self, subset = None, text_prep = 'lem', token_max_words = 5000, maxlen_per_sent = 150, undersample = True):\n",
    "        super().__init__(subset, text_prep, token_max_words, maxlen_per_sent, undersample)\n",
    "\n",
    "    def lstm(self, nodes):\n",
    "        \"\"\"\n",
    "        Single layer LSTM\n",
    "        \"\"\"\n",
    "        self.model = Sequential()\n",
    "        self.model.add(Embedding(input_dim= self.vocab_len, output_dim= self.embed_vector_len, input_shape = (self.maxlen_per_sent,), trainable=False, embeddings_initializer = initializers.Constant(self.emb_matrix)))\n",
    "        self.model.add(LSTM(512))\n",
    "        self.model.add(Dense(1, activation = 'sigmoid'))\n",
    "\n",
    "        self.model.compile(optimizer='adam',\n",
    "                    loss='binary_crossentropy',\n",
    "                    metrics=['accuracy'])\n",
    "\n",
    "        # Train model\n",
    "        self.model.fit(self.X_train, self.y_train, epochs=10, batch_size=1, verbose=1)  \n",
    "    \n",
    "    def lstm_op(self):\n",
    "        import math\n",
    "\n",
    "        def objective(trial):\n",
    "            units = trial.suggest_categorical(\"units\", [32, 64, 128, 256])\n",
    "            units2 = units//2\n",
    "            epochs = trial.suggest_categorical(\"epochs\", [10, 20, 30])\n",
    "            batch_size = trial.suggest_categorical(\"batch_size\", [32, 64, 128])\n",
    "            dropout = trial.suggest_float(\"dropout\", low = 0.1, high = 0.5)\n",
    "            \n",
    "            self.model = Sequential()\n",
    "            self.model.add(Embedding(input_dim= self.vocab_len, output_dim= self.embed_vector_len, input_shape = (self.maxlen_per_sent,), trainable=False, embeddings_initializer = initializers.Constant(self.emb_matrix)))\n",
    "            self.model.add(LSTM(units))\n",
    "            self.model.add(Dropout(dropout))\n",
    "            self.model.add(Dense(units2))\n",
    "            self.model.add(Dense(1, activation = 'sigmoid'))\n",
    "\n",
    "            self.model.compile(optimizer='adam',\n",
    "                            loss='binary_crossentropy',\n",
    "                            metrics=['accuracy'])\n",
    "\n",
    "            self.model.fit(self.X_train, self.y_train, epochs= epochs, batch_size= batch_size, verbose=1)  \n",
    "            _, accuracy = self.model.evaluate(self.X_test, self.y_test, verbose=0)\n",
    "\n",
    "            return accuracy\n",
    "\n",
    "        study = optuna.create_study(direction=\"maximize\")\n",
    "        study.optimize(objective, n_trials=10)\n",
    "\n",
    "        self.best_trial = study.best_trial\n",
    "        self.best_params = self.best_trial.params\n",
    "        self.best_accuracy = self.best_trial.value\n",
    "\n",
    "        print(\"Best hyperparameters:\", self.best_params)\n",
    "        print(\"Best accuracy:\", self.best_accuracy)\n",
    "\n",
    "\n",
    "    def predict(self, verbose = False):\n",
    "\n",
    "        loss, accuracy = self.model.evaluate(self.X_test, self.y_test)\n",
    "        print(\"Test Accuracy:\", accuracy)\n",
    "\n",
    "        # Make predictions\n",
    "        predictions = self.model.predict(self.X_test)\n",
    "\n",
    "        y_hat = [1 if i> 0.5 else 0 for i in predictions]\n",
    "\n",
    "        if verbose:\n",
    "            print(\"Classification Report:\")\n",
    "            print(classification_report(self.y_test, y_hat))\n",
    "\n",
    "            print(\"Confusion Matrix:\")\n",
    "            print(confusion_matrix(self.y_test, y_hat))\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dupes removed\n",
      "Tokenizing..\n",
      "Finished Tokenizing\n",
      "Initialising word2vec\n",
      "lemm/stemm\n",
      "Embedding...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 34255/34255 [40:05<00:00, 14.24it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished embedding\n",
      "Padding\n",
      "Finished padding\n",
      "Undersampling..\n",
      "Counter({0: 20477, 1: 5855})\n",
      "Counter({0: 5855, 1: 5855})\n"
     ]
    }
   ],
   "source": [
    "test = Train()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.lstm(nodes = 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 12:44:45,351] A new study created in memory with name: no-name-e0932ef5-cc00-491c-901f-bcbe8274a0ea\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Zoe Lua\\anaconda3\\envs\\spam\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:81: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 533ms/step - accuracy: 0.5694 - loss: 0.6752\n",
      "Epoch 2/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 490ms/step - accuracy: 0.7480 - loss: 0.5578\n",
      "Epoch 3/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 436ms/step - accuracy: 0.8278 - loss: 0.4109\n",
      "Epoch 4/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 440ms/step - accuracy: 0.9262 - loss: 0.2141\n",
      "Epoch 5/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 444ms/step - accuracy: 0.9585 - loss: 0.1441\n",
      "Epoch 6/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 499ms/step - accuracy: 0.9852 - loss: 0.0671\n",
      "Epoch 7/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 457ms/step - accuracy: 0.9918 - loss: 0.0580\n",
      "Epoch 8/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 505ms/step - accuracy: 0.9933 - loss: 0.0390\n",
      "Epoch 9/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 455ms/step - accuracy: 0.9927 - loss: 0.0453\n",
      "Epoch 10/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 456ms/step - accuracy: 0.9493 - loss: 0.2006\n",
      "Epoch 11/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 437ms/step - accuracy: 0.9804 - loss: 0.0657\n",
      "Epoch 12/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 441ms/step - accuracy: 0.9959 - loss: 0.0257\n",
      "Epoch 13/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 439ms/step - accuracy: 0.9961 - loss: 0.0156\n",
      "Epoch 14/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 785ms/step - accuracy: 0.9970 - loss: 0.0168\n",
      "Epoch 15/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 756ms/step - accuracy: 0.9978 - loss: 0.0115\n",
      "Epoch 16/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 765ms/step - accuracy: 0.9941 - loss: 0.0145\n",
      "Epoch 17/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 875ms/step - accuracy: 0.9977 - loss: 0.0108\n",
      "Epoch 18/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 753ms/step - accuracy: 0.9994 - loss: 0.0079\n",
      "Epoch 19/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 470ms/step - accuracy: 0.9979 - loss: 0.0102\n",
      "Epoch 20/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 438ms/step - accuracy: 0.9957 - loss: 0.0142\n",
      "Epoch 21/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 441ms/step - accuracy: 0.9971 - loss: 0.0110\n",
      "Epoch 22/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 442ms/step - accuracy: 0.9982 - loss: 0.0118\n",
      "Epoch 23/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 456ms/step - accuracy: 0.9996 - loss: 0.0041\n",
      "Epoch 24/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 445ms/step - accuracy: 0.9996 - loss: 0.0048\n",
      "Epoch 25/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 438ms/step - accuracy: 0.9994 - loss: 0.0037\n",
      "Epoch 26/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 435ms/step - accuracy: 0.9997 - loss: 0.0039\n",
      "Epoch 27/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 432ms/step - accuracy: 0.9939 - loss: 0.0288\n",
      "Epoch 28/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 444ms/step - accuracy: 0.9971 - loss: 0.0091\n",
      "Epoch 29/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 437ms/step - accuracy: 0.9979 - loss: 0.0096\n",
      "Epoch 30/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 434ms/step - accuracy: 0.9975 - loss: 0.0090\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 12:49:28,276] Trial 0 finished with value: 0.8999999761581421 and parameters: {'units': 32, 'epochs': 30, 'batch_size': 32, 'dropout': 0.45710706363227016}. Best is trial 0 with value: 0.8999999761581421.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 4s/step - accuracy: 0.6011 - loss: 0.6433\n",
      "Epoch 2/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 4s/step - accuracy: 0.7657 - loss: 0.4722\n",
      "Epoch 3/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 5s/step - accuracy: 0.8732 - loss: 0.3590\n",
      "Epoch 4/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 5s/step - accuracy: 0.9533 - loss: 0.1599\n",
      "Epoch 5/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 4s/step - accuracy: 0.9821 - loss: 0.0657\n",
      "Epoch 6/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 5s/step - accuracy: 0.9825 - loss: 0.0541\n",
      "Epoch 7/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 4s/step - accuracy: 0.9913 - loss: 0.0324\n",
      "Epoch 8/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 4s/step - accuracy: 0.9882 - loss: 0.0286\n",
      "Epoch 9/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 4s/step - accuracy: 0.9911 - loss: 0.0376\n",
      "Epoch 10/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 4s/step - accuracy: 0.9900 - loss: 0.0334\n",
      "Epoch 11/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 4s/step - accuracy: 0.9971 - loss: 0.0142\n",
      "Epoch 12/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 5s/step - accuracy: 0.9952 - loss: 0.0169\n",
      "Epoch 13/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 5s/step - accuracy: 0.9968 - loss: 0.0093\n",
      "Epoch 14/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 5s/step - accuracy: 0.9996 - loss: 0.0103\n",
      "Epoch 15/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 5s/step - accuracy: 0.9989 - loss: 0.0157\n",
      "Epoch 16/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 5s/step - accuracy: 0.9989 - loss: 0.0090\n",
      "Epoch 17/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 5s/step - accuracy: 0.9963 - loss: 0.0080\n",
      "Epoch 18/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 5s/step - accuracy: 0.9989 - loss: 0.0076\n",
      "Epoch 19/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 5s/step - accuracy: 0.9969 - loss: 0.0106\n",
      "Epoch 20/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 5s/step - accuracy: 0.9989 - loss: 0.0068\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 13:04:10,054] Trial 1 finished with value: 0.8969696760177612 and parameters: {'units': 256, 'epochs': 20, 'batch_size': 64, 'dropout': 0.302037602800825}. Best is trial 0 with value: 0.8999999761581421.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 771ms/step - accuracy: 0.5310 - loss: 0.6819\n",
      "Epoch 2/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 783ms/step - accuracy: 0.7539 - loss: 0.5161\n",
      "Epoch 3/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 744ms/step - accuracy: 0.8852 - loss: 0.3163\n",
      "Epoch 4/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 763ms/step - accuracy: 0.9786 - loss: 0.0869\n",
      "Epoch 5/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 765ms/step - accuracy: 0.9950 - loss: 0.0457\n",
      "Epoch 6/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 752ms/step - accuracy: 0.9931 - loss: 0.0283\n",
      "Epoch 7/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 774ms/step - accuracy: 0.9901 - loss: 0.0453\n",
      "Epoch 8/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 783ms/step - accuracy: 0.9914 - loss: 0.0245\n",
      "Epoch 9/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 762ms/step - accuracy: 0.9740 - loss: 0.0769\n",
      "Epoch 10/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 774ms/step - accuracy: 0.9932 - loss: 0.0235\n",
      "Epoch 11/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 769ms/step - accuracy: 0.9808 - loss: 0.0478\n",
      "Epoch 12/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 777ms/step - accuracy: 0.9968 - loss: 0.0139\n",
      "Epoch 13/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 775ms/step - accuracy: 0.9983 - loss: 0.0078\n",
      "Epoch 14/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 772ms/step - accuracy: 0.9975 - loss: 0.0106\n",
      "Epoch 15/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 775ms/step - accuracy: 0.9973 - loss: 0.0099\n",
      "Epoch 16/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 770ms/step - accuracy: 0.9965 - loss: 0.0121\n",
      "Epoch 17/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 784ms/step - accuracy: 0.9979 - loss: 0.0095\n",
      "Epoch 18/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 769ms/step - accuracy: 0.9979 - loss: 0.0107\n",
      "Epoch 19/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 767ms/step - accuracy: 0.9939 - loss: 0.0180\n",
      "Epoch 20/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 775ms/step - accuracy: 0.9979 - loss: 0.0103\n",
      "Epoch 21/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 781ms/step - accuracy: 0.9994 - loss: 0.0038\n",
      "Epoch 22/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 780ms/step - accuracy: 0.9996 - loss: 0.0028\n",
      "Epoch 23/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 769ms/step - accuracy: 0.9957 - loss: 0.0114\n",
      "Epoch 24/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 765ms/step - accuracy: 0.9957 - loss: 0.0128\n",
      "Epoch 25/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 779ms/step - accuracy: 0.9965 - loss: 0.0123\n",
      "Epoch 26/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 793ms/step - accuracy: 0.9986 - loss: 0.0062\n",
      "Epoch 27/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 779ms/step - accuracy: 0.9988 - loss: 0.0056\n",
      "Epoch 28/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 771ms/step - accuracy: 0.9992 - loss: 0.0041\n",
      "Epoch 29/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 765ms/step - accuracy: 0.9996 - loss: 0.0033\n",
      "Epoch 30/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 739ms/step - accuracy: 0.9992 - loss: 0.0042\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 13:11:23,671] Trial 2 finished with value: 0.9121212363243103 and parameters: {'units': 32, 'epochs': 30, 'batch_size': 32, 'dropout': 0.23063450739749547}. Best is trial 2 with value: 0.9121212363243103.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 1s/step - accuracy: 0.5998 - loss: 0.6735\n",
      "Epoch 2/30\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1s/step - accuracy: 0.7410 - loss: 0.5918\n",
      "Epoch 3/30\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1s/step - accuracy: 0.8106 - loss: 0.4824\n",
      "Epoch 4/30\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1s/step - accuracy: 0.8284 - loss: 0.3896\n",
      "Epoch 5/30\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1s/step - accuracy: 0.9488 - loss: 0.2191\n",
      "Epoch 6/30\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 914ms/step - accuracy: 0.9778 - loss: 0.0892\n",
      "Epoch 7/30\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 664ms/step - accuracy: 0.9499 - loss: 0.1461\n",
      "Epoch 8/30\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 593ms/step - accuracy: 0.9694 - loss: 0.1061\n",
      "Epoch 9/30\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 551ms/step - accuracy: 0.9848 - loss: 0.0665\n",
      "Epoch 10/30\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 544ms/step - accuracy: 0.9900 - loss: 0.0479\n",
      "Epoch 11/30\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 578ms/step - accuracy: 0.9909 - loss: 0.0397\n",
      "Epoch 12/30\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 573ms/step - accuracy: 0.9948 - loss: 0.0284\n",
      "Epoch 13/30\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 579ms/step - accuracy: 0.9975 - loss: 0.0165\n",
      "Epoch 14/30\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 558ms/step - accuracy: 0.9946 - loss: 0.0232\n",
      "Epoch 15/30\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 543ms/step - accuracy: 0.9943 - loss: 0.0257\n",
      "Epoch 16/30\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 534ms/step - accuracy: 0.9969 - loss: 0.0186\n",
      "Epoch 17/30\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 556ms/step - accuracy: 0.9967 - loss: 0.0137\n",
      "Epoch 18/30\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 536ms/step - accuracy: 0.9963 - loss: 0.0170\n",
      "Epoch 19/30\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 534ms/step - accuracy: 0.9966 - loss: 0.0151\n",
      "Epoch 20/30\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 547ms/step - accuracy: 0.9964 - loss: 0.0117\n",
      "Epoch 21/30\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 541ms/step - accuracy: 0.9961 - loss: 0.0158\n",
      "Epoch 22/30\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 539ms/step - accuracy: 0.9931 - loss: 0.0135\n",
      "Epoch 23/30\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 533ms/step - accuracy: 0.9982 - loss: 0.0104\n",
      "Epoch 24/30\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 531ms/step - accuracy: 0.9954 - loss: 0.0163\n",
      "Epoch 25/30\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 540ms/step - accuracy: 0.9992 - loss: 0.0070\n",
      "Epoch 26/30\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 542ms/step - accuracy: 0.9972 - loss: 0.0091\n",
      "Epoch 27/30\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 532ms/step - accuracy: 0.9992 - loss: 0.0062\n",
      "Epoch 28/30\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 531ms/step - accuracy: 0.9977 - loss: 0.0104\n",
      "Epoch 29/30\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 538ms/step - accuracy: 0.9969 - loss: 0.0104\n",
      "Epoch 30/30\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 539ms/step - accuracy: 0.9994 - loss: 0.0051\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 13:14:45,026] Trial 3 finished with value: 0.9212121367454529 and parameters: {'units': 32, 'epochs': 30, 'batch_size': 64, 'dropout': 0.37470173407962626}. Best is trial 3 with value: 0.9212121367454529.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 514ms/step - accuracy: 0.5210 - loss: 0.6535\n",
      "Epoch 2/20\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 523ms/step - accuracy: 0.7907 - loss: 0.4474\n",
      "Epoch 3/20\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 513ms/step - accuracy: 0.9241 - loss: 0.2331\n",
      "Epoch 4/20\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 513ms/step - accuracy: 0.9538 - loss: 0.1442\n",
      "Epoch 5/20\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 507ms/step - accuracy: 0.9762 - loss: 0.0730\n",
      "Epoch 6/20\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 523ms/step - accuracy: 0.9898 - loss: 0.0410\n",
      "Epoch 7/20\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 526ms/step - accuracy: 0.9912 - loss: 0.0412\n",
      "Epoch 8/20\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 523ms/step - accuracy: 0.9967 - loss: 0.0105\n",
      "Epoch 9/20\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 532ms/step - accuracy: 0.9930 - loss: 0.0184\n",
      "Epoch 10/20\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 521ms/step - accuracy: 0.9973 - loss: 0.0119\n",
      "Epoch 11/20\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 516ms/step - accuracy: 0.9965 - loss: 0.0102\n",
      "Epoch 12/20\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 526ms/step - accuracy: 0.9994 - loss: 0.0086\n",
      "Epoch 13/20\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 532ms/step - accuracy: 0.9988 - loss: 0.0083\n",
      "Epoch 14/20\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 517ms/step - accuracy: 0.9997 - loss: 0.0037\n",
      "Epoch 15/20\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 527ms/step - accuracy: 0.9979 - loss: 0.0065\n",
      "Epoch 16/20\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 521ms/step - accuracy: 0.9982 - loss: 0.0042\n",
      "Epoch 17/20\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 518ms/step - accuracy: 0.9965 - loss: 0.0142\n",
      "Epoch 18/20\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 526ms/step - accuracy: 0.9994 - loss: 0.0034\n",
      "Epoch 19/20\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 516ms/step - accuracy: 0.9990 - loss: 0.0053\n",
      "Epoch 20/20\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 520ms/step - accuracy: 0.9986 - loss: 0.0061\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 13:17:50,325] Trial 4 finished with value: 0.918181836605072 and parameters: {'units': 128, 'epochs': 20, 'batch_size': 32, 'dropout': 0.4636636128186612}. Best is trial 3 with value: 0.9212121367454529.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 2s/step - accuracy: 0.6705 - loss: 0.6103\n",
      "Epoch 2/10\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 2s/step - accuracy: 0.8987 - loss: 0.2539\n",
      "Epoch 3/10\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 2s/step - accuracy: 0.9415 - loss: 0.1886\n",
      "Epoch 4/10\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 2s/step - accuracy: 0.9773 - loss: 0.0803\n",
      "Epoch 5/10\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 2s/step - accuracy: 0.9462 - loss: 0.1073\n",
      "Epoch 6/10\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 2s/step - accuracy: 0.9909 - loss: 0.0360\n",
      "Epoch 7/10\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 2s/step - accuracy: 0.9937 - loss: 0.0333\n",
      "Epoch 8/10\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 2s/step - accuracy: 0.9894 - loss: 0.0240\n",
      "Epoch 9/10\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 2s/step - accuracy: 0.9965 - loss: 0.0129\n",
      "Epoch 10/10\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 2s/step - accuracy: 0.9996 - loss: 0.0051\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 13:24:03,194] Trial 5 finished with value: 0.9090909361839294 and parameters: {'units': 256, 'epochs': 10, 'batch_size': 32, 'dropout': 0.2626514870278893}. Best is trial 3 with value: 0.9212121367454529.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 347ms/step - accuracy: 0.6471 - loss: 0.6277\n",
      "Epoch 2/20\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 346ms/step - accuracy: 0.8003 - loss: 0.4225\n",
      "Epoch 3/20\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 349ms/step - accuracy: 0.9415 - loss: 0.1761\n",
      "Epoch 4/20\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 345ms/step - accuracy: 0.9595 - loss: 0.1213\n",
      "Epoch 5/20\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 354ms/step - accuracy: 0.9958 - loss: 0.0412\n",
      "Epoch 6/20\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 348ms/step - accuracy: 0.9936 - loss: 0.0351\n",
      "Epoch 7/20\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 346ms/step - accuracy: 0.9957 - loss: 0.0250\n",
      "Epoch 8/20\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 350ms/step - accuracy: 0.9725 - loss: 0.0812\n",
      "Epoch 9/20\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 346ms/step - accuracy: 0.9925 - loss: 0.0370\n",
      "Epoch 10/20\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 345ms/step - accuracy: 0.9902 - loss: 0.0237\n",
      "Epoch 11/20\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 347ms/step - accuracy: 0.9985 - loss: 0.0109\n",
      "Epoch 12/20\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 344ms/step - accuracy: 0.9964 - loss: 0.0108\n",
      "Epoch 13/20\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 350ms/step - accuracy: 0.9965 - loss: 0.0120\n",
      "Epoch 14/20\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 345ms/step - accuracy: 0.9971 - loss: 0.0124\n",
      "Epoch 15/20\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 347ms/step - accuracy: 0.9975 - loss: 0.0109\n",
      "Epoch 16/20\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 355ms/step - accuracy: 0.9984 - loss: 0.0094\n",
      "Epoch 17/20\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 347ms/step - accuracy: 0.9996 - loss: 0.0044\n",
      "Epoch 18/20\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 350ms/step - accuracy: 0.9994 - loss: 0.0052\n",
      "Epoch 19/20\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 345ms/step - accuracy: 0.9996 - loss: 0.0055\n",
      "Epoch 20/20\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 345ms/step - accuracy: 0.9990 - loss: 0.0061\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 13:26:07,411] Trial 6 finished with value: 0.9212121367454529 and parameters: {'units': 32, 'epochs': 20, 'batch_size': 32, 'dropout': 0.22297123095543092}. Best is trial 3 with value: 0.9212121367454529.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 1s/step - accuracy: 0.6338 - loss: 0.6378\n",
      "Epoch 2/30\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 1s/step - accuracy: 0.7650 - loss: 0.4482\n",
      "Epoch 3/30\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 1s/step - accuracy: 0.9092 - loss: 0.2435\n",
      "Epoch 4/30\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - accuracy: 0.9603 - loss: 0.1436\n",
      "Epoch 5/30\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 1s/step - accuracy: 0.9887 - loss: 0.0701\n",
      "Epoch 6/30\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 2s/step - accuracy: 0.9926 - loss: 0.0376\n",
      "Epoch 7/30\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 1s/step - accuracy: 0.9897 - loss: 0.0402\n",
      "Epoch 8/30\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 1s/step - accuracy: 0.9899 - loss: 0.0391\n",
      "Epoch 9/30\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - accuracy: 0.9919 - loss: 0.0347\n",
      "Epoch 10/30\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 1s/step - accuracy: 0.9873 - loss: 0.0416\n",
      "Epoch 11/30\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 1s/step - accuracy: 0.9855 - loss: 0.0408\n",
      "Epoch 12/30\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 1s/step - accuracy: 0.9953 - loss: 0.0230\n",
      "Epoch 13/30\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - accuracy: 0.9854 - loss: 0.0423\n",
      "Epoch 14/30\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 1s/step - accuracy: 0.9954 - loss: 0.0264\n",
      "Epoch 15/30\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 1s/step - accuracy: 0.9974 - loss: 0.0114\n",
      "Epoch 16/30\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 1s/step - accuracy: 0.9958 - loss: 0.0181\n",
      "Epoch 17/30\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 1s/step - accuracy: 0.9986 - loss: 0.0143\n",
      "Epoch 18/30\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 1s/step - accuracy: 0.9971 - loss: 0.0182\n",
      "Epoch 19/30\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 1s/step - accuracy: 0.9989 - loss: 0.0093\n",
      "Epoch 20/30\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 1s/step - accuracy: 0.9977 - loss: 0.0122\n",
      "Epoch 21/30\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 1s/step - accuracy: 0.9982 - loss: 0.0081\n",
      "Epoch 22/30\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - accuracy: 0.9969 - loss: 0.0130\n",
      "Epoch 23/30\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 1s/step - accuracy: 0.9989 - loss: 0.0066\n",
      "Epoch 24/30\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 1s/step - accuracy: 0.9982 - loss: 0.0065\n",
      "Epoch 25/30\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 1s/step - accuracy: 0.9969 - loss: 0.0137\n",
      "Epoch 26/30\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 1s/step - accuracy: 0.9954 - loss: 0.0142\n",
      "Epoch 27/30\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - accuracy: 0.9986 - loss: 0.0081\n",
      "Epoch 28/30\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 1s/step - accuracy: 0.9977 - loss: 0.0068\n",
      "Epoch 29/30\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 1s/step - accuracy: 0.9954 - loss: 0.0153\n",
      "Epoch 30/30\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 1s/step - accuracy: 0.9954 - loss: 0.0108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 13:33:02,756] Trial 7 finished with value: 0.9060605764389038 and parameters: {'units': 128, 'epochs': 30, 'batch_size': 64, 'dropout': 0.43324029512447715}. Best is trial 3 with value: 0.9212121367454529.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 1s/step - accuracy: 0.6538 - loss: 0.6424\n",
      "Epoch 2/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 1s/step - accuracy: 0.7758 - loss: 0.4610\n",
      "Epoch 3/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 1s/step - accuracy: 0.8597 - loss: 0.3473\n",
      "Epoch 4/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 1s/step - accuracy: 0.9218 - loss: 0.1865\n",
      "Epoch 5/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 1s/step - accuracy: 0.9835 - loss: 0.0712\n",
      "Epoch 6/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 1s/step - accuracy: 0.9876 - loss: 0.0516\n",
      "Epoch 7/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 1s/step - accuracy: 0.9925 - loss: 0.0265\n",
      "Epoch 8/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 1s/step - accuracy: 0.9897 - loss: 0.0438\n",
      "Epoch 9/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 1s/step - accuracy: 0.9926 - loss: 0.0309\n",
      "Epoch 10/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 1s/step - accuracy: 0.9963 - loss: 0.0130\n",
      "Epoch 11/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 1s/step - accuracy: 0.9894 - loss: 0.0280\n",
      "Epoch 12/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 1s/step - accuracy: 0.9936 - loss: 0.0206\n",
      "Epoch 13/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 1s/step - accuracy: 0.9981 - loss: 0.0062\n",
      "Epoch 14/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 1s/step - accuracy: 0.9992 - loss: 0.0064\n",
      "Epoch 15/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 1s/step - accuracy: 0.9982 - loss: 0.0115\n",
      "Epoch 16/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 1s/step - accuracy: 0.9982 - loss: 0.0098\n",
      "Epoch 17/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 1s/step - accuracy: 0.9977 - loss: 0.0098\n",
      "Epoch 18/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 1s/step - accuracy: 0.9969 - loss: 0.0115\n",
      "Epoch 19/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - accuracy: 0.9954 - loss: 0.0160\n",
      "Epoch 20/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 1s/step - accuracy: 0.9954 - loss: 0.0159\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 13:37:38,891] Trial 8 finished with value: 0.9060605764389038 and parameters: {'units': 128, 'epochs': 20, 'batch_size': 64, 'dropout': 0.21696542515471423}. Best is trial 3 with value: 0.9212121367454529.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1s/step - accuracy: 0.5689 - loss: 0.6744\n",
      "Epoch 2/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1s/step - accuracy: 0.7092 - loss: 0.5973\n",
      "Epoch 3/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1s/step - accuracy: 0.7410 - loss: 0.5295\n",
      "Epoch 4/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1s/step - accuracy: 0.8207 - loss: 0.4035\n",
      "Epoch 5/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1s/step - accuracy: 0.8543 - loss: 0.3219\n",
      "Epoch 6/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1s/step - accuracy: 0.9454 - loss: 0.1774\n",
      "Epoch 7/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1s/step - accuracy: 0.9650 - loss: 0.1165\n",
      "Epoch 8/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1s/step - accuracy: 0.9609 - loss: 0.0987\n",
      "Epoch 9/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1s/step - accuracy: 0.9883 - loss: 0.0555\n",
      "Epoch 10/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1s/step - accuracy: 0.9881 - loss: 0.0427\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-01 13:38:55,218] Trial 9 finished with value: 0.9151515364646912 and parameters: {'units': 64, 'epochs': 10, 'batch_size': 128, 'dropout': 0.31431720536965646}. Best is trial 3 with value: 0.9212121367454529.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'units': 32, 'epochs': 30, 'batch_size': 64, 'dropout': 0.37470173407962626}\n",
      "Best accuracy: 0.9212121367454529\n"
     ]
    }
   ],
   "source": [
    "test.lstm_op()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spam",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
