{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "NVIDIA GeForce RTX 3080\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from datasets import Dataset, load_dataset\n",
    "print(torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    print(torch.cuda.get_device_name())\n",
    "    print(torch.cuda.current_device())\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import BertTokenizerFast, DataCollatorWithPadding, AutoModelForSequenceClassification, TrainingArguments, Trainer, pipeline\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from tqdm import tqdm\n",
    "import evaluate\n",
    "import random\n",
    "import heapq\n",
    "path = '/app/Data/'\n",
    "model_path = 'google-bert/bert-base-uncased'\n",
    "tokenizer = BertTokenizerFast.from_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "arrow_file_name = \"data-00000-of-00001\"\n",
    "def load_data(path,tokenized=False):\n",
    "    if tokenized:\n",
    "        full_ds = load_dataset('arrow',data_files={\n",
    "            'train':path+f'/tokenized/train_ds/{arrow_file_name}.arrow',\n",
    "            'test':path+f'/tokenized/test_ds/{arrow_file_name}.arrow',\n",
    "            'val':path+f'/tokenized/val_ds/{arrow_file_name}.arrow'\n",
    "        })\n",
    "    else:\n",
    "        full_ds = load_dataset('arrow',data_files={\n",
    "            'train':path+f'/train_ds/{arrow_file_name}.arrow',\n",
    "            'test':path+f'/test_ds/{arrow_file_name}.arrow',\n",
    "            'validation':path+f'/val_ds/{arrow_file_name}.arrow'\n",
    "        })\n",
    "    return full_ds\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train-Val-Test split, run only once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_function(id,example):\n",
    "    text = example['processed']\n",
    "    label = example['class']\n",
    "    tokens = tokenizer.encode(text)\n",
    "    out = []\n",
    "    if len(tokens) <= 512:\n",
    "        out.append([tokens,label,id])\n",
    "        return out\n",
    "    else:\n",
    "        cls_token = tokens[0]\n",
    "        sep_token = tokens[-1]\n",
    "        tokens = tokens[1:-1] # remove CLS and SEP tokens\n",
    "        chunks = [tokens[i:i+500] for i in range(0,len(tokens),500)]\n",
    "        for c in chunks: # add back CLS and SEP tokens\n",
    "            c.insert(0,cls_token)\n",
    "            c.append(sep_token)\n",
    "            out.append([c,label,id])\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shorten(text):\n",
    "    words = text.split(\" \")\n",
    "    curr = None\n",
    "    final = []\n",
    "    for word in words:\n",
    "        if word != curr:\n",
    "            final.append(word)\n",
    "        curr = word\n",
    "    return \" \".join(final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_function_2(id,example):\n",
    "    text = example['processed']\n",
    "    text = shorten(text)\n",
    "    label = example['class']\n",
    "    tokens = tokenizer.encode(text)\n",
    "    cls_token = tokens[0]\n",
    "    sep_token = tokens[-1]\n",
    "    first_chunk = tokens[1: 511]\n",
    "    c = []\n",
    "    c.append(cls_token)\n",
    "    c.extend(first_chunk)\n",
    "    c.append(sep_token)\n",
    "    return([c, label, id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(df):\n",
    "    new_df = {'text':[],'label':[],'raw_text':[]}\n",
    "    ids = []\n",
    "    mapping = {\"ham\":0,\"spam\":1}\n",
    "    for i,row in tqdm(df.iterrows()):\n",
    "        new_df[\"raw_text\"].append(row['processed'])\n",
    "        tokens, label, idx = preprocess_function_2(i,row)\n",
    "        new_df['text'].append(tokens)\n",
    "        new_df['label'].append(mapping[label])\n",
    "        ids.append(idx)\n",
    "    final_df = pd.DataFrame(new_df,index=ids)\n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (574 > 512). Running this sequence through the model will result in indexing errors\n",
      "26078it [00:35, 744.49it/s]\n",
      "6520it [00:09, 680.85it/s]\n",
      "8150it [00:11, 694.33it/s]\n"
     ]
    }
   ],
   "source": [
    "seed = random.seed(37)\n",
    "df = pd.read_pickle(\"/app/Data/full_df.pkl\")\n",
    "df = df.drop_duplicates(subset=['processed'])\n",
    "X = df['processed']\n",
    "y = df['class']\n",
    "X_tr, X_test, y_tr, y_test = train_test_split(X,y,test_size=0.2)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_tr,y_tr,test_size=0.2)\n",
    "train_df = pd.DataFrame({'processed':X_train,'class':y_train})\n",
    "val_df = pd.DataFrame({'processed':X_val,'class':y_val})\n",
    "test_df = pd.DataFrame({'processed':X_test,'class':y_test})\n",
    "train_df = preprocess(train_df)\n",
    "val_df = preprocess(val_df)\n",
    "test_df = preprocess(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = list(df.processed)\n",
    "ids = df.index\n",
    "model = SentenceTransformer('sentence-transformers/all-mpnet-base-v2', device=torch.cuda.current_device())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = model.encode(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_df = pd.DataFrame({\"embedding\": [embeddings[i] for i in range(len(ids))]}, index=list(ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_df.to_pickle(\"/app/Data/embedding.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_df = pd.read_pickle(\"/app/Data/embedding.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "if torch.cuda.is_available():\n",
    "    jax_device = jax.devices(\"gpu\")[0]\n",
    "else:\n",
    "    jax_device = jax.devices(\"cpu\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_sim(x,y):\n",
    "    '''\n",
    "    Computes cosine similarity between b and each row of a\n",
    "    x: 2d np vector\n",
    "    y: 1d np vector\n",
    "    '''\n",
    "    dot_product = jnp.dot(x, y)\n",
    "    \n",
    "    # Compute the magnitudes of x and y\n",
    "    x_norm = jnp.linalg.norm(x)\n",
    "    y_norm = jnp.linalg.norm(y)\n",
    "    \n",
    "    # Compute the cosine similarity\n",
    "    similarity = dot_product / (x_norm * y_norm)\n",
    "    \n",
    "    return similarity\n",
    "cosine_sim_jit = jax.jit(device=jax_device, fun=cosine_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Post(object):\n",
    "    def __init__(self, embedding, pos):\n",
    "        self.embedding = embedding\n",
    "        self.closest_dst = -1 # Cosine similarity is a value from -1 to 1, with similar posts having value close to 1\n",
    "        self.pos = pos # Position in self.posts\n",
    "\n",
    "    def __lt__(self, other):\n",
    "        return self.closest_dst < other.closest_dst\n",
    "\n",
    "class Undersample:\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "        self.post_ids = list(df.index)\n",
    "        self.distances = jnp.array([-1] * len(self.post_ids))\n",
    "        self.embeddings = np.row_stack(list(df.embedding))\n",
    "        self.embeddings = jax.device_put(jnp.array(self.embeddings), device=jax_device)\n",
    "        self.selected_ids = []\n",
    "        self.recent = None\n",
    "    \n",
    "    def select_furthest(self):\n",
    "        if len(self.selected_ids) == 0:\n",
    "            # Pick random starting point\n",
    "            recent_pos = random.randint(0, len(self.post_ids)-1)\n",
    "            self.selected_ids.append(self.post_ids[recent_pos])\n",
    "            self.recent = self.embeddings[recent_pos]\n",
    "            return \n",
    "        dist_to_recent = cosine_sim_jit(self.embeddings, self.recent)\n",
    "        self.distances = jnp.maximum(self.distances, dist_to_recent)\n",
    "        recent_pos = jnp.argmin(self.distances)\n",
    "        self.selected_ids.append(self.post_ids[recent_pos])\n",
    "        self.recent = self.embeddings[recent_pos]\n",
    "        return\n",
    "\n",
    "    def select_n(self, n):\n",
    "        if n>len(self.post_ids):\n",
    "            return self.df\n",
    "        for i in tqdm(range(n)):\n",
    "            self.select_furthest()\n",
    "        return self.df[self.df.index.isin(self.selected_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>raw_text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19745</td>\n",
       "      <td>19745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6333</td>\n",
       "      <td>6333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        text  raw_text\n",
       "label                 \n",
       "0      19745     19745\n",
       "1       6333      6333"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_spam = train_df[train_df.label==1].copy()\n",
    "train_ham = train_df[train_df.label==0].copy()\n",
    "train_ham_embed = pd.merge(train_ham, embedding_df, left_index=True, right_index=True)\n",
    "train_df.groupby([\"label\"]).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6333/6333 [00:18<00:00, 340.94it/s]\n"
     ]
    }
   ],
   "source": [
    "undersampler = Undersample(train_ham_embed)\n",
    "train_ham_sampled = undersampler.select_n(len(train_spam))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_new = pd.concat([train_spam[[\"text\", \"label\"]], train_ham_sampled[[\"text\", \"label\"]]])\n",
    "val_df = val_df[[\"text\", \"label\"]]\n",
    "test_df = test_df[[\"text\", \"label\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|██████████| 12666/12666 [00:00<00:00, 333143.46 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 8150/8150 [00:00<00:00, 295279.12 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 6520/6520 [00:00<00:00, 263457.25 examples/s]\n"
     ]
    }
   ],
   "source": [
    "train_ds = Dataset.from_pandas(train_new,split='train')\n",
    "val_ds = Dataset.from_pandas(val_df,split='validation')\n",
    "test_ds = Dataset.from_pandas(test_df,split='test')\n",
    "train_ds.save_to_disk(path+'/train_ds')\n",
    "test_ds.save_to_disk(path+'/test_ds')\n",
    "val_ds.save_to_disk(path+'/val_ds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 12666 examples [00:00, 339743.77 examples/s]\n",
      "Generating test split: 8150 examples [00:00, 378082.55 examples/s]\n",
      "Generating validation split: 6520 examples [00:00, 334792.58 examples/s]\n"
     ]
    }
   ],
   "source": [
    "ds = load_data(path)\n",
    "train_ds = ds['train']\n",
    "test_ds = ds['test']\n",
    "val_ds = ds['validation']\n",
    "train_ds = train_ds.remove_columns(['__index_level_0__'])\n",
    "test_ds = test_ds.remove_columns(['__index_level_0__'])\n",
    "val_ds = val_ds.remove_columns(['__index_level_0__'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoding of tokens and getting attention maps via BERT Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_and_tokenize_function(example):\n",
    "    tokens = example['text']\n",
    "    text = tokenizer.decode(tokens,skip_special_tokens=True)\n",
    "    return tokenizer(text,padding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 12666/12666 [00:28<00:00, 440.51 examples/s]\n",
      "Map: 100%|██████████| 8150/8150 [00:19<00:00, 417.80 examples/s]\n",
      "Map: 100%|██████████| 6520/6520 [00:15<00:00, 413.05 examples/s]\n"
     ]
    }
   ],
   "source": [
    "tokenized_train_ds = train_ds.map(decode_and_tokenize_function)\n",
    "tokenized_test_ds = test_ds.map(decode_and_tokenize_function)\n",
    "tokenized_val_ds = val_ds.map(decode_and_tokenize_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|██████████| 12666/12666 [00:00<00:00, 100646.51 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 6520/6520 [00:00<00:00, 172687.94 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 8150/8150 [00:00<00:00, 151182.52 examples/s]\n"
     ]
    }
   ],
   "source": [
    "tokenized_train_ds.save_to_disk(path+'/tokenized/train_ds')\n",
    "tokenized_val_ds.save_to_disk(path+'/tokenized/val_ds')\n",
    "tokenized_test_ds.save_to_disk(path+'/tokenized/test_ds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Init Evaluation metrics, Data Collator and Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7ecf9ba7da740da8edf1172a4320b20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52fb2fd537474384b8546d5fcbac3e7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "177eed1cc707489e845bcd18101be3ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d5803d6f296436b8baf1b5928a070fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7441f763180a4552b11f8fef5c6cecb8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating val split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_ds = load_data(path,tokenized=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'label', 'raw_text', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "    num_rows: 12742\n",
       "})"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_ds['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google-bert/bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "accuracy = evaluate.load('accuracy')\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    return accuracy.compute(predictions=predictions, references=labels)\n",
    "\n",
    "id2label = {\n",
    "    0:\"ham\",\n",
    "    1:\"spam\",\n",
    "}\n",
    "\n",
    "label2id = {\n",
    "    \"ham\":0,\n",
    "    \"spam\":1,\n",
    "}\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_path,\n",
    "    num_labels=2,\n",
    "    id2label=id2label,\n",
    "    label2id=label2id,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"model_checkpoints\",\n",
    "    overwrite_output_dir=True,\n",
    "    learning_rate=2e-5,\n",
    "    optim=\"adamw_bnb_8bit\",\n",
    "    gradient_accumulation_steps=2,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=4,\n",
    "    weight_decay=0.01,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    push_to_hub=False,\n",
    "    metric_for_best_model=\"eval_loss\",\n",
    "    logging_steps=200,\n",
    "    save_steps=200,\n",
    "    eval_steps=200,\n",
    "    save_total_limit=5,\n",
    "    load_best_model_at_end=True\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_ds[\"train\"],\n",
    "    eval_dataset=tokenized_ds[\"val\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "acd92f57882c42e79f4ac6ee005e326a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3184 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1321, 'grad_norm': 0.1225442886352539, 'learning_rate': 1.8743718592964826e-05, 'epoch': 0.25}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43f8b7f035bf4ddeacfbac3a68b1fe24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/815 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.11306805908679962, 'eval_accuracy': 0.9664110429447853, 'eval_runtime': 55.3295, 'eval_samples_per_second': 117.84, 'eval_steps_per_second': 14.73, 'epoch': 0.25}\n",
      "{'loss': 0.1236, 'grad_norm': 9.54425048828125, 'learning_rate': 1.748743718592965e-05, 'epoch': 0.5}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9615f5724ece4d05afc90dcee4d0e82c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/815 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.0986725389957428, 'eval_accuracy': 0.975, 'eval_runtime': 56.1346, 'eval_samples_per_second': 116.149, 'eval_steps_per_second': 14.519, 'epoch': 0.5}\n",
      "{'loss': 0.083, 'grad_norm': 26.82895278930664, 'learning_rate': 1.6231155778894474e-05, 'epoch': 0.75}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "913b0af89be24295b11f08fc0d738fb5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/815 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.087204709649086, 'eval_accuracy': 0.9780674846625766, 'eval_runtime': 53.7326, 'eval_samples_per_second': 121.342, 'eval_steps_per_second': 15.168, 'epoch': 0.75}\n",
      "{'loss': 0.078, 'grad_norm': 0.3467020094394684, 'learning_rate': 1.4974874371859299e-05, 'epoch': 1.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3903999c76641a78cd9038305b95998",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/815 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.11468417942523956, 'eval_accuracy': 0.9739263803680982, 'eval_runtime': 53.6444, 'eval_samples_per_second': 121.541, 'eval_steps_per_second': 15.193, 'epoch': 1.0}\n",
      "{'loss': 0.0358, 'grad_norm': 0.015922775492072105, 'learning_rate': 1.3718592964824123e-05, 'epoch': 1.26}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae887c816b8b4243899bc43cd7a8a9b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/815 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.09464883804321289, 'eval_accuracy': 0.9799079754601226, 'eval_runtime': 53.6889, 'eval_samples_per_second': 121.44, 'eval_steps_per_second': 15.18, 'epoch': 1.26}\n",
      "{'loss': 0.0354, 'grad_norm': 0.013116507790982723, 'learning_rate': 1.2462311557788947e-05, 'epoch': 1.51}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e7dea18c23c49b7b79ca43a75a0da5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/815 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.0857028067111969, 'eval_accuracy': 0.9825153374233129, 'eval_runtime': 53.6629, 'eval_samples_per_second': 121.499, 'eval_steps_per_second': 15.187, 'epoch': 1.51}\n",
      "{'loss': 0.041, 'grad_norm': 0.05498252436518669, 'learning_rate': 1.120603015075377e-05, 'epoch': 1.76}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de93b64b8e9e4cd484dc5ec6bfae40e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/815 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.09343696385622025, 'eval_accuracy': 0.9809815950920245, 'eval_runtime': 53.6121, 'eval_samples_per_second': 121.614, 'eval_steps_per_second': 15.202, 'epoch': 1.76}\n",
      "{'loss': 0.0334, 'grad_norm': 0.018323533236980438, 'learning_rate': 9.949748743718594e-06, 'epoch': 2.01}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f5807000258488c97ba78940dd9e81d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/815 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.08328451216220856, 'eval_accuracy': 0.9831288343558282, 'eval_runtime': 53.6436, 'eval_samples_per_second': 121.543, 'eval_steps_per_second': 15.193, 'epoch': 2.01}\n",
      "{'loss': 0.0156, 'grad_norm': 0.008698437362909317, 'learning_rate': 8.693467336683418e-06, 'epoch': 2.26}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89f74ffa1c5246aa8e2afe1471b45c0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/815 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.08576551824808121, 'eval_accuracy': 0.9837423312883435, 'eval_runtime': 53.6895, 'eval_samples_per_second': 121.439, 'eval_steps_per_second': 15.18, 'epoch': 2.26}\n",
      "{'loss': 0.0132, 'grad_norm': 0.005109351594001055, 'learning_rate': 7.437185929648242e-06, 'epoch': 2.51}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4e7a5732fa44521a9a8ef1303b3511a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/815 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.09594490379095078, 'eval_accuracy': 0.9823619631901841, 'eval_runtime': 53.5878, 'eval_samples_per_second': 121.669, 'eval_steps_per_second': 15.209, 'epoch': 2.51}\n",
      "{'loss': 0.0141, 'grad_norm': 0.7692071795463562, 'learning_rate': 6.180904522613066e-06, 'epoch': 2.76}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14f52209098f4b2fb5dde84085f374b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/815 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.09207481890916824, 'eval_accuracy': 0.9829754601226994, 'eval_runtime': 53.6439, 'eval_samples_per_second': 121.542, 'eval_steps_per_second': 15.193, 'epoch': 2.76}\n",
      "{'loss': 0.0136, 'grad_norm': 0.0072205448523163795, 'learning_rate': 4.92462311557789e-06, 'epoch': 3.01}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbcd5a7071df40ce9bf17e7833b1e958",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/815 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.10394727438688278, 'eval_accuracy': 0.9812883435582822, 'eval_runtime': 53.6334, 'eval_samples_per_second': 121.566, 'eval_steps_per_second': 15.196, 'epoch': 3.01}\n",
      "{'loss': 0.0057, 'grad_norm': 1.2677863836288452, 'learning_rate': 3.6683417085427137e-06, 'epoch': 3.26}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2aed44bcf0a4be0ae4502a8d312b5d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/815 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.09566265344619751, 'eval_accuracy': 0.9835889570552148, 'eval_runtime': 53.7206, 'eval_samples_per_second': 121.369, 'eval_steps_per_second': 15.171, 'epoch': 3.26}\n",
      "{'loss': 0.0028, 'grad_norm': 0.001682559261098504, 'learning_rate': 2.412060301507538e-06, 'epoch': 3.52}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1424247648b420d896337d502bab3bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/815 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.09360352158546448, 'eval_accuracy': 0.9842024539877301, 'eval_runtime': 53.6615, 'eval_samples_per_second': 121.502, 'eval_steps_per_second': 15.188, 'epoch': 3.52}\n",
      "{'loss': 0.0031, 'grad_norm': 0.001572438981384039, 'learning_rate': 1.155778894472362e-06, 'epoch': 3.77}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d5b27936c284a46955a7d8a6b7c6cad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/815 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.1002873033285141, 'eval_accuracy': 0.9845092024539878, 'eval_runtime': 53.6078, 'eval_samples_per_second': 121.624, 'eval_steps_per_second': 15.203, 'epoch': 3.77}\n",
      "{'train_runtime': 2079.8779, 'train_samples_per_second': 24.505, 'train_steps_per_second': 1.531, 'train_loss': 0.03964742737349553, 'epoch': 4.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=3184, training_loss=0.03964742737349553, metrics={'train_runtime': 2079.8779, 'train_samples_per_second': 24.505, 'train_steps_per_second': 1.531, 'train_loss': 0.03964742737349553, 'epoch': 4.0})"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7551e0b193ee437e81e66ee211036695",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/815 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "eval_results = trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.08328451216220856,\n",
       " 'eval_accuracy': 0.9831288343558282,\n",
       " 'eval_runtime': 55.2077,\n",
       " 'eval_samples_per_second': 118.099,\n",
       " 'eval_steps_per_second': 14.762,\n",
       " 'epoch': 4.0}"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model(\"models/bert_model5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_ds = load_data(path,tokenized=True)\n",
    "tokenized_test_ds = tokenized_ds['test']\n",
    "classifier = pipeline('text-classification',model='models/bert_model5', device=torch.cuda.current_device())\n",
    "def decode_tokens(example):\n",
    "    tokens = example['text']\n",
    "    # label_map = {0:\"ham\",1:\"spam\"}\n",
    "    text = tokenizer.decode(tokens,skip_special_tokens=True)\n",
    "    # label = label_map[example['label']]\n",
    "    return {'text':text}\n",
    "\n",
    "tokenized_test_ds = tokenized_test_ds.map(decode_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluate import evaluator\n",
    "task_evaluator = evaluator('text-classification')\n",
    "results = task_evaluator.compute(\n",
    "    model_or_pipeline=classifier,\n",
    "    data=tokenized_test_ds,\n",
    "    metric=evaluate.combine(['accuracy','recall','precision','f1']),\n",
    "    label_mapping=label2id,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.9846625766871165,\n",
       " 'recall': 0.9693928750627195,\n",
       " 'precision': 0.9679358717434869,\n",
       " 'f1': 0.9686638255201804,\n",
       " 'total_time_in_seconds': 92.62441260000196,\n",
       " 'samples_per_second': 87.98976178338353,\n",
       " 'latency_in_seconds': 0.011364958601227234}"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
