{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "NVIDIA GeForce RTX 3080\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from datasets import Dataset, load_dataset\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.get_device_name())\n",
    "print(torch.cuda.current_device())\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import BertTokenizerFast, DataCollatorWithPadding, AutoModelForSequenceClassification, TrainingArguments, Trainer, pipeline\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from tqdm import tqdm\n",
    "import evaluate\n",
    "import random\n",
    "import heapq\n",
    "path = 'Data/splits'\n",
    "model_path = 'google-bert/bert-base-uncased'\n",
    "tokenizer = BertTokenizerFast.from_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "arrow_file_name = \"data-00000-of-00001\"\n",
    "def load_data(path,tokenized=False):\n",
    "    if tokenized:\n",
    "        full_ds = load_dataset('arrow',data_files={\n",
    "            'train':path+f'/tokenized/train_ds/{arrow_file_name}.arrow',\n",
    "            'test':path+f'/tokenized/test_ds/{arrow_file_name}.arrow',\n",
    "            'val':path+f'/tokenized/val_ds/{arrow_file_name}.arrow'\n",
    "        })\n",
    "    else:\n",
    "        full_ds = load_dataset('arrow',data_files={\n",
    "            'train':path+f'/train_ds/{arrow_file_name}.arrow',\n",
    "            'test':path+f'/test_ds/{arrow_file_name}.arrow',\n",
    "            'validation':path+f'/val_ds/{arrow_file_name}.arrow'\n",
    "        })\n",
    "    return full_ds\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train-Val-Test split, run only once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_function(id,example):\n",
    "    text = example['processed']\n",
    "    label = example['class']\n",
    "    tokens = tokenizer.encode(text)\n",
    "    out = []\n",
    "    if len(tokens) <= 512:\n",
    "        out.append([tokens,label,id])\n",
    "        return out\n",
    "    else:\n",
    "        cls_token = tokens[0]\n",
    "        sep_token = tokens[-1]\n",
    "        tokens = tokens[1:-1] # remove CLS and SEP tokens\n",
    "        chunks = [tokens[i:i+500] for i in range(0,len(tokens),500)]\n",
    "        for c in chunks: # add back CLS and SEP tokens\n",
    "            c.insert(0,cls_token)\n",
    "            c.append(sep_token)\n",
    "            out.append([c,label,id])\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shorten(text):\n",
    "    words = text.split(\" \")\n",
    "    curr = None\n",
    "    final = []\n",
    "    for word in words:\n",
    "        if word != curr:\n",
    "            final.append(word)\n",
    "        curr = word\n",
    "    return \" \".join(final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_function_2(id,example):\n",
    "    text = example['processed']\n",
    "    text = shorten(text)\n",
    "    label = example['class']\n",
    "    tokens = tokenizer.encode(text)\n",
    "    cls_token = tokens[0]\n",
    "    sep_token = tokens[-1]\n",
    "    first_chunk = tokens[1: 511]\n",
    "    c = []\n",
    "    c.append(cls_token)\n",
    "    c.extend(first_chunk)\n",
    "    c.append(sep_token)\n",
    "    return([c, label, id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(df):\n",
    "    new_df = {'text':[],'label':[],'raw_text':[]}\n",
    "    ids = []\n",
    "    mapping = {\"ham\":0,\"spam\":1}\n",
    "    for i,row in tqdm(df.iterrows()):\n",
    "        new_df[\"raw_text\"].append(row['processed'])\n",
    "        tokens, label, idx = preprocess_function_2(i,row)\n",
    "        new_df['text'].append(tokens)\n",
    "        new_df['label'].append(mapping[label])\n",
    "        ids.append(idx)\n",
    "    final_df = pd.DataFrame(new_df,index=ids)\n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "26078it [00:32, 805.59it/s] \n",
      "6520it [00:07, 903.99it/s] \n",
      "8150it [00:09, 836.10it/s] \n"
     ]
    }
   ],
   "source": [
    "seed = random.seed(37)\n",
    "df = pd.read_pickle(\"Data/full_df.pkl\")\n",
    "df = df.drop_duplicates(subset=['processed'])\n",
    "X = df['processed']\n",
    "y = df['class']\n",
    "X_tr, X_test, y_tr, y_test = train_test_split(X,y,test_size=0.2)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_tr,y_tr,test_size=0.2)\n",
    "train_df = pd.DataFrame({'processed':X_train,'class':y_train})\n",
    "val_df = pd.DataFrame({'processed':X_val,'class':y_val})\n",
    "test_df = pd.DataFrame({'processed':X_test,'class':y_test})\n",
    "train_df = preprocess(train_df)\n",
    "val_df = preprocess(val_df)\n",
    "test_df = preprocess(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>raw_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>trec06p/data/120/299</th>\n",
       "      <td>[101, 18720, 3501, 2615, 27922, 2243, 1051, 68...</td>\n",
       "      <td>0</td>\n",
       "      <td>pgjvzhk oci         phrkignv cjwvdgfibgu ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trec06c/data/153/236</th>\n",
       "      <td>[101, 7592, 6203, 2449, 2814, 1045, 2572, 2013...</td>\n",
       "      <td>1</td>\n",
       "      <td>hello dear business friends i am from shenzhen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trec06p/data/087/127</th>\n",
       "      <td>[101, 14158, 1996, 6671, 1997, 8714, 16371, 22...</td>\n",
       "      <td>0</td>\n",
       "      <td>observing the transit of mercury num may num b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trec06p/data/065/177</th>\n",
       "      <td>[101, 1037, 16371, 2213, 6187, 2050, 16371, 22...</td>\n",
       "      <td>1</td>\n",
       "      <td>a num caa num caa num caa num caa num caa num ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trec06p/data/111/164</th>\n",
       "      <td>[101, 2017, 2342, 2000, 16500, 18830, 5004, 20...</td>\n",
       "      <td>0</td>\n",
       "      <td>you need to install cflow then  see link im a ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                   text  \\\n",
       "trec06p/data/120/299  [101, 18720, 3501, 2615, 27922, 2243, 1051, 68...   \n",
       "trec06c/data/153/236  [101, 7592, 6203, 2449, 2814, 1045, 2572, 2013...   \n",
       "trec06p/data/087/127  [101, 14158, 1996, 6671, 1997, 8714, 16371, 22...   \n",
       "trec06p/data/065/177  [101, 1037, 16371, 2213, 6187, 2050, 16371, 22...   \n",
       "trec06p/data/111/164  [101, 2017, 2342, 2000, 16500, 18830, 5004, 20...   \n",
       "\n",
       "                      label                                           raw_text  \n",
       "trec06p/data/120/299      0       pgjvzhk oci         phrkignv cjwvdgfibgu ...  \n",
       "trec06c/data/153/236      1  hello dear business friends i am from shenzhen...  \n",
       "trec06p/data/087/127      0  observing the transit of mercury num may num b...  \n",
       "trec06p/data/065/177      1  a num caa num caa num caa num caa num caa num ...  \n",
       "trec06p/data/111/164      0  you need to install cflow then  see link im a ...  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>raw_text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19707</td>\n",
       "      <td>19707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6371</td>\n",
       "      <td>6371</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        text  raw_text\n",
       "label                 \n",
       "0      19707     19707\n",
       "1       6371      6371"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.groupby([\"label\"]).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_sim(a,b):\n",
    "    '''\n",
    "    Computes cosine similarity between b and each row of a\n",
    "    a: 2d np vector\n",
    "    b: 1d np vector\n",
    "    '''\n",
    "    a_norm = np.linalg.norm(a, axis=1)\n",
    "    b_norm = np.linalg.norm(b)\n",
    "    return (a @ b) / (a_norm * b_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Post(object):\n",
    "    def __init__(self, id, embedding):\n",
    "        self.id = id\n",
    "        self.embedding = embedding\n",
    "        self.closest_dst = -1 # Cosine similarity is a value from -1 to 1, with similar posts having value close to 1\n",
    "\n",
    "    def __lt__(self, other):\n",
    "        return self.closest_dst < other.closest_dst\n",
    "\n",
    "class Undersample:\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "        self.posts = [Post(row[\"id\"], row[\"embedding\"]) for index, row in df.iterrows()]\n",
    "        self.heap = [post for post in self.posts]\n",
    "        heapq.heapify(self.heap)\n",
    "        self.selected_ids = []\n",
    "        self.selected_embeddings = None\n",
    "    \n",
    "    def select_furthest(self):\n",
    "        if len(self.selected_ids) == 0:\n",
    "            selected = heapq.heappop(self.heap)\n",
    "            return selected\n",
    "        checked = []\n",
    "        heapq.heapify(checked)\n",
    "        furthest_value = 10\n",
    "        furthest_post = None\n",
    "        while len(self.heap) != 0:\n",
    "            post = heapq.heappop(self.heap)\n",
    "            if post.closest_dst > furthest_value:\n",
    "                heapq.heappush(self.heap, post)\n",
    "                temp = list(heapq.merge(self.heap, checked))\n",
    "                heapq.heapify(temp)\n",
    "                self.heap=temp\n",
    "                return furthest_post\n",
    "            x = max(cosine_sim(self.selected_embeddings, post.embedding))\n",
    "            post.closest_dst = x\n",
    "            if x < furthest_value:\n",
    "                furthest_value = x\n",
    "                if furthest_post is not None:\n",
    "                    heapq.heappush(checked, furthest_post)\n",
    "                furthest_post = post\n",
    "            else:\n",
    "                heapq.heappush(checked, post)\n",
    "        self.heap = checked\n",
    "        return furthest_post            \n",
    "\n",
    "    def select_n(self, n):\n",
    "        if n>len(self.posts):\n",
    "            return self.posts\n",
    "        for i in tqdm(range(n)):\n",
    "            selected = self.select_furthest()\n",
    "            reshaped = np.reshape(selected.embedding, (1,len(selected.embedding)))\n",
    "            if self.selected_embeddings is None:\n",
    "                self.selected_embeddings = reshaped\n",
    "            else:\n",
    "                self.selected_embeddings = np.row_stack([self.selected_embeddings, reshaped])\n",
    "            self.selected_ids.append(selected.id)\n",
    "        return self.df[df.id.isin(self.selected_ids)].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_spam = train_df[train_df.label==1].copy()\n",
    "train_ham = train_df[train_df.label==0].copy()\n",
    "undersample_ham = train_ham.sample(len(train_spam), random_state=seed, replace=False)\n",
    "train_df = pd.concat([undersample_ham, train_spam])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "332f13ec4a1e40eb83c09d5ed2007eea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/12742 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3b554a602984f0bac948e376752fcf7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/8150 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c7502b1147c4b13a0af7a6b89260fba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/6520 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_ds = Dataset.from_pandas(train_df,split='train')\n",
    "val_ds = Dataset.from_pandas(val_df,split='validation')\n",
    "test_ds = Dataset.from_pandas(test_df,split='test')\n",
    "train_ds.save_to_disk(path+'/train_ds')\n",
    "test_ds.save_to_disk(path+'/test_ds')\n",
    "val_ds.save_to_disk(path+'/val_ds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "190df4c366394ff7af0f261e39dc7a1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abf2eb219e584244bcf7d005d7a31272",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34245897ae54433ca314c8756940265a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2bc822d030d240a4930d4574c4fd145b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56977b527c064adb8e2c6a7040f0cda9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ds = load_data(path)\n",
    "train_ds = ds['train']\n",
    "test_ds = ds['test']\n",
    "val_ds = ds['validation']\n",
    "train_ds = train_ds.remove_columns(['__index_level_0__'])\n",
    "test_ds = test_ds.remove_columns(['__index_level_0__'])\n",
    "val_ds = val_ds.remove_columns(['__index_level_0__'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoding of tokens and getting attention maps via BERT Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_and_tokenize_function(example):\n",
    "    tokens = example['text']\n",
    "    text = tokenizer.decode(tokens,skip_special_tokens=True)\n",
    "    return tokenizer(text,padding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5eef2be14c63489da858afcd23ab4dba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/12742 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c839f29f00d4298a41eb60d8e114710",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/8150 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8150b8bcdad4bd1b265c4a8ab3ab37b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/6520 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_train_ds = train_ds.map(decode_and_tokenize_function)\n",
    "tokenized_test_ds = test_ds.map(decode_and_tokenize_function)\n",
    "tokenized_val_ds = val_ds.map(decode_and_tokenize_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57815a963f4a40369b99eb0537a4dfde",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/12742 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3cd70c584aaf40ed8e67fc988d738db6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/6520 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c6e436f41894fb9b00d8b255165c9a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/8150 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_train_ds.save_to_disk(path+'/tokenized/train_ds')\n",
    "tokenized_val_ds.save_to_disk(path+'/tokenized/val_ds')\n",
    "tokenized_test_ds.save_to_disk(path+'/tokenized/test_ds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Init Evaluation metrics, Data Collator and Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7ecf9ba7da740da8edf1172a4320b20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52fb2fd537474384b8546d5fcbac3e7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "177eed1cc707489e845bcd18101be3ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d5803d6f296436b8baf1b5928a070fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7441f763180a4552b11f8fef5c6cecb8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating val split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_ds = load_data(path,tokenized=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'label', 'raw_text', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "    num_rows: 12742\n",
       "})"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_ds['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google-bert/bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "accuracy = evaluate.load('accuracy')\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    return accuracy.compute(predictions=predictions, references=labels)\n",
    "\n",
    "id2label = {\n",
    "    0:\"ham\",\n",
    "    1:\"spam\",\n",
    "}\n",
    "\n",
    "label2id = {\n",
    "    \"ham\":0,\n",
    "    \"spam\":1,\n",
    "}\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_path,\n",
    "    num_labels=2,\n",
    "    id2label=id2label,\n",
    "    label2id=label2id,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"model_checkpoints\",\n",
    "    overwrite_output_dir=True,\n",
    "    learning_rate=2e-5,\n",
    "    optim=\"adamw_bnb_8bit\",\n",
    "    gradient_accumulation_steps=2,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=4,\n",
    "    weight_decay=0.01,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    push_to_hub=False,\n",
    "    metric_for_best_model=\"eval_loss\",\n",
    "    logging_steps=200,\n",
    "    save_steps=200,\n",
    "    eval_steps=200,\n",
    "    save_total_limit=5,\n",
    "    load_best_model_at_end=True\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_ds[\"train\"],\n",
    "    eval_dataset=tokenized_ds[\"val\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "acd92f57882c42e79f4ac6ee005e326a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3184 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1321, 'grad_norm': 0.1225442886352539, 'learning_rate': 1.8743718592964826e-05, 'epoch': 0.25}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43f8b7f035bf4ddeacfbac3a68b1fe24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/815 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.11306805908679962, 'eval_accuracy': 0.9664110429447853, 'eval_runtime': 55.3295, 'eval_samples_per_second': 117.84, 'eval_steps_per_second': 14.73, 'epoch': 0.25}\n",
      "{'loss': 0.1236, 'grad_norm': 9.54425048828125, 'learning_rate': 1.748743718592965e-05, 'epoch': 0.5}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9615f5724ece4d05afc90dcee4d0e82c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/815 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.0986725389957428, 'eval_accuracy': 0.975, 'eval_runtime': 56.1346, 'eval_samples_per_second': 116.149, 'eval_steps_per_second': 14.519, 'epoch': 0.5}\n",
      "{'loss': 0.083, 'grad_norm': 26.82895278930664, 'learning_rate': 1.6231155778894474e-05, 'epoch': 0.75}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "913b0af89be24295b11f08fc0d738fb5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/815 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.087204709649086, 'eval_accuracy': 0.9780674846625766, 'eval_runtime': 53.7326, 'eval_samples_per_second': 121.342, 'eval_steps_per_second': 15.168, 'epoch': 0.75}\n",
      "{'loss': 0.078, 'grad_norm': 0.3467020094394684, 'learning_rate': 1.4974874371859299e-05, 'epoch': 1.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3903999c76641a78cd9038305b95998",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/815 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.11468417942523956, 'eval_accuracy': 0.9739263803680982, 'eval_runtime': 53.6444, 'eval_samples_per_second': 121.541, 'eval_steps_per_second': 15.193, 'epoch': 1.0}\n",
      "{'loss': 0.0358, 'grad_norm': 0.015922775492072105, 'learning_rate': 1.3718592964824123e-05, 'epoch': 1.26}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae887c816b8b4243899bc43cd7a8a9b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/815 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.09464883804321289, 'eval_accuracy': 0.9799079754601226, 'eval_runtime': 53.6889, 'eval_samples_per_second': 121.44, 'eval_steps_per_second': 15.18, 'epoch': 1.26}\n",
      "{'loss': 0.0354, 'grad_norm': 0.013116507790982723, 'learning_rate': 1.2462311557788947e-05, 'epoch': 1.51}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e7dea18c23c49b7b79ca43a75a0da5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/815 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.0857028067111969, 'eval_accuracy': 0.9825153374233129, 'eval_runtime': 53.6629, 'eval_samples_per_second': 121.499, 'eval_steps_per_second': 15.187, 'epoch': 1.51}\n",
      "{'loss': 0.041, 'grad_norm': 0.05498252436518669, 'learning_rate': 1.120603015075377e-05, 'epoch': 1.76}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de93b64b8e9e4cd484dc5ec6bfae40e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/815 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.09343696385622025, 'eval_accuracy': 0.9809815950920245, 'eval_runtime': 53.6121, 'eval_samples_per_second': 121.614, 'eval_steps_per_second': 15.202, 'epoch': 1.76}\n",
      "{'loss': 0.0334, 'grad_norm': 0.018323533236980438, 'learning_rate': 9.949748743718594e-06, 'epoch': 2.01}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f5807000258488c97ba78940dd9e81d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/815 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.08328451216220856, 'eval_accuracy': 0.9831288343558282, 'eval_runtime': 53.6436, 'eval_samples_per_second': 121.543, 'eval_steps_per_second': 15.193, 'epoch': 2.01}\n",
      "{'loss': 0.0156, 'grad_norm': 0.008698437362909317, 'learning_rate': 8.693467336683418e-06, 'epoch': 2.26}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89f74ffa1c5246aa8e2afe1471b45c0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/815 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.08576551824808121, 'eval_accuracy': 0.9837423312883435, 'eval_runtime': 53.6895, 'eval_samples_per_second': 121.439, 'eval_steps_per_second': 15.18, 'epoch': 2.26}\n",
      "{'loss': 0.0132, 'grad_norm': 0.005109351594001055, 'learning_rate': 7.437185929648242e-06, 'epoch': 2.51}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4e7a5732fa44521a9a8ef1303b3511a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/815 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.09594490379095078, 'eval_accuracy': 0.9823619631901841, 'eval_runtime': 53.5878, 'eval_samples_per_second': 121.669, 'eval_steps_per_second': 15.209, 'epoch': 2.51}\n",
      "{'loss': 0.0141, 'grad_norm': 0.7692071795463562, 'learning_rate': 6.180904522613066e-06, 'epoch': 2.76}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14f52209098f4b2fb5dde84085f374b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/815 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.09207481890916824, 'eval_accuracy': 0.9829754601226994, 'eval_runtime': 53.6439, 'eval_samples_per_second': 121.542, 'eval_steps_per_second': 15.193, 'epoch': 2.76}\n",
      "{'loss': 0.0136, 'grad_norm': 0.0072205448523163795, 'learning_rate': 4.92462311557789e-06, 'epoch': 3.01}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbcd5a7071df40ce9bf17e7833b1e958",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/815 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.10394727438688278, 'eval_accuracy': 0.9812883435582822, 'eval_runtime': 53.6334, 'eval_samples_per_second': 121.566, 'eval_steps_per_second': 15.196, 'epoch': 3.01}\n",
      "{'loss': 0.0057, 'grad_norm': 1.2677863836288452, 'learning_rate': 3.6683417085427137e-06, 'epoch': 3.26}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2aed44bcf0a4be0ae4502a8d312b5d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/815 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.09566265344619751, 'eval_accuracy': 0.9835889570552148, 'eval_runtime': 53.7206, 'eval_samples_per_second': 121.369, 'eval_steps_per_second': 15.171, 'epoch': 3.26}\n",
      "{'loss': 0.0028, 'grad_norm': 0.001682559261098504, 'learning_rate': 2.412060301507538e-06, 'epoch': 3.52}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1424247648b420d896337d502bab3bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/815 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.09360352158546448, 'eval_accuracy': 0.9842024539877301, 'eval_runtime': 53.6615, 'eval_samples_per_second': 121.502, 'eval_steps_per_second': 15.188, 'epoch': 3.52}\n",
      "{'loss': 0.0031, 'grad_norm': 0.001572438981384039, 'learning_rate': 1.155778894472362e-06, 'epoch': 3.77}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d5b27936c284a46955a7d8a6b7c6cad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/815 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.1002873033285141, 'eval_accuracy': 0.9845092024539878, 'eval_runtime': 53.6078, 'eval_samples_per_second': 121.624, 'eval_steps_per_second': 15.203, 'epoch': 3.77}\n",
      "{'train_runtime': 2079.8779, 'train_samples_per_second': 24.505, 'train_steps_per_second': 1.531, 'train_loss': 0.03964742737349553, 'epoch': 4.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=3184, training_loss=0.03964742737349553, metrics={'train_runtime': 2079.8779, 'train_samples_per_second': 24.505, 'train_steps_per_second': 1.531, 'train_loss': 0.03964742737349553, 'epoch': 4.0})"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7551e0b193ee437e81e66ee211036695",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/815 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "eval_results = trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.08328451216220856,\n",
       " 'eval_accuracy': 0.9831288343558282,\n",
       " 'eval_runtime': 55.2077,\n",
       " 'eval_samples_per_second': 118.099,\n",
       " 'eval_steps_per_second': 14.762,\n",
       " 'epoch': 4.0}"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model(\"models/bert_model5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_ds = load_data(path,tokenized=True)\n",
    "tokenized_test_ds = tokenized_ds['test']\n",
    "classifier = pipeline('text-classification',model='models/bert_model5', device=torch.cuda.current_device())\n",
    "def decode_tokens(example):\n",
    "    tokens = example['text']\n",
    "    # label_map = {0:\"ham\",1:\"spam\"}\n",
    "    text = tokenizer.decode(tokens,skip_special_tokens=True)\n",
    "    # label = label_map[example['label']]\n",
    "    return {'text':text}\n",
    "\n",
    "tokenized_test_ds = tokenized_test_ds.map(decode_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluate import evaluator\n",
    "task_evaluator = evaluator('text-classification')\n",
    "results = task_evaluator.compute(\n",
    "    model_or_pipeline=classifier,\n",
    "    data=tokenized_test_ds,\n",
    "    metric=evaluate.combine(['accuracy','recall','precision','f1']),\n",
    "    label_mapping=label2id,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.9846625766871165,\n",
       " 'recall': 0.9693928750627195,\n",
       " 'precision': 0.9679358717434869,\n",
       " 'f1': 0.9686638255201804,\n",
       " 'total_time_in_seconds': 92.62441260000196,\n",
       " 'samples_per_second': 87.98976178338353,\n",
       " 'latency_in_seconds': 0.011364958601227234}"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
