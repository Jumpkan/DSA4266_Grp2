{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# English Translated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_id</th>\n",
       "      <th>class</th>\n",
       "      <th>translated</th>\n",
       "      <th>clean_msg</th>\n",
       "      <th>pretranslation</th>\n",
       "      <th>lang</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>trec06c/data/000/007</td>\n",
       "      <td>spam</td>\n",
       "      <td>Dear person in charge (manager/finance): Hello...</td>\n",
       "      <td>dear person charge hello trading co ltd strong...</td>\n",
       "      <td>尊敬的负责人（经理／财务）：您好！ 我是深圳伟仕嘉贸易有公司：兴办贸易、物资供销，实力雄厚；...</td>\n",
       "      <td>c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>trec06c/data/000/014</td>\n",
       "      <td>spam</td>\n",
       "      <td>Hello! Nice to meet you. Our company is intere...</td>\n",
       "      <td>hello nice meet company interested cooperating...</td>\n",
       "      <td>您好！很高兴认识您。我司有意与您们合作:可长久给您们带来 巨大的效益,另因合作项目的高度自动...</td>\n",
       "      <td>c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>trec06c/data/000/005</td>\n",
       "      <td>spam</td>\n",
       "      <td>TO: Your company’s manager and finance manager...</td>\n",
       "      <td>manager finance manager hello trading co ltd b...</td>\n",
       "      <td>TO：贵公司经理、财务 　　 　您好！　　　　　　 　 深圳市春洋贸易有限公司（东莞分公司）...</td>\n",
       "      <td>c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>trec06c/data/000/013</td>\n",
       "      <td>spam</td>\n",
       "      <td>New remote-controlled airplanes are widely sol...</td>\n",
       "      <td>new airplanes widely sold many types toy airpl...</td>\n",
       "      <td>新型遥控飞机销路广 百元可办厂 玩具飞机品种繁多，但用微型小开关控制的新型能在空中自控飞翔的...</td>\n",
       "      <td>c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>trec06c/data/000/021</td>\n",
       "      <td>spam</td>\n",
       "      <td>Dear company (factory) manager, hello: Our com...</td>\n",
       "      <td>dear company factory manager hello company com...</td>\n",
       "      <td>尊敬的公司（工厂）经理负责人你好： 我公司是一家多年为外资企业代理进出口业务的公司，现有部分...</td>\n",
       "      <td>c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39240</th>\n",
       "      <td>trec06p/data/035/115</td>\n",
       "      <td>spam</td>\n",
       "      <td>Rent WITHOUT COMMISSION\\r \\r m. Avtozavodskaya...</td>\n",
       "      <td>rent without commission min foot blocks buildi...</td>\n",
       "      <td>Аренда БЕЗ КОМИССИОННЫХ\\r \\r м. Автозаводская,...</td>\n",
       "      <td>p</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39241</th>\n",
       "      <td>trec06p/data/058/203</td>\n",
       "      <td>ham</td>\n",
       "      <td>RIFFx~ WAVEfmt + + dataS~ ~y{yw{ zuvx}}ytmjhed...</td>\n",
       "      <td>aa aa tr pf en kn la qu oka pk oz gun nom mum ...</td>\n",
       "      <td>RIFFx~\u0004\u0000WAVEfmt \u0010\u0000\u0000\u0000\u0001\u0000\u0001\u0000\u0011+\u0000\u0000\u0011+\u0000\u0000\u0001\u0000\b\u0000dataS~\u0004\u0000...</td>\n",
       "      <td>p</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39242</th>\n",
       "      <td>trec06p/data/014/167</td>\n",
       "      <td>spam</td>\n",
       "      <td>dangerous cork blob thirteenth alliterate argu...</td>\n",
       "      <td>dangerous cork blob thirteenth alliterate argu...</td>\n",
       "      <td>dangerous cork blob thirteenth alliterate argu...</td>\n",
       "      <td>p</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39243</th>\n",
       "      <td>trec06p/data/025/231</td>\n",
       "      <td>spam</td>\n",
       "      <td>:*.☆. o:☆';*. :*.☆. o:☆';*. :*.☆. o:☆';*. :*.☆...</td>\n",
       "      <td>largest online community history born site abs...</td>\n",
       "      <td>\\r 　　　:*.☆。o:☆';*。:*.☆。o:☆';*。:*.☆。o:☆';*。:*.☆...</td>\n",
       "      <td>p</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39244</th>\n",
       "      <td>trec06p/data/025/042</td>\n",
       "      <td>spam</td>\n",
       "      <td>Bruceg [Jasper]\\r ¥xÆW«÷³Ì§C «~½è³Ì¦n ªA°È³Ì¦n...</td>\n",
       "      <td>jasper</td>\n",
       "      <td>Bruceg [Jasper]\\r ¥xÆW«÷³Ì§C «~½è³Ì¦n ªA°È³Ì¦n...</td>\n",
       "      <td>p</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>39245 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     doc_id class  \\\n",
       "0      trec06c/data/000/007  spam   \n",
       "1      trec06c/data/000/014  spam   \n",
       "2      trec06c/data/000/005  spam   \n",
       "3      trec06c/data/000/013  spam   \n",
       "4      trec06c/data/000/021  spam   \n",
       "...                     ...   ...   \n",
       "39240  trec06p/data/035/115  spam   \n",
       "39241  trec06p/data/058/203   ham   \n",
       "39242  trec06p/data/014/167  spam   \n",
       "39243  trec06p/data/025/231  spam   \n",
       "39244  trec06p/data/025/042  spam   \n",
       "\n",
       "                                              translated  \\\n",
       "0      Dear person in charge (manager/finance): Hello...   \n",
       "1      Hello! Nice to meet you. Our company is intere...   \n",
       "2      TO: Your company’s manager and finance manager...   \n",
       "3      New remote-controlled airplanes are widely sol...   \n",
       "4      Dear company (factory) manager, hello: Our com...   \n",
       "...                                                  ...   \n",
       "39240  Rent WITHOUT COMMISSION\\r \\r m. Avtozavodskaya...   \n",
       "39241  RIFFx~ WAVEfmt + + dataS~ ~y{yw{ zuvx}}ytmjhed...   \n",
       "39242  dangerous cork blob thirteenth alliterate argu...   \n",
       "39243  :*.☆. o:☆';*. :*.☆. o:☆';*. :*.☆. o:☆';*. :*.☆...   \n",
       "39244  Bruceg [Jasper]\\r ¥xÆW«÷³Ì§C «~½è³Ì¦n ªA°È³Ì¦n...   \n",
       "\n",
       "                                               clean_msg  \\\n",
       "0      dear person charge hello trading co ltd strong...   \n",
       "1      hello nice meet company interested cooperating...   \n",
       "2      manager finance manager hello trading co ltd b...   \n",
       "3      new airplanes widely sold many types toy airpl...   \n",
       "4      dear company factory manager hello company com...   \n",
       "...                                                  ...   \n",
       "39240  rent without commission min foot blocks buildi...   \n",
       "39241  aa aa tr pf en kn la qu oka pk oz gun nom mum ...   \n",
       "39242  dangerous cork blob thirteenth alliterate argu...   \n",
       "39243  largest online community history born site abs...   \n",
       "39244                                             jasper   \n",
       "\n",
       "                                          pretranslation lang  \n",
       "0      尊敬的负责人（经理／财务）：您好！ 我是深圳伟仕嘉贸易有公司：兴办贸易、物资供销，实力雄厚；...    c  \n",
       "1      您好！很高兴认识您。我司有意与您们合作:可长久给您们带来 巨大的效益,另因合作项目的高度自动...    c  \n",
       "2      TO：贵公司经理、财务 　　 　您好！　　　　　　 　 深圳市春洋贸易有限公司（东莞分公司）...    c  \n",
       "3      新型遥控飞机销路广 百元可办厂 玩具飞机品种繁多，但用微型小开关控制的新型能在空中自控飞翔的...    c  \n",
       "4      尊敬的公司（工厂）经理负责人你好： 我公司是一家多年为外资企业代理进出口业务的公司，现有部分...    c  \n",
       "...                                                  ...  ...  \n",
       "39240  Аренда БЕЗ КОМИССИОННЫХ\\r \\r м. Автозаводская,...    p  \n",
       "39241  RIFFx~\u0004\u0000WAVEfmt \u0010\u0000\u0000\u0000\u0001\u0000\u0001\u0000\u0011+\u0000\u0000\u0011+\u0000\u0000\u0001\u0000\b\u0000dataS~\u0004\u0000...    p  \n",
       "39242  dangerous cork blob thirteenth alliterate argu...    p  \n",
       "39243  \\r 　　　:*.☆。o:☆';*。:*.☆。o:☆';*。:*.☆。o:☆';*。:*.☆...    p  \n",
       "39244  Bruceg [Jasper]\\r ¥xÆW«÷³Ì§C «~½è³Ì¦n ªA°È³Ì¦n...    p  \n",
       "\n",
       "[39245 rows x 6 columns]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=pd.read_pickle('C:/Users/forgo/Desktop/dsa4266/full_df_en_processed.pkl').reset_index()#.drop_duplicates('clean_msg')\n",
    "temp=pd.read_pickle('C:/Users/forgo/Desktop/dsa4266/full_df.pkl').reset_index()\n",
    "data=data.merge(temp[['doc_id','pretranslation']],how='left',on='doc_id').drop_duplicates('pretranslation').drop_duplicates('clean_msg')\n",
    "# data=data[['class','processed']].drop_duplicates().rename(columns={'processed':'clean_msg'})\n",
    "data['lang']=data['doc_id'].apply(lambda x: x[6])\n",
    "data=data[data['clean_msg']!=''].reset_index(drop=True)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_id</th>\n",
       "      <th>translated</th>\n",
       "      <th>clean_msg</th>\n",
       "      <th>pretranslation</th>\n",
       "      <th>lang</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ham</th>\n",
       "      <td>30579</td>\n",
       "      <td>30579</td>\n",
       "      <td>30579</td>\n",
       "      <td>30579</td>\n",
       "      <td>30579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spam</th>\n",
       "      <td>8666</td>\n",
       "      <td>8666</td>\n",
       "      <td>8666</td>\n",
       "      <td>8666</td>\n",
       "      <td>8666</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       doc_id  translated  clean_msg  pretranslation   lang\n",
       "class                                                      \n",
       "ham     30579       30579      30579           30579  30579\n",
       "spam     8666        8666       8666            8666   8666"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.groupby('class').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# en_regex = re.compile('[^a-zA-Z ]')\n",
    "# d = enchant.Dict(\"en_US\") \n",
    "# STOPWORDS = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def enPreprocess(string):\n",
    "#     string=string.replace('\\n',' ') #remove newline char\n",
    "#     string=en_regex.sub('',string) #removes non alphabets\n",
    "#     string=string.split()\n",
    "#     string=[word.lower() for word in string if len(word)>1]\n",
    "#     string=' '.join([word for word in string if d.check(word) and (word not in STOPWORDS)]) # split the string into list and check each word if it is in the english dictionary and longer than 1 alphabet\n",
    "#     return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data['clean_msg']=data['translated'].apply(lambda x: enPreprocess(x))\n",
    "# data.to_pickle('lowercase words.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X = data.drop(columns='class')\n",
    "y = data['class']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,test_size=.2,random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train,test_size=.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ham     19566\n",
       "spam     5550\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_train=pd.concat([y_train[y_train=='ham'].sample(5528),y_train[y_train=='spam']]).sample(frac=1) #under sampling\n",
    "# y_train=pd.concat([y_train[y_train=='ham'],y_train[y_train=='spam'].sample(24461,replace=True)]).sample(frac=1) #over sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=X_train.loc[y_train.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_e=X_train[X_train['lang']=='p']['clean_msg']\n",
    "X_val_e=X_val[X_val['lang']=='p']['clean_msg']\n",
    "X_test_e=X_test[X_test['lang']=='p']['clean_msg']\n",
    "y_train_e=y_train.loc[X_train_e.index]\n",
    "y_val_e=y_val.loc[X_val_e.index]\n",
    "y_test_e=y_test.loc[X_test_e.index]\n",
    "\n",
    "X_train_c=X_train[X_train['lang']=='c']['pretranslation']\n",
    "X_val_c=X_val[X_val['lang']=='c']['pretranslation']\n",
    "X_test_c=X_test[X_test['lang']=='c']['pretranslation']\n",
    "y_train_c=y_train.loc[X_train_c.index]\n",
    "y_val_c=y_val.loc[X_val_c.index]\n",
    "y_test_c=y_test.loc[X_test_c.index]\n",
    "\n",
    "X_train=X_train['clean_msg']\n",
    "X_val=X_val['clean_msg']\n",
    "X_test=X_test['clean_msg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = CountVectorizer(stop_words='english')\n",
    "X_train_dtm = vect.fit_transform(X_train)\n",
    "X_val_dtm = vect.transform(X_val)\n",
    "X_test_dtm= vect.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "translated dataset Multinomial Naive Bayes \n",
      "acc 0.9320063694267516\n",
      "f1 0.8406121687196716\n"
     ]
    }
   ],
   "source": [
    "nb = MultinomialNB()\n",
    "nb.fit(X_train_dtm, y_train)\n",
    "y_pred_class = nb.predict(X_val_dtm)\n",
    "\n",
    "print('translated dataset Multinomial Naive Bayes ')\n",
    "print('acc',metrics.accuracy_score(y_val, y_pred_class))\n",
    "print('f1',f1_score(y_val.to_list(), y_pred_class,pos_label=\"spam\"))\n",
    "# metrics.confusion_matrix(y_test, y_pred_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "translated dataset log regression \n",
      "acc 0.9684713375796178\n",
      "validation f1 0.9283646888567294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\forgo\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "logreg = LogisticRegression(solver='liblinear')\n",
    "logreg.fit(X_train_dtm, y_train)\n",
    "y_pred_class = logreg.predict(X_val_dtm)\n",
    "y_pred_prob = logreg.predict_proba(X_val_dtm)[:, 1]\n",
    "\n",
    "print('translated dataset log regression ')\n",
    "print('acc',metrics.accuracy_score(y_val, y_pred_class))\n",
    "print('validation f1',f1_score(y_val.to_list(), y_pred_class,pos_label=\"spam\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=[]\n",
    "b=[]\n",
    "for i in np.arange(0.7,.85,0.001):\n",
    "    a.append(i)\n",
    "    c=pd.Series(y_pred_prob).apply(lambda x: 'spam' if x>i else 'ham')\n",
    "    b.append(f1_score(y_val.to_list(),c,pos_label=\"spam\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>threshhold value</th>\n",
       "      <th>f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.700</td>\n",
       "      <td>0.916163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.701</td>\n",
       "      <td>0.915690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.702</td>\n",
       "      <td>0.915690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.703</td>\n",
       "      <td>0.915690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.704</td>\n",
       "      <td>0.915690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.705</td>\n",
       "      <td>0.915690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.706</td>\n",
       "      <td>0.915690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.715</td>\n",
       "      <td>0.915562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.716</td>\n",
       "      <td>0.915562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.709</td>\n",
       "      <td>0.915280</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    threshhold value  f1_score\n",
       "0              0.700  0.916163\n",
       "1              0.701  0.915690\n",
       "2              0.702  0.915690\n",
       "3              0.703  0.915690\n",
       "4              0.704  0.915690\n",
       "5              0.705  0.915690\n",
       "6              0.706  0.915690\n",
       "15             0.715  0.915562\n",
       "16             0.716  0.915562\n",
       "9              0.709  0.915280"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thresh_hold_table=pd.DataFrame({'threshhold value':a,'f1_score':b}).sort_values('f1_score',ascending=False).head(10)\n",
    "thresh_hold_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test f1 0.9136994568497284\n"
     ]
    }
   ],
   "source": [
    "y_pred_prob = logreg.predict_proba(X_test_dtm)[:, 1]\n",
    "opt_predicted=pd.Series(y_pred_prob).apply(lambda x: 'spam' if x>thresh_hold_table.iloc[0,0] else 'ham')\n",
    "print('test f1',f1_score(y_test.to_list(), opt_predicted,pos_label=\"spam\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 model for each language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = CountVectorizer(stop_words='english')\n",
    "X_train_e_dtm = vect.fit_transform(X_train_e)\n",
    "X_test_e_dtm= vect.transform(X_test_e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "cn_word=re.compile(\"[\\u4e00-\\u9FFF]\")\n",
    "X_train_c=X_train_c.apply(lambda x: ''.join([word for word in x if cn_word.match(word)]))\n",
    "X_test_c=X_test_c.apply(lambda x: ''.join([word for word in x if cn_word.match(word)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\forgo\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\feature_extraction\\text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "vect = CountVectorizer(tokenizer=lambda txt:[*txt])\n",
    "X_train_c_dtm = vect.fit_transform(X_train_c)\n",
    "X_test_c_dtm= vect.transform(X_test_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "nb = MultinomialNB()\n",
    "nb.fit(X_train_e_dtm, y_train_e)\n",
    "y_pred_e_class = nb.predict(X_test_e_dtm)\n",
    "\n",
    "\n",
    "nb = MultinomialNB()\n",
    "nb.fit(X_train_c_dtm, y_train_c)\n",
    "y_pred_c_class = nb.predict(X_test_c_dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 model combined Multinomial Naive Bayes \n",
      "acc 0.9371894508854631\n",
      "f1 0.8630935851152458\n"
     ]
    }
   ],
   "source": [
    "print('2 model combined Multinomial Naive Bayes ')\n",
    "y_pred_combined=y_pred_e_class.tolist()+y_pred_c_class.tolist()\n",
    "y_actual_combined=pd.concat([y_test_e,y_test_c]).to_list()\n",
    "print('acc',metrics.accuracy_score(y_actual_combined, y_pred_combined))\n",
    "print('f1',f1_score(y_pred_combined,y_actual_combined,pos_label=\"spam\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "logreg = LogisticRegression(solver='liblinear')\n",
    "logreg.fit(X_train_e_dtm, y_train_e)\n",
    "y_pred_e_class = logreg.predict(X_test_e_dtm)\n",
    "# y_pred_prob = logreg.predict_proba(X_test_dtm)[:, 1]\n",
    "\n",
    "logreg = LogisticRegression(solver='liblinear')\n",
    "logreg.fit(X_train_c_dtm, y_train_c)\n",
    "y_pred_c_class = logreg.predict(X_test_c_dtm)\n",
    "# y_pred_prob = logreg.predict_proba(X_test_dtm)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 model combined log regression \n",
      "acc 0.9770671423111225\n",
      "f1 0.9477958236658932\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print('2 model combined log regression ')\n",
    "y_pred_combined=y_pred_e_class.tolist()+y_pred_c_class.tolist()\n",
    "y_actual_combined=pd.concat([y_test_e,y_test_c]).to_list()\n",
    "print('acc',metrics.accuracy_score(y_actual_combined, y_pred_combined))\n",
    "print('f1',f1_score(y_pred_combined,y_actual_combined,pos_label=\"spam\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
