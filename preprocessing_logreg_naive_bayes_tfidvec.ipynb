{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import re\n",
    "from TCSP import read_stopwords_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# English Translated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_id</th>\n",
       "      <th>class</th>\n",
       "      <th>translated</th>\n",
       "      <th>clean_msg</th>\n",
       "      <th>pretranslation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>trec06c/data/000/007</td>\n",
       "      <td>spam</td>\n",
       "      <td>Dear person in charge (manager/finance): Hello...</td>\n",
       "      <td>dear person charge hello trading co ltd strong...</td>\n",
       "      <td>尊敬的负责人（经理／财务）：您好！ 我是深圳伟仕嘉贸易有公司：兴办贸易、物资供销，实力雄厚；...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>trec06c/data/000/014</td>\n",
       "      <td>spam</td>\n",
       "      <td>Hello! Nice to meet you. Our company is intere...</td>\n",
       "      <td>hello nice meet company interested cooperating...</td>\n",
       "      <td>您好！很高兴认识您。我司有意与您们合作:可长久给您们带来 巨大的效益,另因合作项目的高度自动...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>trec06c/data/000/005</td>\n",
       "      <td>spam</td>\n",
       "      <td>TO: Your company’s manager and finance manager...</td>\n",
       "      <td>manager finance manager hello trading co ltd b...</td>\n",
       "      <td>TO：贵公司经理、财务 　　 　您好！　　　　　　 　 深圳市春洋贸易有限公司（东莞分公司）...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>trec06c/data/000/013</td>\n",
       "      <td>spam</td>\n",
       "      <td>New remote-controlled airplanes are widely sol...</td>\n",
       "      <td>new airplanes widely sold many types toy airpl...</td>\n",
       "      <td>新型遥控飞机销路广 百元可办厂 玩具飞机品种繁多，但用微型小开关控制的新型能在空中自控飞翔的...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>trec06c/data/000/021</td>\n",
       "      <td>spam</td>\n",
       "      <td>Dear company (factory) manager, hello: Our com...</td>\n",
       "      <td>dear company factory manager hello company com...</td>\n",
       "      <td>尊敬的公司（工厂）经理负责人你好： 我公司是一家多年为外资企业代理进出口业务的公司，现有部分...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39240</th>\n",
       "      <td>trec06p/data/035/115</td>\n",
       "      <td>spam</td>\n",
       "      <td>Rent WITHOUT COMMISSION\\r \\r m. Avtozavodskaya...</td>\n",
       "      <td>rent without commission min foot blocks buildi...</td>\n",
       "      <td>Аренда БЕЗ КОМИССИОННЫХ\\r \\r м. Автозаводская,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39241</th>\n",
       "      <td>trec06p/data/058/203</td>\n",
       "      <td>ham</td>\n",
       "      <td>RIFFx~ WAVEfmt + + dataS~ ~y{yw{ zuvx}}ytmjhed...</td>\n",
       "      <td>aa aa tr pf en kn la qu oka pk oz gun nom mum ...</td>\n",
       "      <td>RIFFx~\u0004\u0000WAVEfmt \u0010\u0000\u0000\u0000\u0001\u0000\u0001\u0000\u0011+\u0000\u0000\u0011+\u0000\u0000\u0001\u0000\b\u0000dataS~\u0004\u0000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39242</th>\n",
       "      <td>trec06p/data/014/167</td>\n",
       "      <td>spam</td>\n",
       "      <td>dangerous cork blob thirteenth alliterate argu...</td>\n",
       "      <td>dangerous cork blob thirteenth alliterate argu...</td>\n",
       "      <td>dangerous cork blob thirteenth alliterate argu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39243</th>\n",
       "      <td>trec06p/data/025/231</td>\n",
       "      <td>spam</td>\n",
       "      <td>:*.☆. o:☆';*. :*.☆. o:☆';*. :*.☆. o:☆';*. :*.☆...</td>\n",
       "      <td>largest online community history born site abs...</td>\n",
       "      <td>\\r 　　　:*.☆。o:☆';*。:*.☆。o:☆';*。:*.☆。o:☆';*。:*.☆...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39244</th>\n",
       "      <td>trec06p/data/025/042</td>\n",
       "      <td>spam</td>\n",
       "      <td>Bruceg [Jasper]\\r ¥xÆW«÷³Ì§C «~½è³Ì¦n ªA°È³Ì¦n...</td>\n",
       "      <td>jasper</td>\n",
       "      <td>Bruceg [Jasper]\\r ¥xÆW«÷³Ì§C «~½è³Ì¦n ªA°È³Ì¦n...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>39245 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     doc_id class  \\\n",
       "0      trec06c/data/000/007  spam   \n",
       "1      trec06c/data/000/014  spam   \n",
       "2      trec06c/data/000/005  spam   \n",
       "3      trec06c/data/000/013  spam   \n",
       "4      trec06c/data/000/021  spam   \n",
       "...                     ...   ...   \n",
       "39240  trec06p/data/035/115  spam   \n",
       "39241  trec06p/data/058/203   ham   \n",
       "39242  trec06p/data/014/167  spam   \n",
       "39243  trec06p/data/025/231  spam   \n",
       "39244  trec06p/data/025/042  spam   \n",
       "\n",
       "                                              translated  \\\n",
       "0      Dear person in charge (manager/finance): Hello...   \n",
       "1      Hello! Nice to meet you. Our company is intere...   \n",
       "2      TO: Your company’s manager and finance manager...   \n",
       "3      New remote-controlled airplanes are widely sol...   \n",
       "4      Dear company (factory) manager, hello: Our com...   \n",
       "...                                                  ...   \n",
       "39240  Rent WITHOUT COMMISSION\\r \\r m. Avtozavodskaya...   \n",
       "39241  RIFFx~ WAVEfmt + + dataS~ ~y{yw{ zuvx}}ytmjhed...   \n",
       "39242  dangerous cork blob thirteenth alliterate argu...   \n",
       "39243  :*.☆. o:☆';*. :*.☆. o:☆';*. :*.☆. o:☆';*. :*.☆...   \n",
       "39244  Bruceg [Jasper]\\r ¥xÆW«÷³Ì§C «~½è³Ì¦n ªA°È³Ì¦n...   \n",
       "\n",
       "                                               clean_msg  \\\n",
       "0      dear person charge hello trading co ltd strong...   \n",
       "1      hello nice meet company interested cooperating...   \n",
       "2      manager finance manager hello trading co ltd b...   \n",
       "3      new airplanes widely sold many types toy airpl...   \n",
       "4      dear company factory manager hello company com...   \n",
       "...                                                  ...   \n",
       "39240  rent without commission min foot blocks buildi...   \n",
       "39241  aa aa tr pf en kn la qu oka pk oz gun nom mum ...   \n",
       "39242  dangerous cork blob thirteenth alliterate argu...   \n",
       "39243  largest online community history born site abs...   \n",
       "39244                                             jasper   \n",
       "\n",
       "                                          pretranslation  \n",
       "0      尊敬的负责人（经理／财务）：您好！ 我是深圳伟仕嘉贸易有公司：兴办贸易、物资供销，实力雄厚；...  \n",
       "1      您好！很高兴认识您。我司有意与您们合作:可长久给您们带来 巨大的效益,另因合作项目的高度自动...  \n",
       "2      TO：贵公司经理、财务 　　 　您好！　　　　　　 　 深圳市春洋贸易有限公司（东莞分公司）...  \n",
       "3      新型遥控飞机销路广 百元可办厂 玩具飞机品种繁多，但用微型小开关控制的新型能在空中自控飞翔的...  \n",
       "4      尊敬的公司（工厂）经理负责人你好： 我公司是一家多年为外资企业代理进出口业务的公司，现有部分...  \n",
       "...                                                  ...  \n",
       "39240  Аренда БЕЗ КОМИССИОННЫХ\\r \\r м. Автозаводская,...  \n",
       "39241  RIFFx~\u0004\u0000WAVEfmt \u0010\u0000\u0000\u0000\u0001\u0000\u0001\u0000\u0011+\u0000\u0000\u0011+\u0000\u0000\u0001\u0000\b\u0000dataS~\u0004\u0000...  \n",
       "39242  dangerous cork blob thirteenth alliterate argu...  \n",
       "39243  \\r 　　　:*.☆。o:☆';*。:*.☆。o:☆';*。:*.☆。o:☆';*。:*.☆...  \n",
       "39244  Bruceg [Jasper]\\r ¥xÆW«÷³Ì§C «~½è³Ì¦n ªA°È³Ì¦n...  \n",
       "\n",
       "[39245 rows x 5 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=pd.read_pickle('C:/Users/forgo/Desktop/dsa4266/full_df_en_processed.pkl').reset_index()#.drop_duplicates('clean_msg')\n",
    "temp=pd.read_pickle('C:/Users/forgo/Desktop/dsa4266/full_df.pkl').reset_index()\n",
    "data=data.merge(temp[['doc_id','pretranslation']],how='left',on='doc_id').drop_duplicates('pretranslation').drop_duplicates('clean_msg')\n",
    "# data=data[['class','processed']].drop_duplicates().rename(columns={'processed':'clean_msg'})\n",
    "\n",
    "data=data[data['clean_msg']!=''].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "cn_word=re.compile(\"[\\u4e00-\\u9FFF]\")\n",
    "data['chinese']=data['pretranslation'].apply(lambda x: ''.join([word for word in x if cn_word.match(word)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['lang']=data['chinese'].apply(lambda x: 'c' if len(x)>2 else 'e')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_id</th>\n",
       "      <th>class</th>\n",
       "      <th>translated</th>\n",
       "      <th>clean_msg</th>\n",
       "      <th>pretranslation</th>\n",
       "      <th>chinese</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lang</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>c</th>\n",
       "      <td>23583</td>\n",
       "      <td>23583</td>\n",
       "      <td>23583</td>\n",
       "      <td>23583</td>\n",
       "      <td>23583</td>\n",
       "      <td>23583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>e</th>\n",
       "      <td>15662</td>\n",
       "      <td>15662</td>\n",
       "      <td>15662</td>\n",
       "      <td>15662</td>\n",
       "      <td>15662</td>\n",
       "      <td>15662</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      doc_id  class  translated  clean_msg  pretranslation  chinese\n",
       "lang                                                               \n",
       "c      23583  23583       23583      23583           23583    23583\n",
       "e      15662  15662       15662      15662           15662    15662"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.groupby('lang').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# en_regex = re.compile('[^a-zA-Z ]')\n",
    "# d = enchant.Dict(\"en_US\") \n",
    "# STOPWORDS = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def enPreprocess(string):\n",
    "#     string=string.replace('\\n',' ') #remove newline char\n",
    "#     string=en_regex.sub('',string) #removes non alphabets\n",
    "#     string=string.split()\n",
    "#     string=[word.lower() for word in string if len(word)>1]\n",
    "#     string=' '.join([word for word in string if d.check(word) and (word not in STOPWORDS)]) # split the string into list and check each word if it is in the english dictionary and longer than 1 alphabet\n",
    "#     return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data['clean_msg']=data['translated'].apply(lambda x: enPreprocess(x))\n",
    "# data.to_pickle('lowercase words.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X = data.drop(columns='class')\n",
    "y = data['class']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,test_size=.2,random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train,test_size=.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ham     19566\n",
       "spam     5550\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train=pd.concat([y_train[y_train=='ham'].sample(5528),y_train[y_train=='spam']]).sample(frac=1) #under sampling\n",
    "# y_train=pd.concat([y_train[y_train=='ham'],y_train[y_train=='spam'].sample(24461,replace=True)]).sample(frac=1) #over sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=X_train.loc[y_train.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_e=X_train[X_train['lang']=='e']['clean_msg']\n",
    "X_val_e=X_val[X_val['lang']=='e']['clean_msg']\n",
    "X_test_e=X_test[X_test['lang']=='e']['clean_msg']\n",
    "y_train_e=y_train.loc[X_train_e.index]\n",
    "y_val_e=y_val.loc[X_val_e.index]\n",
    "y_test_e=y_test.loc[X_test_e.index]\n",
    "\n",
    "X_train_c=X_train[X_train['lang']=='c']['chinese']\n",
    "X_val_c=X_val[X_val['lang']=='c']['chinese']\n",
    "X_test_c=X_test[X_test['lang']=='c']['chinese']\n",
    "y_train_c=y_train.loc[X_train_c.index]\n",
    "y_val_c=y_val.loc[X_val_c.index]\n",
    "y_test_c=y_test.loc[X_test_c.index]\n",
    "\n",
    "X_train=X_train['clean_msg']\n",
    "X_val=X_val['clean_msg']\n",
    "X_test=X_test['clean_msg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = CountVectorizer(stop_words='english')\n",
    "X_train_dtm = vect.fit_transform(X_train)\n",
    "X_val_dtm = vect.transform(X_val)\n",
    "X_test_dtm= vect.transform(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidvect=TfidfTransformer(smooth_idf=1)\n",
    "# X_train_dtm = tfidvect.fit_transform(X_train_dtm)\n",
    "# X_val_dtm = tfidvect.transform(X_val)\n",
    "# X_test_dtm= tfidvect.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "translated dataset Multinomial Naive Bayes \n",
      "acc 0.932484076433121\n",
      "f1 0.8457059679767103\n"
     ]
    }
   ],
   "source": [
    "nb = MultinomialNB()\n",
    "nb.fit(X_train_dtm, y_train)\n",
    "y_pred_class = nb.predict(X_val_dtm)\n",
    "\n",
    "print('translated dataset Multinomial Naive Bayes ')\n",
    "print('acc',metrics.accuracy_score(y_val, y_pred_class))\n",
    "print('f1',f1_score(y_val.to_list(), y_pred_class,pos_label=\"spam\"))\n",
    "# metrics.confusion_matrix(y_test, y_pred_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "translated dataset log regression \n",
      "acc 0.9511146496815287\n",
      "validation f1 0.8976325441813938\n"
     ]
    }
   ],
   "source": [
    "logreg = LogisticRegression(solver='liblinear')\n",
    "logreg.fit(X_train_dtm, y_train)\n",
    "y_pred_class = logreg.predict(X_val_dtm)\n",
    "y_pred_prob = logreg.predict_proba(X_val_dtm)[:, 1]\n",
    "\n",
    "print('translated dataset log regression ')\n",
    "print('acc',metrics.accuracy_score(y_val, y_pred_class))\n",
    "print('validation f1',f1_score(y_val.to_list(), y_pred_class,pos_label=\"spam\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Threshhold optimise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=[]\n",
    "b=[]\n",
    "for i in np.arange(0.7,.85,0.001):\n",
    "    a.append(i)\n",
    "    c=pd.Series(y_pred_prob).apply(lambda x: 'spam' if x>i else 'ham')\n",
    "    b.append(f1_score(y_val.to_list(),c,pos_label=\"spam\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>threshhold value</th>\n",
       "      <th>f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.738</td>\n",
       "      <td>0.921006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.739</td>\n",
       "      <td>0.921006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.737</td>\n",
       "      <td>0.921006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.740</td>\n",
       "      <td>0.920950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.736</td>\n",
       "      <td>0.920680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.742</td>\n",
       "      <td>0.920567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.741</td>\n",
       "      <td>0.920567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.731</td>\n",
       "      <td>0.920410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.735</td>\n",
       "      <td>0.920354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.734</td>\n",
       "      <td>0.920354</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    threshhold value  f1_score\n",
       "38             0.738  0.921006\n",
       "39             0.739  0.921006\n",
       "37             0.737  0.921006\n",
       "40             0.740  0.920950\n",
       "36             0.736  0.920680\n",
       "42             0.742  0.920567\n",
       "41             0.741  0.920567\n",
       "31             0.731  0.920410\n",
       "35             0.735  0.920354\n",
       "34             0.734  0.920354"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thresh_hold_table=pd.DataFrame({'threshhold value':a,'f1_score':b}).sort_values('f1_score',ascending=False).head(10)\n",
    "thresh_hold_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test f1 0.9192405780674411\n"
     ]
    }
   ],
   "source": [
    "y_pred_prob = logreg.predict_proba(X_test_dtm)[:, 1]\n",
    "opt_predicted=pd.Series(y_pred_prob).apply(lambda x: 'spam' if x>thresh_hold_table.iloc[0,0] else 'ham')\n",
    "print('test f1',f1_score(y_test.to_list(), opt_predicted,pos_label=\"spam\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weights Interpretation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample=pd.concat([data[data['class']=='ham'].sample(8666),data[data['class']=='spam']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>weights</th>\n",
       "      <th>word</th>\n",
       "      <th>ham_count</th>\n",
       "      <th>spam_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25802</th>\n",
       "      <td>25802</td>\n",
       "      <td>-2.535008</td>\n",
       "      <td>thanks</td>\n",
       "      <td>250.0</td>\n",
       "      <td>23.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26085</th>\n",
       "      <td>26085</td>\n",
       "      <td>-2.202937</td>\n",
       "      <td>title</td>\n",
       "      <td>55.0</td>\n",
       "      <td>69.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28507</th>\n",
       "      <td>28507</td>\n",
       "      <td>-1.705021</td>\n",
       "      <td>wrote</td>\n",
       "      <td>972.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14354</th>\n",
       "      <td>14354</td>\n",
       "      <td>-1.629618</td>\n",
       "      <td>kind</td>\n",
       "      <td>211.0</td>\n",
       "      <td>104.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14994</th>\n",
       "      <td>14994</td>\n",
       "      <td>-1.598436</td>\n",
       "      <td>list</td>\n",
       "      <td>788.0</td>\n",
       "      <td>213.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19800</th>\n",
       "      <td>19800</td>\n",
       "      <td>-1.481577</td>\n",
       "      <td>produced</td>\n",
       "      <td>35.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21822</th>\n",
       "      <td>21822</td>\n",
       "      <td>-1.371525</td>\n",
       "      <td>ribbon</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21952</th>\n",
       "      <td>21952</td>\n",
       "      <td>-1.337666</td>\n",
       "      <td>robot</td>\n",
       "      <td>283.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18830</th>\n",
       "      <td>18830</td>\n",
       "      <td>-1.279483</td>\n",
       "      <td>pine</td>\n",
       "      <td>71.0</td>\n",
       "      <td>43.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27084</th>\n",
       "      <td>27084</td>\n",
       "      <td>-1.217968</td>\n",
       "      <td>university</td>\n",
       "      <td>44.0</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27230</th>\n",
       "      <td>27230</td>\n",
       "      <td>-1.213598</td>\n",
       "      <td>unsubscribe</td>\n",
       "      <td>204.0</td>\n",
       "      <td>35.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2787</th>\n",
       "      <td>2787</td>\n",
       "      <td>-1.178245</td>\n",
       "      <td>board</td>\n",
       "      <td>893.0</td>\n",
       "      <td>105.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19765</th>\n",
       "      <td>19765</td>\n",
       "      <td>-1.169486</td>\n",
       "      <td>problem</td>\n",
       "      <td>865.0</td>\n",
       "      <td>147.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10167</th>\n",
       "      <td>10167</td>\n",
       "      <td>-1.095609</td>\n",
       "      <td>film</td>\n",
       "      <td>15.0</td>\n",
       "      <td>39.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19315</th>\n",
       "      <td>19315</td>\n",
       "      <td>-1.027528</td>\n",
       "      <td>posted</td>\n",
       "      <td>73.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17122</th>\n",
       "      <td>17122</td>\n",
       "      <td>-1.025257</td>\n",
       "      <td>normal</td>\n",
       "      <td>133.0</td>\n",
       "      <td>96.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21448</th>\n",
       "      <td>21448</td>\n",
       "      <td>-0.994879</td>\n",
       "      <td>requirements</td>\n",
       "      <td>58.0</td>\n",
       "      <td>29.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16571</th>\n",
       "      <td>16571</td>\n",
       "      <td>-0.986034</td>\n",
       "      <td>movie</td>\n",
       "      <td>29.0</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19070</th>\n",
       "      <td>19070</td>\n",
       "      <td>-0.975037</td>\n",
       "      <td>pm</td>\n",
       "      <td>279.0</td>\n",
       "      <td>211.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26524</th>\n",
       "      <td>26524</td>\n",
       "      <td>-0.968841</td>\n",
       "      <td>tried</td>\n",
       "      <td>344.0</td>\n",
       "      <td>57.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1264</th>\n",
       "      <td>1264</td>\n",
       "      <td>-0.963152</td>\n",
       "      <td>appreciated</td>\n",
       "      <td>153.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23926</th>\n",
       "      <td>23926</td>\n",
       "      <td>-0.962328</td>\n",
       "      <td>spam</td>\n",
       "      <td>31.0</td>\n",
       "      <td>53.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14457</th>\n",
       "      <td>14457</td>\n",
       "      <td>-0.961344</td>\n",
       "      <td>lab</td>\n",
       "      <td>685.0</td>\n",
       "      <td>321.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3322</th>\n",
       "      <td>3322</td>\n",
       "      <td>-0.959188</td>\n",
       "      <td>build</td>\n",
       "      <td>236.0</td>\n",
       "      <td>77.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13555</th>\n",
       "      <td>13555</td>\n",
       "      <td>-0.958712</td>\n",
       "      <td>installed</td>\n",
       "      <td>110.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10151</th>\n",
       "      <td>10151</td>\n",
       "      <td>-0.954964</td>\n",
       "      <td>file</td>\n",
       "      <td>650.0</td>\n",
       "      <td>244.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14428</th>\n",
       "      <td>14428</td>\n",
       "      <td>-0.954573</td>\n",
       "      <td>know</td>\n",
       "      <td>1056.0</td>\n",
       "      <td>577.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16078</th>\n",
       "      <td>16078</td>\n",
       "      <td>-0.951833</td>\n",
       "      <td>mike</td>\n",
       "      <td>34.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9748</th>\n",
       "      <td>9748</td>\n",
       "      <td>-0.951008</td>\n",
       "      <td>extremely</td>\n",
       "      <td>48.0</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9892</th>\n",
       "      <td>9892</td>\n",
       "      <td>-0.937402</td>\n",
       "      <td>fans</td>\n",
       "      <td>26.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17740</th>\n",
       "      <td>17740</td>\n",
       "      <td>-0.933655</td>\n",
       "      <td>output</td>\n",
       "      <td>298.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15150</th>\n",
       "      <td>15150</td>\n",
       "      <td>-0.924929</td>\n",
       "      <td>looks</td>\n",
       "      <td>128.0</td>\n",
       "      <td>26.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14152</th>\n",
       "      <td>14152</td>\n",
       "      <td>-0.920753</td>\n",
       "      <td>john</td>\n",
       "      <td>41.0</td>\n",
       "      <td>26.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11932</th>\n",
       "      <td>11932</td>\n",
       "      <td>-0.915898</td>\n",
       "      <td>handy</td>\n",
       "      <td>500.0</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22135</th>\n",
       "      <td>22135</td>\n",
       "      <td>-0.909797</td>\n",
       "      <td>running</td>\n",
       "      <td>346.0</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6704</th>\n",
       "      <td>6704</td>\n",
       "      <td>-0.901831</td>\n",
       "      <td>deadline</td>\n",
       "      <td>56.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17483</th>\n",
       "      <td>17483</td>\n",
       "      <td>0.930118</td>\n",
       "      <td>online</td>\n",
       "      <td>118.0</td>\n",
       "      <td>204.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28527</th>\n",
       "      <td>28527</td>\n",
       "      <td>0.932935</td>\n",
       "      <td>ya</td>\n",
       "      <td>261.0</td>\n",
       "      <td>699.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.940972</td>\n",
       "      <td>ab</td>\n",
       "      <td>2161.0</td>\n",
       "      <td>1788.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9814</th>\n",
       "      <td>9814</td>\n",
       "      <td>1.028133</td>\n",
       "      <td>faculty</td>\n",
       "      <td>28.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22923</th>\n",
       "      <td>22923</td>\n",
       "      <td>1.039335</td>\n",
       "      <td>sex</td>\n",
       "      <td>28.0</td>\n",
       "      <td>93.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17555</th>\n",
       "      <td>17555</td>\n",
       "      <td>1.065829</td>\n",
       "      <td>opt</td>\n",
       "      <td>285.0</td>\n",
       "      <td>663.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14731</th>\n",
       "      <td>14731</td>\n",
       "      <td>1.115345</td>\n",
       "      <td>legal</td>\n",
       "      <td>48.0</td>\n",
       "      <td>80.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19673</th>\n",
       "      <td>19673</td>\n",
       "      <td>1.160200</td>\n",
       "      <td>prices</td>\n",
       "      <td>18.0</td>\n",
       "      <td>159.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4624</th>\n",
       "      <td>4624</td>\n",
       "      <td>1.320211</td>\n",
       "      <td>click</td>\n",
       "      <td>55.0</td>\n",
       "      <td>173.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28309</th>\n",
       "      <td>28309</td>\n",
       "      <td>1.433622</td>\n",
       "      <td>wish</td>\n",
       "      <td>113.0</td>\n",
       "      <td>238.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28056</th>\n",
       "      <td>28056</td>\n",
       "      <td>1.443222</td>\n",
       "      <td>website</td>\n",
       "      <td>112.0</td>\n",
       "      <td>761.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       index   weights          word  ham_count  spam_count\n",
       "25802  25802 -2.535008        thanks      250.0        23.0\n",
       "26085  26085 -2.202937         title       55.0        69.0\n",
       "28507  28507 -1.705021         wrote      972.0        12.0\n",
       "14354  14354 -1.629618          kind      211.0       104.0\n",
       "14994  14994 -1.598436          list      788.0       213.0\n",
       "19800  19800 -1.481577      produced       35.0         8.0\n",
       "21822  21822 -1.371525        ribbon       10.0         5.0\n",
       "21952  21952 -1.337666         robot      283.0         5.0\n",
       "18830  18830 -1.279483          pine       71.0        43.0\n",
       "27084  27084 -1.217968    university       44.0        13.0\n",
       "27230  27230 -1.213598   unsubscribe      204.0        35.0\n",
       "2787    2787 -1.178245         board      893.0       105.0\n",
       "19765  19765 -1.169486       problem      865.0       147.0\n",
       "10167  10167 -1.095609          film       15.0        39.0\n",
       "19315  19315 -1.027528        posted       73.0         4.0\n",
       "17122  17122 -1.025257        normal      133.0        96.0\n",
       "21448  21448 -0.994879  requirements       58.0        29.0\n",
       "16571  16571 -0.986034         movie       29.0        22.0\n",
       "19070  19070 -0.975037            pm      279.0       211.0\n",
       "26524  26524 -0.968841         tried      344.0        57.0\n",
       "1264    1264 -0.963152   appreciated      153.0        12.0\n",
       "23926  23926 -0.962328          spam       31.0        53.0\n",
       "14457  14457 -0.961344           lab      685.0       321.0\n",
       "3322    3322 -0.959188         build      236.0        77.0\n",
       "13555  13555 -0.958712     installed      110.0         0.0\n",
       "10151  10151 -0.954964          file      650.0       244.0\n",
       "14428  14428 -0.954573          know     1056.0       577.0\n",
       "16078  16078 -0.951833          mike       34.0         4.0\n",
       "9748    9748 -0.951008     extremely       48.0        15.0\n",
       "9892    9892 -0.937402          fans       26.0         3.0\n",
       "17740  17740 -0.933655        output      298.0         2.0\n",
       "15150  15150 -0.924929         looks      128.0        26.0\n",
       "14152  14152 -0.920753          john       41.0        26.0\n",
       "11932  11932 -0.915898         handy      500.0        15.0\n",
       "22135  22135 -0.909797       running      346.0        13.0\n",
       "6704    6704 -0.901831      deadline       56.0         9.0\n",
       "17483  17483  0.930118        online      118.0       204.0\n",
       "28527  28527  0.932935            ya      261.0       699.0\n",
       "2          2  0.940972            ab     2161.0      1788.0\n",
       "9814    9814  1.028133       faculty       28.0         8.0\n",
       "22923  22923  1.039335           sex       28.0        93.0\n",
       "17555  17555  1.065829           opt      285.0       663.0\n",
       "14731  14731  1.115345         legal       48.0        80.0\n",
       "19673  19673  1.160200        prices       18.0       159.0\n",
       "4624    4624  1.320211         click       55.0       173.0\n",
       "28309  28309  1.433622          wish      113.0       238.0\n",
       "28056  28056  1.443222       website      112.0       761.0"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ham_count=[]\n",
    "spam_count=[]\n",
    "word_list=[]\n",
    "temp=pd.DataFrame({'weights':logreg.coef_[0]}).reset_index().merge(pd.DataFrame({'index':vect.vocabulary_.values(),'word':vect.vocabulary_.keys()}),how='left',on='index')\n",
    "for index,(word,weights) in temp[temp['weights'].apply(lambda x:abs(x)>.9)][['word','weights']].iterrows():\n",
    "    counter=sample[sample['pretranslation'].apply(lambda x: word in x)]['class'].value_counts()\n",
    "    try:\n",
    "        ham_count.append(counter['ham'])\n",
    "    except:\n",
    "        ham_count.append(0)\n",
    "    try:\n",
    "        spam_count.append(counter['spam'])\n",
    "    except:\n",
    "        spam_count.append(0)\n",
    "    word_list.append(word)\n",
    "\n",
    "word_ham_spam_counter=pd.DataFrame({'word':word_list,'ham_count':ham_count,'spam_count':spam_count})\n",
    "\n",
    "temp=temp.merge(word_ham_spam_counter,how='left',on='word')\n",
    "temp[temp['ham_count']>5].sort_values('weights',ascending=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 model for each language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = CountVectorizer(stop_words='english')\n",
    "X_train_e_dtm = vect.fit_transform(X_train_e)\n",
    "X_test_e_dtm= vect.transform(X_test_e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train_c=X_train_c.apply(lambda x: ''.join([word for word in x if cn_word.match(word)]))\n",
    "X_test_c=X_test_c.apply(lambda x: ''.join([word for word in x if cn_word.match(word)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\forgo\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\feature_extraction\\text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "C:\\Users\\forgo\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\feature_extraction\\text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens [\"'\", 'b', 'c', 'e', 'f', 'g', 'h', 'j', 'l', 'n', 'p', 'r', 'u', 'v', 'w', '介', '代', '令', '似', '位', '余', '作', '例', '便', '候', '值', '假', '僅', '儘', '儻', '先', '免', '全', '兩', '具', '兼', '出', '切', '前', '加', '反', '受', '句', '叮', '否', '呼', '哧', '唯', '唷', '問', '啪', '啷', '喔', '單', '喻', '噠', '固', '基', '外', '天', '夫', '奈', '妨', '妳', '始', '孰', '家', '少', '尚', '巧', '幸', '庶', '徒', '循', '怕', '恰', '悉', '惟', '慢', '成', '截', '抑', '拘', '接', '換', '料', '方', '旁', '旦', '曰', '期', '果', '根', '極', '樣', '次', '止', '正', '步', '死', '毋', '沒', '況', '消', '漫', '烏', '然', '特', '猶', '獨', '甚', '登', '直', '相', '省', '真', '眨', '眼', '知', '確', '種', '竟', '算', '簡', '結', '綜', '緊', '總', '繼', '罷', '肯', '舊', '般', '莫', '萬', '處', '裡', '見', '言', '設', '許', '話', '誠', '譬', '豈', '賊', '賴', '越', '身', '轉', '辦', '述', '逐', '通', '進', '道', '達', '遵', '部', '鄙', '針', '鑒', '開', '間', '關', '限', '難', '雲', '面', '願', '類', '餘', '首', '體', '齊'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "vect = CountVectorizer(tokenizer=lambda txt:[*txt],stop_words=read_stopwords_list())\n",
    "X_train_c_dtm = vect.fit_transform(X_train_c)\n",
    "X_test_c_dtm= vect.transform(X_test_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "nb = MultinomialNB()\n",
    "nb.fit(X_train_e_dtm, y_train_e)\n",
    "y_pred_e_class = nb.predict(X_test_e_dtm)\n",
    "\n",
    "\n",
    "nb = MultinomialNB()\n",
    "nb.fit(X_train_c_dtm, y_train_c)\n",
    "y_pred_c_class = nb.predict(X_test_c_dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 model combined Multinomial Naive Bayes \n",
      "acc 0.9416486176583004\n",
      "f1 0.8746579091406678\n"
     ]
    }
   ],
   "source": [
    "print('2 model combined Multinomial Naive Bayes ')\n",
    "y_pred_combined=y_pred_e_class.tolist()+y_pred_c_class.tolist()\n",
    "y_actual_combined=pd.concat([y_test_e,y_test_c]).to_list()\n",
    "print('acc',metrics.accuracy_score(y_actual_combined, y_pred_combined))\n",
    "print('f1',f1_score(y_pred_combined,y_actual_combined,pos_label=\"spam\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "logreg = LogisticRegression(solver='liblinear')\n",
    "logreg.fit(X_train_e_dtm, y_train_e)\n",
    "y_pred_e_class = logreg.predict(X_test_e_dtm)\n",
    "# y_pred_prob = logreg.predict_proba(X_test_dtm)[:, 1]\n",
    "\n",
    "logreg = LogisticRegression(solver='liblinear')\n",
    "logreg.fit(X_train_c_dtm, y_train_c)\n",
    "y_pred_c_class = logreg.predict(X_test_c_dtm)\n",
    "# y_pred_prob = logreg.predict_proba(X_test_dtm)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 model combined log regression \n",
      "acc 0.9624155943432284\n",
      "f1 0.9190672153635118\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print('2 model combined log regression ')\n",
    "y_pred_combined=y_pred_e_class.tolist()+y_pred_c_class.tolist()\n",
    "y_actual_combined=pd.concat([y_test_e,y_test_c]).to_list()\n",
    "print('acc',metrics.accuracy_score(y_actual_combined, y_pred_combined))\n",
    "print('f1',f1_score(y_pred_combined,y_actual_combined,pos_label=\"spam\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>weights</th>\n",
       "      <th>word</th>\n",
       "      <th>ham_count</th>\n",
       "      <th>spam_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4435</th>\n",
       "      <td>4435</td>\n",
       "      <td>-0.995960</td>\n",
       "      <td>题</td>\n",
       "      <td>1857.0</td>\n",
       "      <td>963.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>465</th>\n",
       "      <td>465</td>\n",
       "      <td>-0.953509</td>\n",
       "      <td>历</td>\n",
       "      <td>692.0</td>\n",
       "      <td>514.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3969</th>\n",
       "      <td>3969</td>\n",
       "      <td>-0.948641</td>\n",
       "      <td>较</td>\n",
       "      <td>1139.0</td>\n",
       "      <td>855.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1910</th>\n",
       "      <td>1910</td>\n",
       "      <td>-0.864361</td>\n",
       "      <td>校</td>\n",
       "      <td>862.0</td>\n",
       "      <td>274.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1619</th>\n",
       "      <td>1619</td>\n",
       "      <td>-0.859695</td>\n",
       "      <td>掩</td>\n",
       "      <td>53.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2754</th>\n",
       "      <td>2754</td>\n",
       "      <td>-0.809725</td>\n",
       "      <td>研</td>\n",
       "      <td>899.0</td>\n",
       "      <td>651.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1339</th>\n",
       "      <td>1339</td>\n",
       "      <td>0.826265</td>\n",
       "      <td>息</td>\n",
       "      <td>510.0</td>\n",
       "      <td>1591.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>260</td>\n",
       "      <td>0.867502</td>\n",
       "      <td>免</td>\n",
       "      <td>243.0</td>\n",
       "      <td>1540.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>625</th>\n",
       "      <td>625</td>\n",
       "      <td>0.942715</td>\n",
       "      <td>商</td>\n",
       "      <td>321.0</td>\n",
       "      <td>2771.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>724</th>\n",
       "      <td>724</td>\n",
       "      <td>1.087136</td>\n",
       "      <td>图</td>\n",
       "      <td>256.0</td>\n",
       "      <td>644.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4090</th>\n",
       "      <td>4090</td>\n",
       "      <td>1.188510</td>\n",
       "      <td>邮</td>\n",
       "      <td>143.0</td>\n",
       "      <td>2291.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      index   weights word  ham_count  spam_count\n",
       "4435   4435 -0.995960    题     1857.0       963.0\n",
       "465     465 -0.953509    历      692.0       514.0\n",
       "3969   3969 -0.948641    较     1139.0       855.0\n",
       "1910   1910 -0.864361    校      862.0       274.0\n",
       "1619   1619 -0.859695    掩       53.0         6.0\n",
       "2754   2754 -0.809725    研      899.0       651.0\n",
       "1339   1339  0.826265    息      510.0      1591.0\n",
       "260     260  0.867502    免      243.0      1540.0\n",
       "625     625  0.942715    商      321.0      2771.0\n",
       "724     724  1.087136    图      256.0       644.0\n",
       "4090   4090  1.188510    邮      143.0      2291.0"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ham_count=[]\n",
    "spam_count=[]\n",
    "word_list=[]\n",
    "temp=pd.DataFrame({'weights':logreg.coef_[0]}).reset_index().merge(pd.DataFrame({'index':vect.vocabulary_.values(),'word':vect.vocabulary_.keys()}),how='left',on='index')\n",
    "for index,(word,weights) in temp[temp['weights'].apply(lambda x:abs(x)>.8)][['word','weights']].iterrows():\n",
    "    counter=sample[sample['pretranslation'].apply(lambda x: word in x)]['class'].value_counts()\n",
    "    try:\n",
    "        ham_count.append(counter['ham'])\n",
    "    except:\n",
    "        ham_count.append(0)\n",
    "    try:\n",
    "        spam_count.append(counter['spam'])\n",
    "    except:\n",
    "        spam_count.append(0)\n",
    "    word_list.append(word)\n",
    "\n",
    "word_ham_spam_counter=pd.DataFrame({'word':word_list,'ham_count':ham_count,'spam_count':spam_count})\n",
    "\n",
    "temp=temp.merge(word_ham_spam_counter,how='left',on='word')\n",
    "temp[temp['ham_count']>5].sort_values('weights',ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_id</th>\n",
       "      <th>class</th>\n",
       "      <th>translated</th>\n",
       "      <th>clean_msg</th>\n",
       "      <th>pretranslation</th>\n",
       "      <th>chinese</th>\n",
       "      <th>lang</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7093</th>\n",
       "      <td>trec06c/data/062/274</td>\n",
       "      <td>ham</td>\n",
       "      <td>Being a woman is sometimes very helpless. God ...</td>\n",
       "      <td>woman sometimes helpless god gives us little t...</td>\n",
       "      <td>做女人有时挺无奈的 老天给我们选合适人的时间太少了 才刚刚开始 时间就到了 该结婚了 ble...</td>\n",
       "      <td>做女人有时挺无奈的老天给我们选合适人的时间太少了才刚刚开始时间就到了该结婚了希望你能更爱你准...</td>\n",
       "      <td>c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6706</th>\n",
       "      <td>trec06c/data/058/006</td>\n",
       "      <td>ham</td>\n",
       "      <td>Li4u?= X-Priority: 3 X-Originating-IP: [222.82...</td>\n",
       "      <td>words searching hard found place worries even ...</td>\n",
       "      <td>Li4u?= X-Priority: 3 X-Originating-IP: [222.82...</td>\n",
       "      <td>很久以来一直想通过一种方式表述自己的言语但苦苦追寻时至今日才发现还是这里得以让我无所顾忌纵然...</td>\n",
       "      <td>c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21426</th>\n",
       "      <td>trec06c/data/196/174</td>\n",
       "      <td>ham</td>\n",
       "      <td>What is a favorite? What is true love? Unless ...</td>\n",
       "      <td>favorite true love unless never talk word love...</td>\n",
       "      <td>什么是最爱？什么是真爱？除非你我从此都不在谈及“恋爱”两字，或者即将死去的人，才有资格评价自...</td>\n",
       "      <td>什么是最爱什么是真爱除非你我从此都不在谈及恋爱两字或者即将死去的人才有资格评价自己此生的爱情...</td>\n",
       "      <td>c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346</th>\n",
       "      <td>trec06c/data/003/131</td>\n",
       "      <td>ham</td>\n",
       "      <td>Sincerely looking for short-term collaborators...</td>\n",
       "      <td>sincerely looking collaborators chance make mo...</td>\n",
       "      <td>诚寻短期合作者，暑假赚点小钱的机会！ 你要做的是提供符合以下条件的信息： 1、1-5个以零散...</td>\n",
       "      <td>诚寻短期合作者暑假赚点小钱的机会你要做的是提供符合以下条件的信息个以零散公司入住为主的写字楼...</td>\n",
       "      <td>c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21402</th>\n",
       "      <td>trec06c/data/196/129</td>\n",
       "      <td>ham</td>\n",
       "      <td>☆───────────────────────────────────☆ odjfre (...</td>\n",
       "      <td>honest understand graduate student understand ...</td>\n",
       "      <td>☆─────────────────────────────────────☆ odjfre...</td>\n",
       "      <td>说老实话我刚读研究生时也不懂但我现在懂了在中国师生关系说白了就是上级和下级的关系也可以说是雇...</td>\n",
       "      <td>c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23155</th>\n",
       "      <td>trec06c/data/212/237</td>\n",
       "      <td>spam</td>\n",
       "      <td>This is a letter in HTML format! -------------...</td>\n",
       "      <td>letter format mail system free download lifeti...</td>\n",
       "      <td>这是一封HTML格式信件！ -------------VolleyMail邮件系统-----...</td>\n",
       "      <td>这是一封格式信件邮件系统免费下载终身可用您好感谢您能在百忙之中抽出时间阅读此信函首先对冒昧地...</td>\n",
       "      <td>c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23209</th>\n",
       "      <td>trec06c/data/213/200</td>\n",
       "      <td>spam</td>\n",
       "      <td>Socorro, the friend of Socorro and meditates w...</td>\n",
       "      <td>friend meditates crank case toothache related ...</td>\n",
       "      <td>Socorro, the friend of Socorro and meditates w...</td>\n",
       "      <td>模具估计大师寻求和作模具估价系统主要是根据塑料成品尺寸估算出塑料模具规格以及价格可进行模具估...</td>\n",
       "      <td>c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23253</th>\n",
       "      <td>trec06c/data/214/020</td>\n",
       "      <td>spam</td>\n",
       "      <td>Countless businessmen have benefited from it. ...</td>\n",
       "      <td>countless businessmen benefited tool many ente...</td>\n",
       "      <td>无数商人从中获益 　　众多企业必备利刃 您有新产品却不知如何推广？您建了网站却没几个人访问？...</td>\n",
       "      <td>无数商人从中获益众多企业必备利刃您有新产品却不知如何推广您建了网站却没几个人访问您做了搜索引...</td>\n",
       "      <td>c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32853</th>\n",
       "      <td>trec06p/data/070/200</td>\n",
       "      <td>spam</td>\n",
       "      <td>How to obtain high-quality overseas customers ...</td>\n",
       "      <td>obtain overseas customers orders obtain overse...</td>\n",
       "      <td>如何获取海外优质客户与订单 　 如何获取海外优质客户与订单 及国际商务谈判实战技巧强化训练 ...</td>\n",
       "      <td>如何获取海外优质客户与订单如何获取海外优质客户与订单及国际商务谈判实战技巧强化训练上海深圳准...</td>\n",
       "      <td>c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38940</th>\n",
       "      <td>trec06p/data/124/020</td>\n",
       "      <td>spam</td>\n",
       "      <td>Supplier Management and Procurement Cost Reduc...</td>\n",
       "      <td>supplier management procurement cost reduction...</td>\n",
       "      <td>供应商管理及采购成本降低技巧 3月18-19日 采购外包管理及供应商业绩改进实务高级研修班 ...</td>\n",
       "      <td>供应商管理及采购成本降低技巧月日采购外包管理及供应商业绩改进实务高级研修班时间年月日深圳金百...</td>\n",
       "      <td>c</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>426 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     doc_id class  \\\n",
       "7093   trec06c/data/062/274   ham   \n",
       "6706   trec06c/data/058/006   ham   \n",
       "21426  trec06c/data/196/174   ham   \n",
       "346    trec06c/data/003/131   ham   \n",
       "21402  trec06c/data/196/129   ham   \n",
       "...                     ...   ...   \n",
       "23155  trec06c/data/212/237  spam   \n",
       "23209  trec06c/data/213/200  spam   \n",
       "23253  trec06c/data/214/020  spam   \n",
       "32853  trec06p/data/070/200  spam   \n",
       "38940  trec06p/data/124/020  spam   \n",
       "\n",
       "                                              translated  \\\n",
       "7093   Being a woman is sometimes very helpless. God ...   \n",
       "6706   Li4u?= X-Priority: 3 X-Originating-IP: [222.82...   \n",
       "21426  What is a favorite? What is true love? Unless ...   \n",
       "346    Sincerely looking for short-term collaborators...   \n",
       "21402  ☆───────────────────────────────────☆ odjfre (...   \n",
       "...                                                  ...   \n",
       "23155  This is a letter in HTML format! -------------...   \n",
       "23209  Socorro, the friend of Socorro and meditates w...   \n",
       "23253  Countless businessmen have benefited from it. ...   \n",
       "32853  How to obtain high-quality overseas customers ...   \n",
       "38940  Supplier Management and Procurement Cost Reduc...   \n",
       "\n",
       "                                               clean_msg  \\\n",
       "7093   woman sometimes helpless god gives us little t...   \n",
       "6706   words searching hard found place worries even ...   \n",
       "21426  favorite true love unless never talk word love...   \n",
       "346    sincerely looking collaborators chance make mo...   \n",
       "21402  honest understand graduate student understand ...   \n",
       "...                                                  ...   \n",
       "23155  letter format mail system free download lifeti...   \n",
       "23209  friend meditates crank case toothache related ...   \n",
       "23253  countless businessmen benefited tool many ente...   \n",
       "32853  obtain overseas customers orders obtain overse...   \n",
       "38940  supplier management procurement cost reduction...   \n",
       "\n",
       "                                          pretranslation  \\\n",
       "7093   做女人有时挺无奈的 老天给我们选合适人的时间太少了 才刚刚开始 时间就到了 该结婚了 ble...   \n",
       "6706   Li4u?= X-Priority: 3 X-Originating-IP: [222.82...   \n",
       "21426  什么是最爱？什么是真爱？除非你我从此都不在谈及“恋爱”两字，或者即将死去的人，才有资格评价自...   \n",
       "346    诚寻短期合作者，暑假赚点小钱的机会！ 你要做的是提供符合以下条件的信息： 1、1-5个以零散...   \n",
       "21402  ☆─────────────────────────────────────☆ odjfre...   \n",
       "...                                                  ...   \n",
       "23155  这是一封HTML格式信件！ -------------VolleyMail邮件系统-----...   \n",
       "23209  Socorro, the friend of Socorro and meditates w...   \n",
       "23253  无数商人从中获益 　　众多企业必备利刃 您有新产品却不知如何推广？您建了网站却没几个人访问？...   \n",
       "32853  如何获取海外优质客户与订单 　 如何获取海外优质客户与订单 及国际商务谈判实战技巧强化训练 ...   \n",
       "38940  供应商管理及采购成本降低技巧 3月18-19日 采购外包管理及供应商业绩改进实务高级研修班 ...   \n",
       "\n",
       "                                                 chinese lang  \n",
       "7093   做女人有时挺无奈的老天给我们选合适人的时间太少了才刚刚开始时间就到了该结婚了希望你能更爱你准...    c  \n",
       "6706   很久以来一直想通过一种方式表述自己的言语但苦苦追寻时至今日才发现还是这里得以让我无所顾忌纵然...    c  \n",
       "21426  什么是最爱什么是真爱除非你我从此都不在谈及恋爱两字或者即将死去的人才有资格评价自己此生的爱情...    c  \n",
       "346    诚寻短期合作者暑假赚点小钱的机会你要做的是提供符合以下条件的信息个以零散公司入住为主的写字楼...    c  \n",
       "21402  说老实话我刚读研究生时也不懂但我现在懂了在中国师生关系说白了就是上级和下级的关系也可以说是雇...    c  \n",
       "...                                                  ...  ...  \n",
       "23155  这是一封格式信件邮件系统免费下载终身可用您好感谢您能在百忙之中抽出时间阅读此信函首先对冒昧地...    c  \n",
       "23209  模具估计大师寻求和作模具估价系统主要是根据塑料成品尺寸估算出塑料模具规格以及价格可进行模具估...    c  \n",
       "23253  无数商人从中获益众多企业必备利刃您有新产品却不知如何推广您建了网站却没几个人访问您做了搜索引...    c  \n",
       "32853  如何获取海外优质客户与订单如何获取海外优质客户与订单及国际商务谈判实战技巧强化训练上海深圳准...    c  \n",
       "38940  供应商管理及采购成本降低技巧月日采购外包管理及供应商业绩改进实务高级研修班时间年月日深圳金百...    c  \n",
       "\n",
       "[426 rows x 7 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample[sample['pretranslation'].apply(lambda x: '寻' in x)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'如何获取海外优质客户与订单如何获取海外优质客户与订单及国际商务谈判实战技巧强化训练上海深圳准时开课主办单位华鹰企业管理咨询公司时间地点年月日上海兆安酒店时间地点年月日深圳金融培训中心费用元人包括培训费资料费两天午餐证书费以及上下午茶点等学员对象成长型出口企业的总经理海外营销部长国际贸易部经理区域市场经理主管海外业务员驻外代表以及预备外销员和其他对国际贸易感兴趣的人士课程背景中国很多非常有竞争力的企业因为不懂得如何开拓国际市场而失去了迅速做大做强的机会部分已经出口的企业也因为不懂得如何开拓国际市场而不得不依靠外贸企业间接出口但结果是产品出口了自己并没有享受到高额的利润并游离在国际市场的门外没有自己的海外客户始终受制于外贸企业有的企业已经直接出口产品但却没有找到最有利润的市场和客户仅仅学会了出口操作而没有达到出口的真正目的获取高额销售利润与此形成鲜明对比的是全球买家越来越青睐中国制造的产品纷纷开始从中国采购或者加大从中国采购的力度实践证明主动找上门来的买家比自己主动找去的买家成交率高倍以上平均首次成交所需时间只有后者的但中国的企业却不知道如何抓住这些机会如何能够让自己轻松地被海外客户找到因而坐失商机出口营销实战系列培训课程着重帮助解决中国出口商开拓国际市场的两个核心问题快速获取国际市场与买家信息和高效出口推广策略不仅准确地定位买家而且更能让买家轻松找到和优先联络自己您的七项收益准确定位目标市场和发现高利润市场迅速地找到您全球的潜在买家和合作伙伴发现竞争对手难以发现的客户独享高利润出口订单极大丰富客户数据库不断优化客户结构提高整体客户质量提高国际市场调查技能轻松获取高价值的市场信息掌握一套获取市场信息和客户情报的系统方法知己知彼百战不殆结识同行拓展人脉积累资源培训核心内容一外销启动前的准备人才方面的准备中国各类企业国际营销部门组织架构的设定及管理方式优劣对比硬件方面的准备软件方面的准备资料方面的准备其它方面的准备二掌握产品知识应该包含哪些关键内容产品知识测试题清楚自己产品的名称清楚自己产品的技术知识及卖点清楚自己产品成本构成及报价清楚相关联产品与行业的知识及名称三如何迅速了解行业宏观环境及掌握竞争对手信息行业国际市场宏观环境所包含的要素及获取办法购买现成的行业国际市场宏观环境报告的途径利用互联网手段查询制作简易行业国际市场宏观环境利用互联网查询和分析国内最主要的竞争对手利用互联网查询和分析国际市场最主要的竞争对手明确我们的竞争对手锁定和分析我们的竞争对手四如何开拓海外市场和寻找海外客户商机经常出没的地方选用哪种方式寻找这些商机更加适合自己如何抓住这些商机获取商机的其他一些途径买家分类和所遵循的标准关键买家信息所应包含的内容和获取的途径获得买家信息主要的途径和方法用什么办法来提高买家信息的准确性和完整性利用互联网寻找全球买家的一些方法五海外目标市场定向调研和管理海外目标市场的调研手段方法及关键所应包含的内容有哪些六海外市场定点调研及对海外客户评估国际区域市场划分原则和客户调研海外买家实力和信用简易评估方法客户信用调查辅助机构和手段利用互联网评估客户评估客户是否适合自己七中国企业自主品牌国际营销风险种类及控制方法八分析企业自身的优势劣势及制定各海外区域市场相应的进占战略分析对本企业的作用分析当中重点关注的要素如何来做分析九根据分析结果制订年度销售规划与政策并分解之各区域及个人十根据调研结果制定目标海外市场产品线策略十一根据调研结果制定目标海外市场价格策略十二根据调研结果制定目标海外市场渠道策略客户渠道的设定及管理渠道规划的基本原则各个时期所采用的渠道策略十三根据调研结果制定目标海外市场促销策略十四根据调研结果制定目标海外市场售后服务策略十五月度季度年度销售统计和分析十六海外营销部内部运作体系和管理海外营销部分权手册和审批权限海外营销部作业流程和相关规定外销业务员的奖励和处罚规定十七同海外客户沟通及获取信任的几个关键技巧同客户沟通的内容和基本要素沟通中的人性基础和重要的沟通策略获取海外客户信任的途径利用企业网站赢得客户信任通过电话沟通取得客户信任外销员个人专业素养取得客户信任客户信任的企业文化包括哪些要素利用企业形象取得客户信任企业形象有哪些作用客户欣赏怎样的企业形象有效的形象传播企业形象的塑造因素出口企业形象操作出口企业形象和本上销售企业形象的差异十八参加展览的标准和取得成功的关键因素选择展览的评估展览成功展览的标准和关键的成功因素展览组织的细节问题如何挑选展位展前如何邀请客户参展现场需要注意问题特装设计技巧怎样充分挖掘展览价值十九临门一脚争取客户最后落单展后如何争取成交机会如何开始接触海外客户商业信函的写作技巧联络海外客户各种方式的选择二十管理海外客户的询盘海外询盘的各种形式辨别和获取高质量的询盘辨别询盘的真假回复询盘的原则抓住真实有效的询盘机会分类管理好以往的询盘二十一获取订单的战略战术应用突破客户落单的最后几个障碍如何获得和对待海外大客户大客户有哪些特点如何获得大客户的青睐开发大客户当中常见的问题如何留住大客户二十二接待客户来访的注意事项如何体现品质保障能力规范运作所体现出来的公司实力二十三中国外销企业当前所面临的问题和挑战战略联盟的形成前提条件如何运作略联盟来实现企业的高速增长美的企业战略联盟的成功案例分析主讲导师徐老师国际贸易实战型专家高级讲师首批丹麦哥本哈根工程学院专业公费留学生北方交通大学工商管理硕士曾任中国机械进出口公司驻巴基斯坦首席代表丹麦通讯公司驻欧洲区市场助理八年国外生活工作经历原任广东美的企业集团广东美的厨房电器海外营销总监广东华帝海外事业部总经理年月因成功完成交钥匙工程合作项目受到巴基斯坦总统穆沙夫接见年作为广东经济代表团成员之一随同当时的广东省委书记李长春访问欧洲其中随同的正式代表有广东集团董事长李东生广东美的企业集团董事长何享健广东格兰仕企业集团董事长梁庆德金羚电器集团董事长陈立民广东省交通集团董事长游国经等广东前强企业董事长多次接受大经贸在越南等地专访印度尼西亚所建的品牌旗舰店在胡主席参观企业时得到高度赞扬现所操盘的企业海外年销售额过万美元江西财经大学国际学院客座教授广州华鹰企业管理咨询有限公司国际营销管理首席顾问自行设置和开发的课程中小企业如何顺利实现走出国门系列外贸出口营销管理实战类课程培训获得由广东省劳动和社会保障厅颁发的第五届广东省职业技能培训和技工教育教学成果奖组委会联络处联系电话联系传真联系人吴小姐陈先生报名回执我单位共人报名参加年月日在上海深圳举办的如何获取海外优质客户与订单及国际商务谈判实战技巧强化训练单位名称培训联系人联系电话联系传真移动电话电子邮箱参加人数人费用总计元参会人所任职务移动电话参会人所任职务移动电话参会人所任职务移动电话付款方式请选择打钩现金支票转帐'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.loc[32853,'chinese']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
