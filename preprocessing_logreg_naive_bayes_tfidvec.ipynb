{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# English Translated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_id</th>\n",
       "      <th>class</th>\n",
       "      <th>translated</th>\n",
       "      <th>clean_msg</th>\n",
       "      <th>pretranslation</th>\n",
       "      <th>lang</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>trec06c/data/000/007</td>\n",
       "      <td>spam</td>\n",
       "      <td>Dear person in charge (manager/finance): Hello...</td>\n",
       "      <td>dear person charge hello trading co ltd strong...</td>\n",
       "      <td>尊敬的负责人（经理／财务）：您好！ 我是深圳伟仕嘉贸易有公司：兴办贸易、物资供销，实力雄厚；...</td>\n",
       "      <td>c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>trec06c/data/000/014</td>\n",
       "      <td>spam</td>\n",
       "      <td>Hello! Nice to meet you. Our company is intere...</td>\n",
       "      <td>hello nice meet company interested cooperating...</td>\n",
       "      <td>您好！很高兴认识您。我司有意与您们合作:可长久给您们带来 巨大的效益,另因合作项目的高度自动...</td>\n",
       "      <td>c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>trec06c/data/000/005</td>\n",
       "      <td>spam</td>\n",
       "      <td>TO: Your company’s manager and finance manager...</td>\n",
       "      <td>manager finance manager hello trading co ltd b...</td>\n",
       "      <td>TO：贵公司经理、财务 　　 　您好！　　　　　　 　 深圳市春洋贸易有限公司（东莞分公司）...</td>\n",
       "      <td>c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>trec06c/data/000/013</td>\n",
       "      <td>spam</td>\n",
       "      <td>New remote-controlled airplanes are widely sol...</td>\n",
       "      <td>new airplanes widely sold many types toy airpl...</td>\n",
       "      <td>新型遥控飞机销路广 百元可办厂 玩具飞机品种繁多，但用微型小开关控制的新型能在空中自控飞翔的...</td>\n",
       "      <td>c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>trec06c/data/000/021</td>\n",
       "      <td>spam</td>\n",
       "      <td>Dear company (factory) manager, hello: Our com...</td>\n",
       "      <td>dear company factory manager hello company com...</td>\n",
       "      <td>尊敬的公司（工厂）经理负责人你好： 我公司是一家多年为外资企业代理进出口业务的公司，现有部分...</td>\n",
       "      <td>c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39240</th>\n",
       "      <td>trec06p/data/035/115</td>\n",
       "      <td>spam</td>\n",
       "      <td>Rent WITHOUT COMMISSION\\r \\r m. Avtozavodskaya...</td>\n",
       "      <td>rent without commission min foot blocks buildi...</td>\n",
       "      <td>Аренда БЕЗ КОМИССИОННЫХ\\r \\r м. Автозаводская,...</td>\n",
       "      <td>p</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39241</th>\n",
       "      <td>trec06p/data/058/203</td>\n",
       "      <td>ham</td>\n",
       "      <td>RIFFx~ WAVEfmt + + dataS~ ~y{yw{ zuvx}}ytmjhed...</td>\n",
       "      <td>aa aa tr pf en kn la qu oka pk oz gun nom mum ...</td>\n",
       "      <td>RIFFx~\u0004\u0000WAVEfmt \u0010\u0000\u0000\u0000\u0001\u0000\u0001\u0000\u0011+\u0000\u0000\u0011+\u0000\u0000\u0001\u0000\b\u0000dataS~\u0004\u0000...</td>\n",
       "      <td>p</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39242</th>\n",
       "      <td>trec06p/data/014/167</td>\n",
       "      <td>spam</td>\n",
       "      <td>dangerous cork blob thirteenth alliterate argu...</td>\n",
       "      <td>dangerous cork blob thirteenth alliterate argu...</td>\n",
       "      <td>dangerous cork blob thirteenth alliterate argu...</td>\n",
       "      <td>p</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39243</th>\n",
       "      <td>trec06p/data/025/231</td>\n",
       "      <td>spam</td>\n",
       "      <td>:*.☆. o:☆';*. :*.☆. o:☆';*. :*.☆. o:☆';*. :*.☆...</td>\n",
       "      <td>largest online community history born site abs...</td>\n",
       "      <td>\\r 　　　:*.☆。o:☆';*。:*.☆。o:☆';*。:*.☆。o:☆';*。:*.☆...</td>\n",
       "      <td>p</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39244</th>\n",
       "      <td>trec06p/data/025/042</td>\n",
       "      <td>spam</td>\n",
       "      <td>Bruceg [Jasper]\\r ¥xÆW«÷³Ì§C «~½è³Ì¦n ªA°È³Ì¦n...</td>\n",
       "      <td>jasper</td>\n",
       "      <td>Bruceg [Jasper]\\r ¥xÆW«÷³Ì§C «~½è³Ì¦n ªA°È³Ì¦n...</td>\n",
       "      <td>p</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>39245 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     doc_id class  \\\n",
       "0      trec06c/data/000/007  spam   \n",
       "1      trec06c/data/000/014  spam   \n",
       "2      trec06c/data/000/005  spam   \n",
       "3      trec06c/data/000/013  spam   \n",
       "4      trec06c/data/000/021  spam   \n",
       "...                     ...   ...   \n",
       "39240  trec06p/data/035/115  spam   \n",
       "39241  trec06p/data/058/203   ham   \n",
       "39242  trec06p/data/014/167  spam   \n",
       "39243  trec06p/data/025/231  spam   \n",
       "39244  trec06p/data/025/042  spam   \n",
       "\n",
       "                                              translated  \\\n",
       "0      Dear person in charge (manager/finance): Hello...   \n",
       "1      Hello! Nice to meet you. Our company is intere...   \n",
       "2      TO: Your company’s manager and finance manager...   \n",
       "3      New remote-controlled airplanes are widely sol...   \n",
       "4      Dear company (factory) manager, hello: Our com...   \n",
       "...                                                  ...   \n",
       "39240  Rent WITHOUT COMMISSION\\r \\r m. Avtozavodskaya...   \n",
       "39241  RIFFx~ WAVEfmt + + dataS~ ~y{yw{ zuvx}}ytmjhed...   \n",
       "39242  dangerous cork blob thirteenth alliterate argu...   \n",
       "39243  :*.☆. o:☆';*. :*.☆. o:☆';*. :*.☆. o:☆';*. :*.☆...   \n",
       "39244  Bruceg [Jasper]\\r ¥xÆW«÷³Ì§C «~½è³Ì¦n ªA°È³Ì¦n...   \n",
       "\n",
       "                                               clean_msg  \\\n",
       "0      dear person charge hello trading co ltd strong...   \n",
       "1      hello nice meet company interested cooperating...   \n",
       "2      manager finance manager hello trading co ltd b...   \n",
       "3      new airplanes widely sold many types toy airpl...   \n",
       "4      dear company factory manager hello company com...   \n",
       "...                                                  ...   \n",
       "39240  rent without commission min foot blocks buildi...   \n",
       "39241  aa aa tr pf en kn la qu oka pk oz gun nom mum ...   \n",
       "39242  dangerous cork blob thirteenth alliterate argu...   \n",
       "39243  largest online community history born site abs...   \n",
       "39244                                             jasper   \n",
       "\n",
       "                                          pretranslation lang  \n",
       "0      尊敬的负责人（经理／财务）：您好！ 我是深圳伟仕嘉贸易有公司：兴办贸易、物资供销，实力雄厚；...    c  \n",
       "1      您好！很高兴认识您。我司有意与您们合作:可长久给您们带来 巨大的效益,另因合作项目的高度自动...    c  \n",
       "2      TO：贵公司经理、财务 　　 　您好！　　　　　　 　 深圳市春洋贸易有限公司（东莞分公司）...    c  \n",
       "3      新型遥控飞机销路广 百元可办厂 玩具飞机品种繁多，但用微型小开关控制的新型能在空中自控飞翔的...    c  \n",
       "4      尊敬的公司（工厂）经理负责人你好： 我公司是一家多年为外资企业代理进出口业务的公司，现有部分...    c  \n",
       "...                                                  ...  ...  \n",
       "39240  Аренда БЕЗ КОМИССИОННЫХ\\r \\r м. Автозаводская,...    p  \n",
       "39241  RIFFx~\u0004\u0000WAVEfmt \u0010\u0000\u0000\u0000\u0001\u0000\u0001\u0000\u0011+\u0000\u0000\u0011+\u0000\u0000\u0001\u0000\b\u0000dataS~\u0004\u0000...    p  \n",
       "39242  dangerous cork blob thirteenth alliterate argu...    p  \n",
       "39243  \\r 　　　:*.☆。o:☆';*。:*.☆。o:☆';*。:*.☆。o:☆';*。:*.☆...    p  \n",
       "39244  Bruceg [Jasper]\\r ¥xÆW«÷³Ì§C «~½è³Ì¦n ªA°È³Ì¦n...    p  \n",
       "\n",
       "[39245 rows x 6 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=pd.read_pickle('C:/Users/forgo/Desktop/dsa4266/full_df_en_processed.pkl').reset_index()#.drop_duplicates('clean_msg')\n",
    "temp=pd.read_pickle('C:/Users/forgo/Desktop/dsa4266/full_df.pkl').reset_index()\n",
    "data=data.merge(temp[['doc_id','pretranslation']],how='left',on='doc_id').drop_duplicates('pretranslation').drop_duplicates('clean_msg')\n",
    "# data=data[['class','processed']].drop_duplicates().rename(columns={'processed':'clean_msg'})\n",
    "data['lang']=data['doc_id'].apply(lambda x: x[6])\n",
    "data=data[data['clean_msg']!=''].reset_index(drop=True)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_id</th>\n",
       "      <th>translated</th>\n",
       "      <th>clean_msg</th>\n",
       "      <th>pretranslation</th>\n",
       "      <th>lang</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ham</th>\n",
       "      <td>30579</td>\n",
       "      <td>30579</td>\n",
       "      <td>30579</td>\n",
       "      <td>30579</td>\n",
       "      <td>30579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spam</th>\n",
       "      <td>8666</td>\n",
       "      <td>8666</td>\n",
       "      <td>8666</td>\n",
       "      <td>8666</td>\n",
       "      <td>8666</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       doc_id  translated  clean_msg  pretranslation   lang\n",
       "class                                                      \n",
       "ham     30579       30579      30579           30579  30579\n",
       "spam     8666        8666       8666            8666   8666"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.groupby('class').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# en_regex = re.compile('[^a-zA-Z ]')\n",
    "# d = enchant.Dict(\"en_US\") \n",
    "# STOPWORDS = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def enPreprocess(string):\n",
    "#     string=string.replace('\\n',' ') #remove newline char\n",
    "#     string=en_regex.sub('',string) #removes non alphabets\n",
    "#     string=string.split()\n",
    "#     string=[word.lower() for word in string if len(word)>1]\n",
    "#     string=' '.join([word for word in string if d.check(word) and (word not in STOPWORDS)]) # split the string into list and check each word if it is in the english dictionary and longer than 1 alphabet\n",
    "#     return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data['clean_msg']=data['translated'].apply(lambda x: enPreprocess(x))\n",
    "# data.to_pickle('lowercase words.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X = data.drop(columns='class')\n",
    "y = data['class']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,test_size=.2,random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train,test_size=.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ham     19566\n",
       "spam     5550\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train=pd.concat([y_train[y_train=='ham'].sample(5528),y_train[y_train=='spam']]).sample(frac=1) #under sampling\n",
    "# y_train=pd.concat([y_train[y_train=='ham'],y_train[y_train=='spam'].sample(24461,replace=True)]).sample(frac=1) #over sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=X_train.loc[y_train.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_e=X_train[X_train['lang']=='p']['clean_msg']\n",
    "X_val_e=X_val[X_val['lang']=='p']['clean_msg']\n",
    "X_test_e=X_test[X_test['lang']=='p']['clean_msg']\n",
    "y_train_e=y_train.loc[X_train_e.index]\n",
    "y_val_e=y_val.loc[X_val_e.index]\n",
    "y_test_e=y_test.loc[X_test_e.index]\n",
    "\n",
    "X_train_c=X_train[X_train['lang']=='c']['pretranslation']\n",
    "X_val_c=X_val[X_val['lang']=='c']['pretranslation']\n",
    "X_test_c=X_test[X_test['lang']=='c']['pretranslation']\n",
    "y_train_c=y_train.loc[X_train_c.index]\n",
    "y_val_c=y_val.loc[X_val_c.index]\n",
    "y_test_c=y_test.loc[X_test_c.index]\n",
    "\n",
    "X_train=X_train['clean_msg']\n",
    "X_val=X_val['clean_msg']\n",
    "X_test=X_test['clean_msg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = CountVectorizer(stop_words='english')\n",
    "X_train_dtm = vect.fit_transform(X_train)\n",
    "X_val_dtm = vect.transform(X_val)\n",
    "X_test_dtm= vect.transform(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidvect=TfidfTransformer(smooth_idf=1)\n",
    "# X_train_dtm = tfidvect.fit_transform(X_train_dtm)\n",
    "# X_val_dtm = tfidvect.transform(X_val)\n",
    "# X_test_dtm= tfidvect.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "translated dataset Multinomial Naive Bayes \n",
      "acc 0.9280254777070064\n",
      "f1 0.8371757925072046\n"
     ]
    }
   ],
   "source": [
    "nb = MultinomialNB()\n",
    "nb.fit(X_train_dtm, y_train)\n",
    "y_pred_class = nb.predict(X_val_dtm)\n",
    "\n",
    "print('translated dataset Multinomial Naive Bayes ')\n",
    "print('acc',metrics.accuracy_score(y_val, y_pred_class))\n",
    "print('f1',f1_score(y_val.to_list(), y_pred_class,pos_label=\"spam\"))\n",
    "# metrics.confusion_matrix(y_test, y_pred_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "translated dataset log regression \n",
      "acc 0.9503184713375796\n",
      "validation f1 0.8963455149501661\n"
     ]
    }
   ],
   "source": [
    "logreg = LogisticRegression(solver='liblinear')\n",
    "logreg.fit(X_train_dtm, y_train)\n",
    "y_pred_class = logreg.predict(X_val_dtm)\n",
    "y_pred_prob = logreg.predict_proba(X_val_dtm)[:, 1]\n",
    "\n",
    "print('translated dataset log regression ')\n",
    "print('acc',metrics.accuracy_score(y_val, y_pred_class))\n",
    "print('validation f1',f1_score(y_val.to_list(), y_pred_class,pos_label=\"spam\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=[]\n",
    "b=[]\n",
    "for i in np.arange(0.7,.85,0.001):\n",
    "    a.append(i)\n",
    "    c=pd.Series(y_pred_prob).apply(lambda x: 'spam' if x>i else 'ham')\n",
    "    b.append(f1_score(y_val.to_list(),c,pos_label=\"spam\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>threshhold value</th>\n",
       "      <th>f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.796</td>\n",
       "      <td>0.919573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>0.786</td>\n",
       "      <td>0.919475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>0.785</td>\n",
       "      <td>0.919475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>0.784</td>\n",
       "      <td>0.919475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.795</td>\n",
       "      <td>0.919246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>0.781</td>\n",
       "      <td>0.919206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0.797</td>\n",
       "      <td>0.919188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>0.783</td>\n",
       "      <td>0.919149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>0.782</td>\n",
       "      <td>0.919149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0.798</td>\n",
       "      <td>0.919131</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    threshhold value  f1_score\n",
       "96             0.796  0.919573\n",
       "86             0.786  0.919475\n",
       "85             0.785  0.919475\n",
       "84             0.784  0.919475\n",
       "95             0.795  0.919246\n",
       "81             0.781  0.919206\n",
       "97             0.797  0.919188\n",
       "83             0.783  0.919149\n",
       "82             0.782  0.919149\n",
       "98             0.798  0.919131"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thresh_hold_table=pd.DataFrame({'threshhold value':a,'f1_score':b}).sort_values('f1_score',ascending=False).head(10)\n",
    "thresh_hold_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test f1 0.9172672239838571\n"
     ]
    }
   ],
   "source": [
    "y_pred_prob = logreg.predict_proba(X_test_dtm)[:, 1]\n",
    "opt_predicted=pd.Series(y_pred_prob).apply(lambda x: 'spam' if x>thresh_hold_table.iloc[0,0] else 'ham')\n",
    "print('test f1',f1_score(y_test.to_list(), opt_predicted,pos_label=\"spam\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample=pd.concat([data[data['class']=='ham'].sample(8666),data[data['class']=='spam']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>weights</th>\n",
       "      <th>word</th>\n",
       "      <th>ham_count</th>\n",
       "      <th>spam_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25092</th>\n",
       "      <td>25092</td>\n",
       "      <td>-2.503356</td>\n",
       "      <td>thanks</td>\n",
       "      <td>231.0</td>\n",
       "      <td>23.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25361</th>\n",
       "      <td>25361</td>\n",
       "      <td>-2.233811</td>\n",
       "      <td>title</td>\n",
       "      <td>66.0</td>\n",
       "      <td>69.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2732</th>\n",
       "      <td>2732</td>\n",
       "      <td>-1.398841</td>\n",
       "      <td>board</td>\n",
       "      <td>887.0</td>\n",
       "      <td>105.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3262</th>\n",
       "      <td>3262</td>\n",
       "      <td>-1.391454</td>\n",
       "      <td>build</td>\n",
       "      <td>223.0</td>\n",
       "      <td>77.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19261</th>\n",
       "      <td>19261</td>\n",
       "      <td>-1.315924</td>\n",
       "      <td>produced</td>\n",
       "      <td>35.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27728</th>\n",
       "      <td>27728</td>\n",
       "      <td>-1.315301</td>\n",
       "      <td>wrote</td>\n",
       "      <td>942.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18341</th>\n",
       "      <td>18341</td>\n",
       "      <td>-1.306825</td>\n",
       "      <td>pine</td>\n",
       "      <td>90.0</td>\n",
       "      <td>43.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14630</th>\n",
       "      <td>14630</td>\n",
       "      <td>-1.303556</td>\n",
       "      <td>list</td>\n",
       "      <td>833.0</td>\n",
       "      <td>213.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19230</th>\n",
       "      <td>19230</td>\n",
       "      <td>-1.296658</td>\n",
       "      <td>problem</td>\n",
       "      <td>859.0</td>\n",
       "      <td>147.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16717</th>\n",
       "      <td>16717</td>\n",
       "      <td>-1.219624</td>\n",
       "      <td>normal</td>\n",
       "      <td>152.0</td>\n",
       "      <td>96.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26353</th>\n",
       "      <td>26353</td>\n",
       "      <td>-1.194249</td>\n",
       "      <td>university</td>\n",
       "      <td>48.0</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21541</th>\n",
       "      <td>21541</td>\n",
       "      <td>-1.163382</td>\n",
       "      <td>running</td>\n",
       "      <td>360.0</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21241</th>\n",
       "      <td>21241</td>\n",
       "      <td>-1.154588</td>\n",
       "      <td>ribbon</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18572</th>\n",
       "      <td>18572</td>\n",
       "      <td>-1.139740</td>\n",
       "      <td>pm</td>\n",
       "      <td>267.0</td>\n",
       "      <td>211.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13997</th>\n",
       "      <td>13997</td>\n",
       "      <td>-1.073527</td>\n",
       "      <td>kind</td>\n",
       "      <td>224.0</td>\n",
       "      <td>104.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21358</th>\n",
       "      <td>21358</td>\n",
       "      <td>-1.066490</td>\n",
       "      <td>rob</td>\n",
       "      <td>1281.0</td>\n",
       "      <td>252.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13467</th>\n",
       "      <td>13467</td>\n",
       "      <td>-1.058724</td>\n",
       "      <td>interval</td>\n",
       "      <td>127.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27357</th>\n",
       "      <td>27357</td>\n",
       "      <td>-1.047424</td>\n",
       "      <td>whats</td>\n",
       "      <td>20.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16131</th>\n",
       "      <td>16131</td>\n",
       "      <td>-1.044042</td>\n",
       "      <td>motor</td>\n",
       "      <td>276.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19203</th>\n",
       "      <td>19203</td>\n",
       "      <td>-1.021929</td>\n",
       "      <td>private</td>\n",
       "      <td>30.0</td>\n",
       "      <td>165.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18437</th>\n",
       "      <td>18437</td>\n",
       "      <td>-1.021865</td>\n",
       "      <td>plan</td>\n",
       "      <td>271.0</td>\n",
       "      <td>154.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1408</th>\n",
       "      <td>1408</td>\n",
       "      <td>-1.021419</td>\n",
       "      <td>article</td>\n",
       "      <td>103.0</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9890</th>\n",
       "      <td>9890</td>\n",
       "      <td>-1.001623</td>\n",
       "      <td>file</td>\n",
       "      <td>699.0</td>\n",
       "      <td>244.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13583</th>\n",
       "      <td>13583</td>\n",
       "      <td>1.025371</td>\n",
       "      <td>investment</td>\n",
       "      <td>17.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9558</th>\n",
       "      <td>9558</td>\n",
       "      <td>1.033163</td>\n",
       "      <td>faculty</td>\n",
       "      <td>29.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19138</th>\n",
       "      <td>19138</td>\n",
       "      <td>1.118246</td>\n",
       "      <td>prices</td>\n",
       "      <td>24.0</td>\n",
       "      <td>159.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17063</th>\n",
       "      <td>17063</td>\n",
       "      <td>1.168511</td>\n",
       "      <td>online</td>\n",
       "      <td>118.0</td>\n",
       "      <td>204.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4533</th>\n",
       "      <td>4533</td>\n",
       "      <td>1.376279</td>\n",
       "      <td>click</td>\n",
       "      <td>57.0</td>\n",
       "      <td>173.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27287</th>\n",
       "      <td>27287</td>\n",
       "      <td>1.595601</td>\n",
       "      <td>website</td>\n",
       "      <td>125.0</td>\n",
       "      <td>761.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       index   weights        word  ham_count  spam_count\n",
       "25092  25092 -2.503356      thanks      231.0        23.0\n",
       "25361  25361 -2.233811       title       66.0        69.0\n",
       "2732    2732 -1.398841       board      887.0       105.0\n",
       "3262    3262 -1.391454       build      223.0        77.0\n",
       "19261  19261 -1.315924    produced       35.0         8.0\n",
       "27728  27728 -1.315301       wrote      942.0        12.0\n",
       "18341  18341 -1.306825        pine       90.0        43.0\n",
       "14630  14630 -1.303556        list      833.0       213.0\n",
       "19230  19230 -1.296658     problem      859.0       147.0\n",
       "16717  16717 -1.219624      normal      152.0        96.0\n",
       "26353  26353 -1.194249  university       48.0        13.0\n",
       "21541  21541 -1.163382     running      360.0        13.0\n",
       "21241  21241 -1.154588      ribbon        7.0         5.0\n",
       "18572  18572 -1.139740          pm      267.0       211.0\n",
       "13997  13997 -1.073527        kind      224.0       104.0\n",
       "21358  21358 -1.066490         rob     1281.0       252.0\n",
       "13467  13467 -1.058724    interval      127.0         0.0\n",
       "27357  27357 -1.047424       whats       20.0         8.0\n",
       "16131  16131 -1.044042       motor      276.0         8.0\n",
       "19203  19203 -1.021929     private       30.0       165.0\n",
       "18437  18437 -1.021865        plan      271.0       154.0\n",
       "1408    1408 -1.021419     article      103.0        24.0\n",
       "9890    9890 -1.001623        file      699.0       244.0\n",
       "13583  13583  1.025371  investment       17.0       100.0\n",
       "9558    9558  1.033163     faculty       29.0         8.0\n",
       "19138  19138  1.118246      prices       24.0       159.0\n",
       "17063  17063  1.168511      online      118.0       204.0\n",
       "4533    4533  1.376279       click       57.0       173.0\n",
       "27287  27287  1.595601     website      125.0       761.0"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ham_count=[]\n",
    "spam_count=[]\n",
    "word_list=[]\n",
    "temp=pd.DataFrame({'weights':logreg.coef_[0]}).reset_index().merge(pd.DataFrame({'index':vect.vocabulary_.values(),'word':vect.vocabulary_.keys()}),how='left',on='index')\n",
    "for index,(word,weights) in temp[temp['weights'].apply(lambda x:abs(x)>1)][['word','weights']].iterrows():\n",
    "    counter=sample[sample['pretranslation'].apply(lambda x: word in x)]['class'].value_counts()\n",
    "    try:\n",
    "        ham_count.append(counter['ham'])\n",
    "    except:\n",
    "        ham_count.append(0)\n",
    "    try:\n",
    "        spam_count.append(counter['spam'])\n",
    "    except:\n",
    "        spam_count.append(0)\n",
    "    word_list.append(word)\n",
    "\n",
    "word_ham_spam_counter=pd.DataFrame({'word':word_list,'ham_count':ham_count,'spam_count':spam_count})\n",
    "\n",
    "temp=temp.merge(word_ham_spam_counter,how='left',on='word')\n",
    "temp[temp['ham_count']>5].sort_values('weights',ascending=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 model for each language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = CountVectorizer(stop_words='english')\n",
    "X_train_e_dtm = vect.fit_transform(X_train_e)\n",
    "X_test_e_dtm= vect.transform(X_test_e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from TCSP import read_stopwords_list\n",
    "cn_word=re.compile(\"[\\u4e00-\\u9FFF]\")\n",
    "X_train_c=X_train_c.apply(lambda x: ''.join([word for word in x if cn_word.match(word)]))\n",
    "X_test_c=X_test_c.apply(lambda x: ''.join([word for word in x if cn_word.match(word)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\forgo\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\feature_extraction\\text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "C:\\Users\\forgo\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\feature_extraction\\text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens [\"'\", 'b', 'c', 'e', 'f', 'g', 'h', 'j', 'l', 'n', 'p', 'r', 'u', 'v', 'w', '介', '代', '令', '似', '位', '余', '作', '例', '便', '候', '值', '假', '僅', '儘', '儻', '先', '免', '全', '兩', '具', '兼', '出', '切', '前', '加', '反', '受', '句', '叮', '否', '呼', '哧', '唯', '唷', '問', '啪', '啷', '喔', '單', '喻', '噠', '固', '基', '外', '天', '夫', '奈', '妨', '妳', '始', '孰', '家', '少', '尚', '巧', '幸', '庶', '徒', '循', '怕', '恰', '悉', '惟', '慢', '成', '截', '抑', '拘', '接', '換', '料', '方', '旁', '旦', '曰', '期', '果', '根', '極', '樣', '次', '止', '正', '步', '死', '毋', '沒', '況', '消', '漫', '烏', '然', '特', '猶', '獨', '甚', '登', '直', '相', '省', '真', '眨', '眼', '知', '確', '種', '竟', '算', '簡', '結', '綜', '緊', '總', '繼', '罷', '肯', '舊', '般', '莫', '萬', '處', '裡', '見', '言', '設', '許', '話', '誠', '譬', '豈', '賊', '賴', '越', '身', '轉', '辦', '述', '逐', '通', '進', '道', '達', '遵', '部', '鄙', '針', '鑒', '開', '間', '關', '限', '難', '雲', '面', '願', '類', '餘', '首', '體', '齊'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "vect = CountVectorizer(tokenizer=lambda txt:[*txt],stop_words=read_stopwords_list())\n",
    "X_train_c_dtm = vect.fit_transform(X_train_c)\n",
    "X_test_c_dtm= vect.transform(X_test_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "nb = MultinomialNB()\n",
    "nb.fit(X_train_e_dtm, y_train_e)\n",
    "y_pred_e_class = nb.predict(X_test_e_dtm)\n",
    "\n",
    "\n",
    "nb = MultinomialNB()\n",
    "nb.fit(X_train_c_dtm, y_train_c)\n",
    "y_pred_c_class = nb.predict(X_test_c_dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 model combined Multinomial Naive Bayes \n",
      "acc 0.9401197604790419\n",
      "f1 0.8722131593257205\n"
     ]
    }
   ],
   "source": [
    "print('2 model combined Multinomial Naive Bayes ')\n",
    "y_pred_combined=y_pred_e_class.tolist()+y_pred_c_class.tolist()\n",
    "y_actual_combined=pd.concat([y_test_e,y_test_c]).to_list()\n",
    "print('acc',metrics.accuracy_score(y_actual_combined, y_pred_combined))\n",
    "print('f1',f1_score(y_pred_combined,y_actual_combined,pos_label=\"spam\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "logreg = LogisticRegression(solver='liblinear')\n",
    "logreg.fit(X_train_e_dtm, y_train_e)\n",
    "y_pred_e_class = logreg.predict(X_test_e_dtm)\n",
    "# y_pred_prob = logreg.predict_proba(X_test_dtm)[:, 1]\n",
    "\n",
    "logreg = LogisticRegression(solver='liblinear')\n",
    "logreg.fit(X_train_c_dtm, y_train_c)\n",
    "y_pred_c_class = logreg.predict(X_test_c_dtm)\n",
    "# y_pred_prob = logreg.predict_proba(X_test_dtm)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 model combined log regression \n",
      "acc 0.9603771181042171\n",
      "f1 0.9151432469304229\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print('2 model combined log regression ')\n",
    "y_pred_combined=y_pred_e_class.tolist()+y_pred_c_class.tolist()\n",
    "y_actual_combined=pd.concat([y_test_e,y_test_c]).to_list()\n",
    "print('acc',metrics.accuracy_score(y_actual_combined, y_pred_combined))\n",
    "print('f1',f1_score(y_pred_combined,y_actual_combined,pos_label=\"spam\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>weights</th>\n",
       "      <th>word</th>\n",
       "      <th>ham_count</th>\n",
       "      <th>spam_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1251</th>\n",
       "      <td>1251</td>\n",
       "      <td>1.041424</td>\n",
       "      <td>息</td>\n",
       "      <td>526</td>\n",
       "      <td>1591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>674</th>\n",
       "      <td>674</td>\n",
       "      <td>1.041125</td>\n",
       "      <td>图</td>\n",
       "      <td>227</td>\n",
       "      <td>644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3449</th>\n",
       "      <td>3449</td>\n",
       "      <td>0.940270</td>\n",
       "      <td>详</td>\n",
       "      <td>124</td>\n",
       "      <td>1289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3751</th>\n",
       "      <td>3751</td>\n",
       "      <td>0.785325</td>\n",
       "      <td>邮</td>\n",
       "      <td>143</td>\n",
       "      <td>2291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>99</td>\n",
       "      <td>0.768213</td>\n",
       "      <td>件</td>\n",
       "      <td>915</td>\n",
       "      <td>2254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>772</th>\n",
       "      <td>772</td>\n",
       "      <td>-0.863598</td>\n",
       "      <td>太</td>\n",
       "      <td>1450</td>\n",
       "      <td>424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2582</th>\n",
       "      <td>2582</td>\n",
       "      <td>-0.864265</td>\n",
       "      <td>研</td>\n",
       "      <td>854</td>\n",
       "      <td>651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1511</th>\n",
       "      <td>1511</td>\n",
       "      <td>-0.918331</td>\n",
       "      <td>掩</td>\n",
       "      <td>56</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1597</th>\n",
       "      <td>1597</td>\n",
       "      <td>-0.952178</td>\n",
       "      <td>政</td>\n",
       "      <td>198</td>\n",
       "      <td>608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4058</th>\n",
       "      <td>4058</td>\n",
       "      <td>-1.080577</td>\n",
       "      <td>题</td>\n",
       "      <td>1817</td>\n",
       "      <td>963</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4229 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      index   weights word  ham_count  spam_count\n",
       "1251   1251  1.041424    息        526        1591\n",
       "674     674  1.041125    图        227         644\n",
       "3449   3449  0.940270    详        124        1289\n",
       "3751   3751  0.785325    邮        143        2291\n",
       "99       99  0.768213    件        915        2254\n",
       "...     ...       ...  ...        ...         ...\n",
       "772     772 -0.863598    太       1450         424\n",
       "2582   2582 -0.864265    研        854         651\n",
       "1511   1511 -0.918331    掩         56           6\n",
       "1597   1597 -0.952178    政        198         608\n",
       "4058   4058 -1.080577    题       1817         963\n",
       "\n",
       "[4229 rows x 5 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ham_count=[]\n",
    "spam_count=[]\n",
    "word_list=[]\n",
    "temp=pd.DataFrame({'weights':logreg.coef_[0]}).reset_index().merge(pd.DataFrame({'index':vect.vocabulary_.values(),'word':vect.vocabulary_.keys()}),how='left',on='index')\n",
    "for index,(word,weights) in temp[temp['weights'].apply(lambda x:abs(x)>1)][['word','weights']].iterrows():\n",
    "    counter=sample[sample['pretranslation'].apply(lambda x: word in x)]['class'].value_counts()\n",
    "    try:\n",
    "        ham_count.append(counter['ham'])\n",
    "    except:\n",
    "        ham_count.append(0)\n",
    "    try:\n",
    "        spam_count.append(counter['spam'])\n",
    "    except:\n",
    "        spam_count.append(0)\n",
    "    word_list.append(word)\n",
    "\n",
    "word_ham_spam_counter=pd.DataFrame({'word':word_list,'ham_count':ham_count,'spam_count':spam_count})\n",
    "\n",
    "temp=temp.merge(word_ham_spam_counter,how='left',on='word')\n",
    "temp[temp['ham_count']>5].sort_values('weights',ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>weights</th>\n",
       "      <th>word</th>\n",
       "      <th>ham_count</th>\n",
       "      <th>spam_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4058</th>\n",
       "      <td>4058</td>\n",
       "      <td>-1.080577</td>\n",
       "      <td>题</td>\n",
       "      <td>1817</td>\n",
       "      <td>963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1597</th>\n",
       "      <td>1597</td>\n",
       "      <td>-0.952178</td>\n",
       "      <td>政</td>\n",
       "      <td>198</td>\n",
       "      <td>608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2582</th>\n",
       "      <td>2582</td>\n",
       "      <td>-0.864265</td>\n",
       "      <td>研</td>\n",
       "      <td>854</td>\n",
       "      <td>651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>772</th>\n",
       "      <td>772</td>\n",
       "      <td>-0.863598</td>\n",
       "      <td>太</td>\n",
       "      <td>1450</td>\n",
       "      <td>424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3640</th>\n",
       "      <td>3640</td>\n",
       "      <td>-0.857633</td>\n",
       "      <td>较</td>\n",
       "      <td>1105</td>\n",
       "      <td>855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>99</td>\n",
       "      <td>0.768213</td>\n",
       "      <td>件</td>\n",
       "      <td>915</td>\n",
       "      <td>2254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3751</th>\n",
       "      <td>3751</td>\n",
       "      <td>0.785325</td>\n",
       "      <td>邮</td>\n",
       "      <td>143</td>\n",
       "      <td>2291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3449</th>\n",
       "      <td>3449</td>\n",
       "      <td>0.940270</td>\n",
       "      <td>详</td>\n",
       "      <td>124</td>\n",
       "      <td>1289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>674</th>\n",
       "      <td>674</td>\n",
       "      <td>1.041125</td>\n",
       "      <td>图</td>\n",
       "      <td>227</td>\n",
       "      <td>644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1251</th>\n",
       "      <td>1251</td>\n",
       "      <td>1.041424</td>\n",
       "      <td>息</td>\n",
       "      <td>526</td>\n",
       "      <td>1591</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1391 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      index   weights word  ham_count  spam_count\n",
       "4058   4058 -1.080577    题       1817         963\n",
       "1597   1597 -0.952178    政        198         608\n",
       "2582   2582 -0.864265    研        854         651\n",
       "772     772 -0.863598    太       1450         424\n",
       "3640   3640 -0.857633    较       1105         855\n",
       "...     ...       ...  ...        ...         ...\n",
       "99       99  0.768213    件        915        2254\n",
       "3751   3751  0.785325    邮        143        2291\n",
       "3449   3449  0.940270    详        124        1289\n",
       "674     674  1.041125    图        227         644\n",
       "1251   1251  1.041424    息        526        1591\n",
       "\n",
       "[1391 rows x 5 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_c[temp_c['ham_count']>56].sort_values('weights',ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spam    1540\n",
       "ham      230\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample[sample['pretranslation'].apply(lambda x: '免'  in x)]['class'].value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
