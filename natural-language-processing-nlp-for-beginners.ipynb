{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d72a1911",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-16T22:12:54.350276Z",
     "iopub.status.busy": "2023-02-16T22:12:54.349329Z",
     "iopub.status.idle": "2023-02-16T22:12:55.394450Z",
     "shell.execute_reply": "2023-02-16T22:12:55.393161Z"
    },
    "papermill": {
     "duration": 1.064236,
     "end_time": "2023-02-16T22:12:55.397743",
     "exception": false,
     "start_time": "2023-02-16T22:12:54.333507",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Manish Seal\\AppData\\Local\\Temp\\ipykernel_14100\\2907955941.py:1: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.style.use(\"fivethirtyeight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e167be80",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-16T22:12:55.524819Z",
     "iopub.status.busy": "2023-02-16T22:12:55.524190Z",
     "iopub.status.idle": "2023-02-16T22:12:55.703045Z",
     "shell.execute_reply": "2023-02-16T22:12:55.701806Z"
    },
    "papermill": {
     "duration": 0.197556,
     "end_time": "2023-02-16T22:12:55.705490",
     "exception": false,
     "start_time": "2023-02-16T22:12:55.507934",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import and instantiate CountVectorizer (with the default parameters)\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vect = CountVectorizer()\n",
    "\n",
    "# learn the 'vocabulary' of the training data (occurs in-place)\n",
    "\n",
    "# examine the fitted vocabulary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d5cf05a",
   "metadata": {
    "papermill": {
     "duration": 0.014788,
     "end_time": "2023-02-16T22:12:55.875926",
     "exception": false,
     "start_time": "2023-02-16T22:12:55.861138",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "📌 From the [scikit-learn documentation](http://scikit-learn.org/stable/modules/feature_extraction.html#text-feature-extraction):\n",
    "\n",
    "> In this scheme, features and samples are defined as follows:\n",
    "\n",
    "> - Each individual token occurrence frequency (normalized or not) is treated as a **feature**.\n",
    "> - The vector of all the token frequencies for a given document is considered a multivariate **sample**.\n",
    "\n",
    "> A **corpus of documents** can thus be represented by a matrix with **one row per document** and **one column per token** (e.g. word) occurring in the corpus.\n",
    "\n",
    "> We call **vectorization** the general process of turning a collection of text documents into numerical feature vectors. This specific strategy (tokenization, counting and normalization) is called the **Bag of Words** or \"Bag of n-grams\" representation. Documents are described by word occurrences while completely ignoring the relative position information of the words in the document."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b95575af",
   "metadata": {
    "papermill": {
     "duration": 0.01475,
     "end_time": "2023-02-16T22:12:55.948988",
     "exception": false,
     "start_time": "2023-02-16T22:12:55.934238",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "📌 From the [scikit-learn documentation](http://scikit-learn.org/stable/modules/feature_extraction.html#text-feature-extraction):\n",
    "\n",
    "> As most documents will typically use a very small subset of the words used in the corpus, the resulting matrix will have **many feature values that are zeros** (typically more than 99% of them).\n",
    "\n",
    "> For instance, a collection of 10,000 short text documents (such as emails) will use a vocabulary with a size in the order of 100,000 unique words in total while each document will use 100 to 1000 unique words individually.\n",
    "\n",
    "> In order to be able to **store such a matrix in memory** but also to **speed up operations**, implementations will typically use a **sparse representation** such as the implementations available in the `scipy.sparse` package."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "846053b8",
   "metadata": {
    "papermill": {
     "duration": 0.015054,
     "end_time": "2023-02-16T22:12:56.138737",
     "exception": false,
     "start_time": "2023-02-16T22:12:56.123683",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 📋 **Summary:**\n",
    "\n",
    "> - `vect.fit(train)` **learns the vocabulary** of the training data\n",
    "> - `vect.transform(train)` uses the **fitted vocabulary** to build a document-term matrix from the training data\n",
    "> - `vect.transform(test)` uses the **fitted vocabulary** to build a document-term matrix from the testing data (and **ignores tokens** it hasn't seen before)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "429c0cc0",
   "metadata": {
    "papermill": {
     "duration": 0.014819,
     "end_time": "2023-02-16T22:12:56.168812",
     "exception": false,
     "start_time": "2023-02-16T22:12:56.153993",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 💾 Reading a text-based dataset into pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e9630dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_pickle('Data/en_emails_raw.pkl')\n",
    "data=data[['class','message']].rename(columns={'class':'label'}).drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f29b534c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-16T22:12:56.201446Z",
     "iopub.status.busy": "2023-02-16T22:12:56.200671Z",
     "iopub.status.idle": "2023-02-16T22:12:56.283323Z",
     "shell.execute_reply": "2023-02-16T22:12:56.281887Z"
    },
    "papermill": {
     "duration": 0.101748,
     "end_time": "2023-02-16T22:12:56.285847",
     "exception": false,
     "start_time": "2023-02-16T22:12:56.184099",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>full_subpath</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>trec06p/data/000/001</th>\n",
       "      <td>spam</td>\n",
       "      <td>\\n                                 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trec06p/data/000/002</th>\n",
       "      <td>spam</td>\n",
       "      <td>Academic Qualifications available from prestig...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trec06p/data/000/003</th>\n",
       "      <td>ham</td>\n",
       "      <td>Greetings all.  This is to verify your subscri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trec06p/data/000/004</th>\n",
       "      <td>spam</td>\n",
       "      <td>try chauncey may conferred the luscious not co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trec06p/data/000/005</th>\n",
       "      <td>ham</td>\n",
       "      <td>It's quiet.  Too quiet.  Well, how about a str...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     label                                            message\n",
       "full_subpath                                                                 \n",
       "trec06p/data/000/001  spam             \\n                                 ...\n",
       "trec06p/data/000/002  spam  Academic Qualifications available from prestig...\n",
       "trec06p/data/000/003   ham  Greetings all.  This is to verify your subscri...\n",
       "trec06p/data/000/004  spam  try chauncey may conferred the luscious not co...\n",
       "trec06p/data/000/005   ham  It's quiet.  Too quiet.  Well, how about a str..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read file into pandas using a relative path\n",
    "# data = pd.read_csv(\"/kaggle/input/data-spam-collection-dataset/spam.csv\", encoding='latin-1')\n",
    "# data.dropna(how=\"any\", inplace=True, axis=1)\n",
    "data.columns = ['label', 'message']\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22f64c11",
   "metadata": {
    "papermill": {
     "duration": 0.015165,
     "end_time": "2023-02-16T22:12:56.316965",
     "exception": false,
     "start_time": "2023-02-16T22:12:56.301800",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 🔍 Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "377e3c3f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-16T22:12:56.414256Z",
     "iopub.status.busy": "2023-02-16T22:12:56.413810Z",
     "iopub.status.idle": "2023-02-16T22:12:56.445976Z",
     "shell.execute_reply": "2023-02-16T22:12:56.444617Z"
    },
    "papermill": {
     "duration": 0.052162,
     "end_time": "2023-02-16T22:12:56.448526",
     "exception": false,
     "start_time": "2023-02-16T22:12:56.396364",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"4\" halign=\"left\">message</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>unique</th>\n",
       "      <th>top</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ham</th>\n",
       "      <td>12184</td>\n",
       "      <td>12184</td>\n",
       "      <td>Greetings all.  This is to verify your subscri...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spam</th>\n",
       "      <td>5403</td>\n",
       "      <td>5403</td>\n",
       "      <td>\\n                                 ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      message                                                               \n",
       "        count unique                                                top freq\n",
       "label                                                                       \n",
       "ham     12184  12184  Greetings all.  This is to verify your subscri...    1\n",
       "spam     5403   5403             \\n                                 ...    1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Distribution of the labels\n",
    "data.groupby('label').describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "068f517a",
   "metadata": {
    "papermill": {
     "duration": 0.015579,
     "end_time": "2023-02-16T22:12:56.480056",
     "exception": false,
     "start_time": "2023-02-16T22:12:56.464477",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We have `4825` ham message and `747` spam message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "708e6081",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-16T22:12:56.514400Z",
     "iopub.status.busy": "2023-02-16T22:12:56.513605Z",
     "iopub.status.idle": "2023-02-16T22:12:56.526318Z",
     "shell.execute_reply": "2023-02-16T22:12:56.525159Z"
    },
    "papermill": {
     "duration": 0.032753,
     "end_time": "2023-02-16T22:12:56.528737",
     "exception": false,
     "start_time": "2023-02-16T22:12:56.495984",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "      <th>label_num</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>full_subpath</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>trec06p/data/000/001</th>\n",
       "      <td>spam</td>\n",
       "      <td>\\n                                 ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trec06p/data/000/002</th>\n",
       "      <td>spam</td>\n",
       "      <td>Academic Qualifications available from prestig...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trec06p/data/000/003</th>\n",
       "      <td>ham</td>\n",
       "      <td>Greetings all.  This is to verify your subscri...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trec06p/data/000/004</th>\n",
       "      <td>spam</td>\n",
       "      <td>try chauncey may conferred the luscious not co...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trec06p/data/000/005</th>\n",
       "      <td>ham</td>\n",
       "      <td>It's quiet.  Too quiet.  Well, how about a str...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     label                                            message  \\\n",
       "full_subpath                                                                    \n",
       "trec06p/data/000/001  spam             \\n                                 ...   \n",
       "trec06p/data/000/002  spam  Academic Qualifications available from prestig...   \n",
       "trec06p/data/000/003   ham  Greetings all.  This is to verify your subscri...   \n",
       "trec06p/data/000/004  spam  try chauncey may conferred the luscious not co...   \n",
       "trec06p/data/000/005   ham  It's quiet.  Too quiet.  Well, how about a str...   \n",
       "\n",
       "                      label_num  \n",
       "full_subpath                     \n",
       "trec06p/data/000/001          1  \n",
       "trec06p/data/000/002          1  \n",
       "trec06p/data/000/003          0  \n",
       "trec06p/data/000/004          1  \n",
       "trec06p/data/000/005          0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert label to a numerical variable\n",
    "data['label_num'] = data.label.map({'ham':0, 'spam':1})\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "954e359d",
   "metadata": {
    "papermill": {
     "duration": 0.015674,
     "end_time": "2023-02-16T22:12:56.560697",
     "exception": false,
     "start_time": "2023-02-16T22:12:56.545023",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "> As we continue our analysis we want to start thinking about the features we are going to be using. This goes along with the general idea of feature engineering. The better your domain knowledge on the data, the better your ability to engineer more features from it. Feature engineering is a very large part of spam detection in general."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "266b0490",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-16T22:12:56.595320Z",
     "iopub.status.busy": "2023-02-16T22:12:56.594624Z",
     "iopub.status.idle": "2023-02-16T22:12:56.609370Z",
     "shell.execute_reply": "2023-02-16T22:12:56.608031Z"
    },
    "papermill": {
     "duration": 0.035513,
     "end_time": "2023-02-16T22:12:56.612285",
     "exception": false,
     "start_time": "2023-02-16T22:12:56.576772",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "      <th>label_num</th>\n",
       "      <th>message_len</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>full_subpath</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>trec06p/data/000/001</th>\n",
       "      <td>spam</td>\n",
       "      <td>\\n                                 ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trec06p/data/000/002</th>\n",
       "      <td>spam</td>\n",
       "      <td>Academic Qualifications available from prestig...</td>\n",
       "      <td>1</td>\n",
       "      <td>632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trec06p/data/000/003</th>\n",
       "      <td>ham</td>\n",
       "      <td>Greetings all.  This is to verify your subscri...</td>\n",
       "      <td>0</td>\n",
       "      <td>861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trec06p/data/000/004</th>\n",
       "      <td>spam</td>\n",
       "      <td>try chauncey may conferred the luscious not co...</td>\n",
       "      <td>1</td>\n",
       "      <td>909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trec06p/data/000/005</th>\n",
       "      <td>ham</td>\n",
       "      <td>It's quiet.  Too quiet.  Well, how about a str...</td>\n",
       "      <td>0</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     label                                            message  \\\n",
       "full_subpath                                                                    \n",
       "trec06p/data/000/001  spam             \\n                                 ...   \n",
       "trec06p/data/000/002  spam  Academic Qualifications available from prestig...   \n",
       "trec06p/data/000/003   ham  Greetings all.  This is to verify your subscri...   \n",
       "trec06p/data/000/004  spam  try chauncey may conferred the luscious not co...   \n",
       "trec06p/data/000/005   ham  It's quiet.  Too quiet.  Well, how about a str...   \n",
       "\n",
       "                      label_num  message_len  \n",
       "full_subpath                                  \n",
       "trec06p/data/000/001          1         1404  \n",
       "trec06p/data/000/002          1          632  \n",
       "trec06p/data/000/003          0          861  \n",
       "trec06p/data/000/004          1          909  \n",
       "trec06p/data/000/005          0           94  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['message_len'] = data.message.apply(len)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3ced686",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1378e63",
   "metadata": {
    "papermill": {
     "duration": 0.017635,
     "end_time": "2023-02-16T22:12:57.470366",
     "exception": false,
     "start_time": "2023-02-16T22:12:57.452731",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 📑 Text Pre-processing\n",
    "\n",
    "> Our main issue with our data is that it is all in text format (strings). The classification algorithms that we usally use need some sort of numerical feature vector in order to perform the classification task. There are actually many methods to convert a corpus to a vector format. The simplest is the `bag-of-words` approach, where each unique word in a text will be represented by one number.\n",
    "\n",
    "\n",
    "> In this section we'll convert the raw messages (sequence of characters) into vectors (sequences of numbers).\n",
    "\n",
    "> As a first step, let's write a function that will split a message into its individual words and return a list. We'll also remove very common words, ('the', 'a', etc..). To do this we will take advantage of the `NLTK` library. It's pretty much the standard library in Python for processing text and has a lot of useful features. We'll only use some of the basic ones here.\n",
    "\n",
    "> Let's create a function that will process the string in the message column, then we can just use **apply()** in pandas do process all the text in the DataFrame.\n",
    "\n",
    ">First removing punctuation. We can just take advantage of Python's built-in **string** library to get a quick list of all the possible punctuation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "181222f5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-16T22:12:57.507881Z",
     "iopub.status.busy": "2023-02-16T22:12:57.507467Z",
     "iopub.status.idle": "2023-02-16T22:12:58.167389Z",
     "shell.execute_reply": "2023-02-16T22:12:58.166229Z"
    },
    "papermill": {
     "duration": 0.682108,
     "end_time": "2023-02-16T22:12:58.170145",
     "exception": false,
     "start_time": "2023-02-16T22:12:57.488037",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "def text_process(mess):\n",
    "    \"\"\"\n",
    "    Takes in a string of text, then performs the following:\n",
    "    1. Remove all punctuation\n",
    "    2. Remove all stopwords\n",
    "    3. Returns a list of the cleaned text\n",
    "    \"\"\"\n",
    "    STOPWORDS = stopwords.words('english') + ['u', 'ü', 'ur', '4', '2', 'im', 'dont', 'doin', 'ure']\n",
    "    # Check characters to see if they are in punctuation\n",
    "    nopunc = [char for char in mess if char not in string.punctuation]\n",
    "\n",
    "    # Join the characters again to form the string.\n",
    "    nopunc = ''.join(nopunc)\n",
    "    \n",
    "    # Now just remove any stopwords\n",
    "    return ' '.join([word for word in nopunc.split() if word.lower() not in STOPWORDS])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cc7046fb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-16T22:12:58.208015Z",
     "iopub.status.busy": "2023-02-16T22:12:58.207569Z",
     "iopub.status.idle": "2023-02-16T22:12:58.219710Z",
     "shell.execute_reply": "2023-02-16T22:12:58.218615Z"
    },
    "papermill": {
     "duration": 0.034002,
     "end_time": "2023-02-16T22:12:58.222128",
     "exception": false,
     "start_time": "2023-02-16T22:12:58.188126",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "      <th>label_num</th>\n",
       "      <th>message_len</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>full_subpath</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>trec06p/data/000/001</th>\n",
       "      <td>spam</td>\n",
       "      <td>\\n                                 ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trec06p/data/000/002</th>\n",
       "      <td>spam</td>\n",
       "      <td>Academic Qualifications available from prestig...</td>\n",
       "      <td>1</td>\n",
       "      <td>632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trec06p/data/000/003</th>\n",
       "      <td>ham</td>\n",
       "      <td>Greetings all.  This is to verify your subscri...</td>\n",
       "      <td>0</td>\n",
       "      <td>861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trec06p/data/000/004</th>\n",
       "      <td>spam</td>\n",
       "      <td>try chauncey may conferred the luscious not co...</td>\n",
       "      <td>1</td>\n",
       "      <td>909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trec06p/data/000/005</th>\n",
       "      <td>ham</td>\n",
       "      <td>It's quiet.  Too quiet.  Well, how about a str...</td>\n",
       "      <td>0</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     label                                            message  \\\n",
       "full_subpath                                                                    \n",
       "trec06p/data/000/001  spam             \\n                                 ...   \n",
       "trec06p/data/000/002  spam  Academic Qualifications available from prestig...   \n",
       "trec06p/data/000/003   ham  Greetings all.  This is to verify your subscri...   \n",
       "trec06p/data/000/004  spam  try chauncey may conferred the luscious not co...   \n",
       "trec06p/data/000/005   ham  It's quiet.  Too quiet.  Well, how about a str...   \n",
       "\n",
       "                      label_num  message_len  \n",
       "full_subpath                                  \n",
       "trec06p/data/000/001          1         1404  \n",
       "trec06p/data/000/002          1          632  \n",
       "trec06p/data/000/003          0          861  \n",
       "trec06p/data/000/004          1          909  \n",
       "trec06p/data/000/005          0           94  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b314afa",
   "metadata": {
    "papermill": {
     "duration": 0.01797,
     "end_time": "2023-02-16T22:12:58.258141",
     "exception": false,
     "start_time": "2023-02-16T22:12:58.240171",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "> Now let's \"tokenize\" these messages. Tokenization is just the term used to describe the process of converting the normal text strings in to a list of tokens (words that we actually want)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fbbe1033",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-16T22:12:58.296864Z",
     "iopub.status.busy": "2023-02-16T22:12:58.296465Z",
     "iopub.status.idle": "2023-02-16T22:12:59.382560Z",
     "shell.execute_reply": "2023-02-16T22:12:59.381284Z"
    },
    "papermill": {
     "duration": 1.109105,
     "end_time": "2023-02-16T22:12:59.385540",
     "exception": false,
     "start_time": "2023-02-16T22:12:58.276435",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "      <th>label_num</th>\n",
       "      <th>message_len</th>\n",
       "      <th>clean_msg</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>full_subpath</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>trec06p/data/000/001</th>\n",
       "      <td>spam</td>\n",
       "      <td>\\n                                 ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1404</td>\n",
       "      <td>LUXURY WATCHES BUY ROLEX 219 Rolex Cartier Bvl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trec06p/data/000/002</th>\n",
       "      <td>spam</td>\n",
       "      <td>Academic Qualifications available from prestig...</td>\n",
       "      <td>1</td>\n",
       "      <td>632</td>\n",
       "      <td>Academic Qualifications available prestigious ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trec06p/data/000/003</th>\n",
       "      <td>ham</td>\n",
       "      <td>Greetings all.  This is to verify your subscri...</td>\n",
       "      <td>0</td>\n",
       "      <td>861</td>\n",
       "      <td>Greetings verify subscription plan9fans list c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trec06p/data/000/004</th>\n",
       "      <td>spam</td>\n",
       "      <td>try chauncey may conferred the luscious not co...</td>\n",
       "      <td>1</td>\n",
       "      <td>909</td>\n",
       "      <td>try chauncey may conferred luscious continued ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trec06p/data/000/005</th>\n",
       "      <td>ham</td>\n",
       "      <td>It's quiet.  Too quiet.  Well, how about a str...</td>\n",
       "      <td>0</td>\n",
       "      <td>94</td>\n",
       "      <td>quiet quiet Well straw poll many plan9 running...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     label                                            message  \\\n",
       "full_subpath                                                                    \n",
       "trec06p/data/000/001  spam             \\n                                 ...   \n",
       "trec06p/data/000/002  spam  Academic Qualifications available from prestig...   \n",
       "trec06p/data/000/003   ham  Greetings all.  This is to verify your subscri...   \n",
       "trec06p/data/000/004  spam  try chauncey may conferred the luscious not co...   \n",
       "trec06p/data/000/005   ham  It's quiet.  Too quiet.  Well, how about a str...   \n",
       "\n",
       "                      label_num  message_len  \\\n",
       "full_subpath                                   \n",
       "trec06p/data/000/001          1         1404   \n",
       "trec06p/data/000/002          1          632   \n",
       "trec06p/data/000/003          0          861   \n",
       "trec06p/data/000/004          1          909   \n",
       "trec06p/data/000/005          0           94   \n",
       "\n",
       "                                                              clean_msg  \n",
       "full_subpath                                                             \n",
       "trec06p/data/000/001  LUXURY WATCHES BUY ROLEX 219 Rolex Cartier Bvl...  \n",
       "trec06p/data/000/002  Academic Qualifications available prestigious ...  \n",
       "trec06p/data/000/003  Greetings verify subscription plan9fans list c...  \n",
       "trec06p/data/000/004  try chauncey may conferred luscious continued ...  \n",
       "trec06p/data/000/005  quiet quiet Well straw poll many plan9 running...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['clean_msg'] = data.message.apply(text_process)\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "42288c44",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-16T22:12:59.425866Z",
     "iopub.status.busy": "2023-02-16T22:12:59.425420Z",
     "iopub.status.idle": "2023-02-16T22:12:59.433868Z",
     "shell.execute_reply": "2023-02-16T22:12:59.432927Z"
    },
    "papermill": {
     "duration": 0.03138,
     "end_time": "2023-02-16T22:12:59.435994",
     "exception": false,
     "start_time": "2023-02-16T22:12:59.404614",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ee82a1c5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-16T22:12:59.475459Z",
     "iopub.status.busy": "2023-02-16T22:12:59.474552Z",
     "iopub.status.idle": "2023-02-16T22:12:59.518143Z",
     "shell.execute_reply": "2023-02-16T22:12:59.516921Z"
    },
    "papermill": {
     "duration": 0.065866,
     "end_time": "2023-02-16T22:12:59.520478",
     "exception": false,
     "start_time": "2023-02-16T22:12:59.454612",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('would', 11217), ('one', 10590), ('1', 9768), ('use', 9579), ('id', 9096), ('list', 8441), ('received', 8388), ('subject', 8180), ('get', 8161), ('email', 7496), ('like', 7276), ('also', 7233), ('using', 7076), ('date', 6926), ('time', 6909), ('may', 6867), ('dmdx', 6750), ('new', 6567), ('file', 6536), ('message', 6450), ('0', 6151), ('wrote', 6113), ('information', 5919), ('university', 5727), ('could', 5639), ('know', 5564), ('nil', 5423), ('send', 5412), ('thanks', 5385), ('help', 5379), ('problem', 5201), ('board', 5191), ('please', 5141), ('10', 5129), ('2002', 5070), ('20', 5056), ('system', 5014), ('work', 5013), ('need', 4781), ('two', 4653), ('dmdxpsy1psycharizonaedu', 4652), ('mail', 4589), ('0700', 4565), ('see', 4494), ('used', 4405), ('3', 4347), ('available', 4343), ('first', 4329), ('way', 4216), ('make', 4166)]\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "words = data[data.label=='ham'].clean_msg.apply(lambda x: [word.lower() for word in x.split()])\n",
    "ham_words = Counter()\n",
    "\n",
    "for msg in words:\n",
    "    ham_words.update(msg)\n",
    "    \n",
    "print(ham_words.most_common(50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5051c011",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-16T22:12:59.560199Z",
     "iopub.status.busy": "2023-02-16T22:12:59.559752Z",
     "iopub.status.idle": "2023-02-16T22:12:59.578898Z",
     "shell.execute_reply": "2023-02-16T22:12:59.577584Z"
    },
    "papermill": {
     "duration": 0.042129,
     "end_time": "2023-02-16T22:12:59.581504",
     "exception": false,
     "start_time": "2023-02-16T22:12:59.539375",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('20', 5602), ('e', 3090), ('l', 2747), ('v', 2722), ('r', 2652), ('c', 2348), ('3', 2173), ('n', 2151), ('x', 1891), ('p', 1868), ('us', 1607), ('g', 1416), ('company', 1407), ('000', 1267), ('please', 1252), ('b', 1251), ('z', 1177), ('1', 1148), ('email', 1120), ('website', 1110), ('new', 1085), ('money', 1052), ('h', 1051), ('è', 1037), ('get', 1012), ('like', 988), ('one', 972), ('campaign', 955), ('f', 955), ('e8', 947), ('want', 942), ('ra', 938), ('td', 898), ('info', 882), ('gold', 881), ('hi', 872), ('8', 861), ('account', 836), ('best', 832), ('de', 819), ('product', 800), ('7', 799), ('time', 793), ('hoodia', 784), ('weight', 779), ('q', 777), ('may', 762), ('w', 761), ('also', 735), ('â', 713)]\n"
     ]
    }
   ],
   "source": [
    "words = data[data.label=='spam'].clean_msg.apply(lambda x: [word.lower() for word in x.split()])\n",
    "spam_words = Counter()\n",
    "\n",
    "for msg in words:\n",
    "    spam_words.update(msg)\n",
    "    \n",
    "print(spam_words.most_common(50))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11e90ea1",
   "metadata": {},
   "source": [
    "### 🗡️ Lemmatization (*Part of Speech is an option*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "34cce012",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "data['clean_msg'] = data['clean_msg'].apply(lambda x: ' '.join([WordNetLemmatizer().lemmatize(word) for word in x.split()]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f948a56c",
   "metadata": {
    "papermill": {
     "duration": 0.019118,
     "end_time": "2023-02-16T22:12:59.619536",
     "exception": false,
     "start_time": "2023-02-16T22:12:59.600418",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 🧮 Vectorization\n",
    "\n",
    "> Currently, we have the messages as lists of tokens (also known as [lemmas](http://nlp.stanford.edu/IR-book/html/htmledition/stemming-and-lemmatization-1.html)) and now we need to convert each of those messages into a vector the SciKit Learn's algorithm models can work with.\n",
    "\n",
    "> Now we'll convert each message, represented as a list of tokens (lemmas) above, into a vector that machine learning models can understand.\n",
    "\n",
    "> We'll do that in three steps using the bag-of-words model:\n",
    "\n",
    "> 1. Count how many times does a word occur in each message (Known as term frequency)\n",
    "> 2. Weigh the counts, so that frequent tokens get lower weight (inverse document frequency)\n",
    "> 3. Normalize the vectors to unit length, to abstract from the original text length (L2 norm)\n",
    "\n",
    "> Let's begin the first step:\n",
    "\n",
    "> Each vector will have as many dimensions as there are unique words in the data corpus.  We will first use SciKit Learn's **CountVectorizer**. This model will convert a collection of text documents to a matrix of token counts.\n",
    "\n",
    "> We can imagine this as a 2-Dimensional matrix. Where the 1-dimension is the entire vocabulary (1 row per word) and the other dimension are the actual documents, in this case a column per text message. \n",
    "\n",
    "> For example:\n",
    "\n",
    "<table border = “1“>\n",
    "<tr>\n",
    "<th></th> <th>Message 1</th> <th>Message 2</th> <th>...</th> <th>Message N</th> \n",
    "</tr>\n",
    "<tr>\n",
    "<td><b>Word 1 Count</b></td><td>0</td><td>1</td><td>...</td><td>0</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td><b>Word 2 Count</b></td><td>0</td><td>0</td><td>...</td><td>0</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td><b>...</b></td> <td>1</td><td>2</td><td>...</td><td>0</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td><b>Word N Count</b></td> <td>0</td><td>1</td><td>...</td><td>1</td>\n",
    "</tr>\n",
    "</table>\n",
    "\n",
    "\n",
    "> Since there are so many messages, we can expect a lot of zero counts for the presence of that word in that document. Because of this, SciKit Learn will output a [Sparse Matrix](https://en.wikipedia.org/wiki/Sparse_matrix)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "63b33667",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-16T22:12:59.658981Z",
     "iopub.status.busy": "2023-02-16T22:12:59.658525Z",
     "iopub.status.idle": "2023-02-16T22:12:59.670509Z",
     "shell.execute_reply": "2023-02-16T22:12:59.669471Z"
    },
    "papermill": {
     "duration": 0.03499,
     "end_time": "2023-02-16T22:12:59.673230",
     "exception": false,
     "start_time": "2023-02-16T22:12:59.638240",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17587,)\n",
      "(17587,)\n",
      "(13190,)\n",
      "(4397,)\n",
      "(13190,)\n",
      "(4397,)\n"
     ]
    }
   ],
   "source": [
    "# split X and y into training and testing sets \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# how to define X and y (from the data data) for use with COUNTVECTORIZER\n",
    "X = data.clean_msg\n",
    "y = data.label_num\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "950abac6",
   "metadata": {
    "papermill": {
     "duration": 0.018449,
     "end_time": "2023-02-16T22:12:59.710632",
     "exception": false,
     "start_time": "2023-02-16T22:12:59.692183",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "> There are a lot of arguments and parameters that can be passed to the CountVectorizer. In this case we will just specify the **analyzer** to be our own previously defined function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0cd9ed9e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-16T22:12:59.750917Z",
     "iopub.status.busy": "2023-02-16T22:12:59.750495Z",
     "iopub.status.idle": "2023-02-16T22:12:59.941257Z",
     "shell.execute_reply": "2023-02-16T22:12:59.939871Z"
    },
    "papermill": {
     "duration": 0.215048,
     "end_time": "2023-02-16T22:12:59.944594",
     "exception": false,
     "start_time": "2023-02-16T22:12:59.729546",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'scipy.sparse._csr.csr_matrix'> (13190, 241803)\n",
      "<class 'scipy.sparse._csr.csr_matrix'> (4397, 241803)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# instantiate the vectorizer\n",
    "vect = CountVectorizer()\n",
    "vect.fit(X_train)\n",
    "\n",
    "# learn training data vocabulary, then use it to create a document-term matrix\n",
    "X_train_dtm = vect.transform(X_train)\n",
    "\n",
    "# equivalently: combine fit and transform into a single step\n",
    "X_train_dtm = vect.fit_transform(X_train)\n",
    "\n",
    "\n",
    "# examine the document-term matrix\n",
    "print(type(X_train_dtm), X_train_dtm.shape)\n",
    "\n",
    "# transform testing data (using fitted vocabulary) into a document-term matrix\n",
    "X_test_dtm = vect.transform(X_test)\n",
    "print(type(X_test_dtm), X_test_dtm.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9fa1f75e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-16T22:12:59.985899Z",
     "iopub.status.busy": "2023-02-16T22:12:59.985498Z",
     "iopub.status.idle": "2023-02-16T22:13:00.001587Z",
     "shell.execute_reply": "2023-02-16T22:13:00.000185Z"
    },
    "papermill": {
     "duration": 0.039986,
     "end_time": "2023-02-16T22:13:00.004419",
     "exception": false,
     "start_time": "2023-02-16T22:12:59.964433",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<13190x241803 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 1318748 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "tfidf_transformer.fit(X_train_dtm)\n",
    "tfidf_transformer.transform(X_train_dtm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5889608f",
   "metadata": {
    "papermill": {
     "duration": 0.019406,
     "end_time": "2023-02-16T22:13:00.043116",
     "exception": false,
     "start_time": "2023-02-16T22:13:00.023710",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 🤖 Building and evaluating a model\n",
    "\n",
    "> We will use [multinomial Naive Bayes](http://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html):\n",
    "\n",
    "> The multinomial Naive Bayes classifier is suitable for classification with **discrete features** (e.g., word counts for text classification). The multinomial distribution normally requires integer feature counts. However, in practice, fractional counts such as tf-idf may also work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4c71b460",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-16T22:13:00.085470Z",
     "iopub.status.busy": "2023-02-16T22:13:00.084995Z",
     "iopub.status.idle": "2023-02-16T22:13:00.093021Z",
     "shell.execute_reply": "2023-02-16T22:13:00.091753Z"
    },
    "papermill": {
     "duration": 0.032552,
     "end_time": "2023-02-16T22:13:00.095683",
     "exception": false,
     "start_time": "2023-02-16T22:13:00.063131",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import and instantiate a Multinomial Naive Bayes model\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "nb = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "05a2e07d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-16T22:13:00.135604Z",
     "iopub.status.busy": "2023-02-16T22:13:00.135179Z",
     "iopub.status.idle": "2023-02-16T22:13:00.150227Z",
     "shell.execute_reply": "2023-02-16T22:13:00.148657Z"
    },
    "papermill": {
     "duration": 0.038182,
     "end_time": "2023-02-16T22:13:00.153134",
     "exception": false,
     "start_time": "2023-02-16T22:13:00.114952",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 15.6 ms\n",
      "Wall time: 22.4 ms\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultinomialNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train the model using X_train_dtm (timing it with an IPython \"magic command\")\n",
    "%time nb.fit(X_train_dtm, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "50e292d9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-16T22:13:00.193145Z",
     "iopub.status.busy": "2023-02-16T22:13:00.192721Z",
     "iopub.status.idle": "2023-02-16T22:13:00.205150Z",
     "shell.execute_reply": "2023-02-16T22:13:00.203829Z"
    },
    "papermill": {
     "duration": 0.035256,
     "end_time": "2023-02-16T22:13:00.207441",
     "exception": false,
     "start_time": "2023-02-16T22:13:00.172185",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======Accuracy Score===========\n",
      "0.9499658858312485\n",
      "=======Confision Matrix===========\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[3049,   20],\n",
       "       [ 200, 1128]], dtype=int64)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "# make class predictions for X_test_dtm\n",
    "y_pred_class = nb.predict(X_test_dtm)\n",
    "\n",
    "# calculate accuracy of class predictions\n",
    "print(\"=======Accuracy Score===========\")\n",
    "print(metrics.accuracy_score(y_test, y_pred_class))\n",
    "\n",
    "# print the confusion matrix\n",
    "print(\"=======Confision Matrix===========\")\n",
    "metrics.confusion_matrix(y_test, y_pred_class)\n",
    "\n",
    "# Multinomial Naive Bayes model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4fea51cb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-16T22:13:00.249659Z",
     "iopub.status.busy": "2023-02-16T22:13:00.249243Z",
     "iopub.status.idle": "2023-02-16T22:13:00.258808Z",
     "shell.execute_reply": "2023-02-16T22:13:00.257552Z"
    },
    "papermill": {
     "duration": 0.033557,
     "end_time": "2023-02-16T22:13:00.261184",
     "exception": false,
     "start_time": "2023-02-16T22:13:00.227627",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "full_subpath\n",
       "trec06p/data/116/065    RGVhciBpcmMtbGlzdC13ZWJAc2tpZG1vcmUuZWR1LCB0aG...\n",
       "trec06p/data/020/003    MIAGCSqGSIb3DQEHAqCAMIACAQExCzAJBgUrDgMCGgUAMI...\n",
       "trec06p/data/110/013    Dear val heard sweepstakes marykateandashleyco...\n",
       "trec06p/data/121/177    Hey Kellie Would mind sending one reminder Pro...\n",
       "trec06p/data/100/131    RGVhciBpcmMtbGlzdC13ZWJAc2tpZG1vcmUuZWR1LCB0aG...\n",
       "trec06p/data/104/040    nevoie sa fac procura pentru vanzarea unui apa...\n",
       "trec06p/data/054/048    SGkhDQoNCkhhcyBhbnlvbmUgaWRlYSBhYm91dCB0aGUgbW...\n",
       "trec06p/data/003/267    Hallo Da sind sie endlich die Skripte fuer den...\n",
       "trec06p/data/005/008    Appel darticles La place du football dans la v...\n",
       "trec06p/data/107/274    EstarE9 fuera de mi oficina hasta el 31 de oct...\n",
       "trec06p/data/030/186                        Happy Holidays Happy Holidays\n",
       "trec06p/data/108/127    RGVhciBpcmMtbGlzdC13ZWJAc2tpZG1vcmUuZWR1LCB0aG...\n",
       "trec06p/data/021/040    Nayant pa accE9s E0 un micro E9quipE9 dun lect...\n",
       "trec06p/data/085/138    DOCTYPE HTML PUBLIC W3CDTD HTML 40 Transitiona...\n",
       "trec06p/data/056/047    VIAGRA LINE Click http216342923viagra viagragu...\n",
       "trec06p/data/069/101    hola estoy muy interesada en saber como puedo ...\n",
       "trec06p/data/108/187    RGVhciBpcmMtbGlzdC13ZWJAc2tpZG1vcmUuZWR1LCB0aG...\n",
       "trec06p/data/114/067    RGVhciBpcmMtbGlzdC13ZWJAc2tpZG1vcmUuZWR1LCB0aG...\n",
       "trec06p/data/119/160    Hey Check great promotion get cool new iPod na...\n",
       "trec06p/data/048/018    SSd2ZSBpbnN0YWxsZWQgdHdvIDY1MDAgc29uYXIgbW9kdW...\n",
       "Name: clean_msg, dtype: object"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print message text for false positives (ham incorrectly classifier)\n",
    "# X_test[(y_pred_class==1) & (y_test==0)]\n",
    "X_test[y_pred_class > y_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9a6dc145",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-16T22:13:00.302077Z",
     "iopub.status.busy": "2023-02-16T22:13:00.301629Z",
     "iopub.status.idle": "2023-02-16T22:13:00.311296Z",
     "shell.execute_reply": "2023-02-16T22:13:00.310123Z"
    },
    "papermill": {
     "duration": 0.032884,
     "end_time": "2023-02-16T22:13:00.313745",
     "exception": false,
     "start_time": "2023-02-16T22:13:00.280861",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "full_subpath\n",
       "trec06p/data/005/025    Hi 20 V P C L V X r e b L v n z L G e R x n c ...\n",
       "trec06p/data/102/176    Make relaxed interesting forever Jane sharing ...\n",
       "trec06p/data/066/014    Hello contacting let know compact disc replica...\n",
       "trec06p/data/096/001    Morning eldy still trying please girl friend s...\n",
       "trec06p/data/121/038    Hail Erectile Dysfunction help site ochhorfand...\n",
       "                                              ...                        \n",
       "trec06p/data/036/056    精彩手机铃声图片免无限下载！ 每天都有互联网上最新的动感铃声，每天都有互联网上最新的原创图片...\n",
       "trec06p/data/027/202                                   width3D0 height3D0\n",
       "trec06p/data/081/275    3c21444f43545950452048544d4c205055424c49432022...\n",
       "trec06p/data/024/010    set modern resource http69xanthationinfo nwjh ...\n",
       "trec06p/data/000/221                                                     \n",
       "Name: clean_msg, Length: 200, dtype: object"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print message text for false negatives (spam incorrectly classifier)\n",
    "X_test[y_pred_class < y_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b16b84f8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-16T22:13:00.404882Z",
     "iopub.status.busy": "2023-02-16T22:13:00.404476Z",
     "iopub.status.idle": "2023-02-16T22:13:00.413380Z",
     "shell.execute_reply": "2023-02-16T22:13:00.412173Z"
    },
    "papermill": {
     "duration": 0.032687,
     "end_time": "2023-02-16T22:13:00.415619",
     "exception": false,
     "start_time": "2023-02-16T22:13:00.382932",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7.30272941e-001, 9.99882438e-001, 3.48925964e-148, ...,\n",
       "       1.00000000e+000, 1.00000000e+000, 2.31094517e-023])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate predicted probabilities for X_test_dtm (poorly calibrated)\n",
    "y_pred_prob = nb.predict_proba(X_test_dtm)[:, 1]\n",
    "y_pred_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f8b42534",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-16T22:13:00.457385Z",
     "iopub.status.busy": "2023-02-16T22:13:00.456955Z",
     "iopub.status.idle": "2023-02-16T22:13:00.468180Z",
     "shell.execute_reply": "2023-02-16T22:13:00.467056Z"
    },
    "papermill": {
     "duration": 0.035106,
     "end_time": "2023-02-16T22:13:00.470597",
     "exception": false,
     "start_time": "2023-02-16T22:13:00.435491",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC of multinomial naive bayes model is  0.9888\n"
     ]
    }
   ],
   "source": [
    "# calculate AUC\n",
    "AUC_NB = metrics.roc_auc_score(y_test, y_pred_prob)\n",
    "print(f'AUC of multinomial naive bayes model is {AUC_NB: .4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "76bac208",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-16T22:13:00.512698Z",
     "iopub.status.busy": "2023-02-16T22:13:00.512267Z",
     "iopub.status.idle": "2023-02-16T22:13:00.612825Z",
     "shell.execute_reply": "2023-02-16T22:13:00.611460Z"
    },
    "papermill": {
     "duration": 0.125448,
     "end_time": "2023-02-16T22:13:00.615922",
     "exception": false,
     "start_time": "2023-02-16T22:13:00.490474",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======Accuracy Score===========\n",
      "0.8908346599954514\n",
      "=======Confision Matrix===========\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[3063,    6],\n",
       "       [ 474,  854]], dtype=int64)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "pipe = Pipeline([('bow', CountVectorizer()), \n",
    "                 ('tfid', TfidfTransformer()),  \n",
    "                 ('model', MultinomialNB())])\n",
    "\n",
    "pipe.fit(X_train, y_train)\n",
    "y_pred = pipe.predict(X_test)\n",
    "\n",
    "# calculate accuracy of class predictions\n",
    "print(\"=======Accuracy Score===========\")\n",
    "print(metrics.accuracy_score(y_test, y_pred))\n",
    "\n",
    "# print the confusion matrix\n",
    "print(\"=======Confision Matrix===========\")\n",
    "metrics.confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# TfidfTransformer > MultinomialNB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e816488",
   "metadata": {
    "papermill": {
     "duration": 0.019578,
     "end_time": "2023-02-16T22:13:00.655711",
     "exception": false,
     "start_time": "2023-02-16T22:13:00.636133",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 📊 Comparing models\n",
    "\n",
    "We will compare multinomial Naive Bayes with [logistic regression](http://scikit-learn.org/stable/modules/linear_model.html#logistic-regression):\n",
    "\n",
    "> Logistic regression, despite its name, is a **linear model for classification** rather than regression. Logistic regression is also known in the literature as logit regression, maximum-entropy classification (MaxEnt) or the log-linear classifier. In this model, the probabilities describing the possible outcomes of a single trial are modeled using a logistic function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "87b874a9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-16T22:13:00.698211Z",
     "iopub.status.busy": "2023-02-16T22:13:00.697147Z",
     "iopub.status.idle": "2023-02-16T22:13:00.730363Z",
     "shell.execute_reply": "2023-02-16T22:13:00.728779Z"
    },
    "papermill": {
     "duration": 0.057407,
     "end_time": "2023-02-16T22:13:00.733054",
     "exception": false,
     "start_time": "2023-02-16T22:13:00.675647",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 5.62 s\n",
      "Wall time: 5.53 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(solver=&#x27;liblinear&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(solver=&#x27;liblinear&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(solver='liblinear')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import an instantiate a logistic regression model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logreg = LogisticRegression(solver='liblinear')\n",
    "\n",
    "# train the model using X_train_dtm\n",
    "%time logreg.fit(X_train_dtm, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "011c8184",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-16T22:13:00.776295Z",
     "iopub.status.busy": "2023-02-16T22:13:00.775220Z",
     "iopub.status.idle": "2023-02-16T22:13:00.784858Z",
     "shell.execute_reply": "2023-02-16T22:13:00.783801Z"
    },
    "papermill": {
     "duration": 0.033897,
     "end_time": "2023-02-16T22:13:00.787306",
     "exception": false,
     "start_time": "2023-02-16T22:13:00.753409",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7.71678409e-01, 9.27622192e-01, 3.88813203e-14, ...,\n",
       "       9.89836985e-01, 9.99636487e-01, 6.23313039e-05])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make class predictions for X_test_dtm\n",
    "y_pred_class = logreg.predict(X_test_dtm)\n",
    "\n",
    "# calculate predicted probabilities for X_test_dtm (well calibrated)\n",
    "y_pred_prob = logreg.predict_proba(X_test_dtm)[:, 1]\n",
    "y_pred_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6fac6a4e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-16T22:13:00.829556Z",
     "iopub.status.busy": "2023-02-16T22:13:00.829146Z",
     "iopub.status.idle": "2023-02-16T22:13:00.840379Z",
     "shell.execute_reply": "2023-02-16T22:13:00.839026Z"
    },
    "papermill": {
     "duration": 0.035907,
     "end_time": "2023-02-16T22:13:00.843610",
     "exception": false,
     "start_time": "2023-02-16T22:13:00.807703",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======Accuracy Score===========\n",
      "0.9770297930407096\n",
      "=======Confision Matrix===========\n",
      "[[3001   68]\n",
      " [  33 1295]]\n",
      "=======ROC AUC Score===========\n",
      "0.9933087678180953\n"
     ]
    }
   ],
   "source": [
    "# calculate accuracy of class predictions\n",
    "print(\"=======Accuracy Score===========\")\n",
    "print(metrics.accuracy_score(y_test, y_pred_class))\n",
    "\n",
    "# print the confusion matrix\n",
    "print(\"=======Confision Matrix===========\")\n",
    "print(metrics.confusion_matrix(y_test, y_pred_class))\n",
    "\n",
    "# calculate AUC\n",
    "print(\"=======ROC AUC Score===========\")\n",
    "print(metrics.roc_auc_score(y_test, y_pred_prob))\n",
    "\n",
    "\n",
    "# LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74afb562",
   "metadata": {},
   "source": [
    "We will compare multinomial Naive Bayes with [Random Forest](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html):\n",
    "\n",
    "> A random forest is a meta estimator that fits a number of decision tree classifiers on various sub-samples of the dataset and uses averaging to improve the predictive accuracy and control over-fitting. Trees in the forest use the best split strategy, i.e. equivalent to passing splitter=\"best\" to the underlying DecisionTreeRegressor. The sub-sample size is controlled with the max_samples parameter if bootstrap=True (default), otherwise the whole dataset is used to build each tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "4e99425f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 10.1 s\n",
      "Wall time: 10.2 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-13 {color: black;background-color: white;}#sk-container-id-13 pre{padding: 0;}#sk-container-id-13 div.sk-toggleable {background-color: white;}#sk-container-id-13 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-13 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-13 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-13 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-13 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-13 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-13 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-13 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-13 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-13 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-13 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-13 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-13 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-13 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-13 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-13 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-13 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-13 div.sk-item {position: relative;z-index: 1;}#sk-container-id-13 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-13 div.sk-item::before, #sk-container-id-13 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-13 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-13 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-13 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-13 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-13 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-13 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-13 div.sk-label-container {text-align: center;}#sk-container-id-13 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-13 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-13\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(max_depth=50, random_state=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" checked><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(max_depth=50, random_state=0)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(max_depth=50, random_state=0)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import an instantiate a Random Forest model\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf = RandomForestClassifier(max_depth=50, random_state=0)\n",
    "\n",
    "# train the model using X_train_dtm\n",
    "%time clf.fit(X_train_dtm, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "d45ab552",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.50368403, 0.49859137, 0.01444498, ..., 0.90190106, 0.91262423,\n",
       "       0.21587352])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make class predictions for X_test_dtm\n",
    "y_pred_class = clf.predict(X_test_dtm)\n",
    "\n",
    "# calculate predicted probabilities for X_test_dtm (well calibrated)\n",
    "y_pred_prob = clf.predict_proba(X_test_dtm)[:, 1]\n",
    "y_pred_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "cd0f0fd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======Accuracy Score===========\n",
      "0.9049351830793723\n",
      "=======Confision Matrix===========\n",
      "[[3066    3]\n",
      " [ 415  913]]\n",
      "=======ROC AUC Score===========\n",
      "0.9911492254452807\n"
     ]
    }
   ],
   "source": [
    "# calculate accuracy of class predictions\n",
    "print(\"=======Accuracy Score===========\")\n",
    "print(metrics.accuracy_score(y_test, y_pred_class))\n",
    "\n",
    "# print the confusion matrix\n",
    "print(\"=======Confision Matrix===========\")\n",
    "print(metrics.confusion_matrix(y_test, y_pred_class))\n",
    "\n",
    "# calculate AUC\n",
    "print(\"=======ROC AUC Score===========\")\n",
    "print(metrics.roc_auc_score(y_test, y_pred_prob))\n",
    "\n",
    "\n",
    "# Random Forest (note: requires a deep tree to yield at least 90% accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf7958d4",
   "metadata": {},
   "source": [
    "We will compare multinomial Naive Bayes with [XGBOOST](https://xgboost.readthedocs.io/en/stable/):\n",
    "\n",
    "> XGBoost is an optimized distributed gradient boosting library designed to be highly efficient, flexible and portable. It implements machine learning algorithms under the Gradient Boosting framework. XGBoost provides a parallel tree boosting (also known as GBDT, GBM) that solve many data science problems in a fast and accurate way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "c8867693",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 1min 10s\n",
      "Wall time: 10.6 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-14 {color: black;background-color: white;}#sk-container-id-14 pre{padding: 0;}#sk-container-id-14 div.sk-toggleable {background-color: white;}#sk-container-id-14 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-14 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-14 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-14 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-14 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-14 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-14 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-14 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-14 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-14 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-14 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-14 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-14 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-14 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-14 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-14 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-14 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-14 div.sk-item {position: relative;z-index: 1;}#sk-container-id-14 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-14 div.sk-item::before, #sk-container-id-14 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-14 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-14 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-14 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-14 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-14 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-14 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-14 div.sk-label-container {text-align: center;}#sk-container-id-14 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-14 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-14\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "              num_parallel_tree=None, random_state=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" checked><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "              num_parallel_tree=None, random_state=None, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "              num_parallel_tree=None, random_state=None, ...)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "xgb_clf = XGBClassifier()\n",
    "%time xgb_clf.fit(X_train_dtm, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "76e9fba0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7.9640204e-01, 8.7103349e-01, 2.8235695e-06, ..., 9.8145056e-01,\n",
       "       9.8253298e-01, 1.4098986e-03], dtype=float32)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make class predictions for X_test_dtm\n",
    "y_pred_class = xgb_clf.predict(X_test_dtm)\n",
    "\n",
    "# calculate predicted probabilities for X_test_dtm (well calibrated)\n",
    "y_pred_prob = xgb_clf.predict_proba(X_test_dtm)[:, 1]\n",
    "y_pred_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "8f7a8f4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======Accuracy Score===========\n",
      "0.9672503979986354\n",
      "=======Confision Matrix===========\n",
      "[[2968  101]\n",
      " [  43 1285]]\n",
      "=======ROC AUC Score===========\n",
      "0.9945783868612278\n"
     ]
    }
   ],
   "source": [
    "# calculate accuracy of class predictions\n",
    "print(\"=======Accuracy Score===========\")\n",
    "print(metrics.accuracy_score(y_test, y_pred_class))\n",
    "\n",
    "# print the confusion matrix\n",
    "print(\"=======Confision Matrix===========\")\n",
    "print(metrics.confusion_matrix(y_test, y_pred_class))\n",
    "\n",
    "# calculate AUC\n",
    "print(\"=======ROC AUC Score===========\")\n",
    "print(metrics.roc_auc_score(y_test, y_pred_prob))\n",
    "\n",
    "\n",
    "# XGBOOST"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7cf4e8e",
   "metadata": {
    "papermill": {
     "duration": 0.020193,
     "end_time": "2023-02-16T22:13:00.884989",
     "exception": false,
     "start_time": "2023-02-16T22:13:00.864796",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 🧮 Tuning the vectorizer\n",
    "\n",
    "Thus far, we have been using the default parameters of [CountVectorizer:](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "26b98148",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-16T22:13:00.928430Z",
     "iopub.status.busy": "2023-02-16T22:13:00.927251Z",
     "iopub.status.idle": "2023-02-16T22:13:00.934115Z",
     "shell.execute_reply": "2023-02-16T22:13:00.933070Z"
    },
    "papermill": {
     "duration": 0.030878,
     "end_time": "2023-02-16T22:13:00.936299",
     "exception": false,
     "start_time": "2023-02-16T22:13:00.905421",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>CountVectorizer()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CountVectorizer</label><div class=\"sk-toggleable__content\"><pre>CountVectorizer()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "CountVectorizer()"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show default parameters for CountVectorizer\n",
    "vect"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1846039e",
   "metadata": {
    "papermill": {
     "duration": 0.020052,
     "end_time": "2023-02-16T22:13:00.977351",
     "exception": false,
     "start_time": "2023-02-16T22:13:00.957299",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "> 📌 However, the vectorizer is worth tuning, just like a model is worth tuning! Here are a few parameters that you might want to tune:\n",
    "\n",
    "> - 📌 **stop_words**: string {'english'}, list, or None (default)\n",
    "    - If 'english', a built-in stop word list for English is used.\n",
    "    - If a list, that list is assumed to contain stop words, all of which will be removed from the resulting tokens.\n",
    "    - If None, no stop words will be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b04f6756",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-16T22:13:01.020403Z",
     "iopub.status.busy": "2023-02-16T22:13:01.019493Z",
     "iopub.status.idle": "2023-02-16T22:13:01.024973Z",
     "shell.execute_reply": "2023-02-16T22:13:01.023950Z"
    },
    "papermill": {
     "duration": 0.029514,
     "end_time": "2023-02-16T22:13:01.027353",
     "exception": false,
     "start_time": "2023-02-16T22:13:00.997839",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# remove English stop words\n",
    "vect = CountVectorizer(stop_words='english')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a809111d",
   "metadata": {
    "papermill": {
     "duration": 0.01982,
     "end_time": "2023-02-16T22:13:01.067613",
     "exception": false,
     "start_time": "2023-02-16T22:13:01.047793",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "> - 📌 **ngram_range**: tuple (min_n, max_n), default=(1, 1)\n",
    "    - The lower and upper boundary of the range of n-values for different n-grams to be extracted.\n",
    "    - All values of n such that min_n <= n <= max_n will be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ff6e54a3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-16T22:13:01.111619Z",
     "iopub.status.busy": "2023-02-16T22:13:01.110796Z",
     "iopub.status.idle": "2023-02-16T22:13:01.115922Z",
     "shell.execute_reply": "2023-02-16T22:13:01.114817Z"
    },
    "papermill": {
     "duration": 0.029745,
     "end_time": "2023-02-16T22:13:01.118561",
     "exception": false,
     "start_time": "2023-02-16T22:13:01.088816",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# include 1-grams and 2-grams\n",
    "vect = CountVectorizer(ngram_range=(1, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a479b0ad",
   "metadata": {
    "papermill": {
     "duration": 0.020159,
     "end_time": "2023-02-16T22:13:01.160046",
     "exception": false,
     "start_time": "2023-02-16T22:13:01.139887",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "> - 📌 **max_df**: float in range [0.0, 1.0] or int, default=1.0\n",
    "    - When building the vocabulary, ignore terms that have a document frequency strictly higher than the given threshold (corpus-specific stop words).\n",
    "    - If float, the parameter represents a proportion of documents.\n",
    "    - If integer, the parameter represents an absolute count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3019f77d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-16T22:13:01.207674Z",
     "iopub.status.busy": "2023-02-16T22:13:01.207277Z",
     "iopub.status.idle": "2023-02-16T22:13:01.212899Z",
     "shell.execute_reply": "2023-02-16T22:13:01.211494Z"
    },
    "papermill": {
     "duration": 0.034967,
     "end_time": "2023-02-16T22:13:01.215375",
     "exception": false,
     "start_time": "2023-02-16T22:13:01.180408",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ignore terms that appear in more than 50% of the documents\n",
    "vect = CountVectorizer(max_df=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e68ed232",
   "metadata": {
    "papermill": {
     "duration": 0.02384,
     "end_time": "2023-02-16T22:13:01.265302",
     "exception": false,
     "start_time": "2023-02-16T22:13:01.241462",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "> - 📌 **min_df**: float in range [0.0, 1.0] or int, default=1\n",
    "    - When building the vocabulary, ignore terms that have a document frequency strictly lower than the given threshold. (This value is also called \"cut-off\" in the literature.)\n",
    "    - If float, the parameter represents a proportion of documents.\n",
    "    - If integer, the parameter represents an absolute count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "696c0819",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-16T22:13:01.309510Z",
     "iopub.status.busy": "2023-02-16T22:13:01.308641Z",
     "iopub.status.idle": "2023-02-16T22:13:01.314591Z",
     "shell.execute_reply": "2023-02-16T22:13:01.313359Z"
    },
    "papermill": {
     "duration": 0.031092,
     "end_time": "2023-02-16T22:13:01.317580",
     "exception": false,
     "start_time": "2023-02-16T22:13:01.286488",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# only keep terms that appear in at least 2 documents\n",
    "vect = CountVectorizer(min_df=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d8df107",
   "metadata": {
    "papermill": {
     "duration": 0.020042,
     "end_time": "2023-02-16T22:13:01.358495",
     "exception": false,
     "start_time": "2023-02-16T22:13:01.338453",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "> - 📌 **Guidelines for tuning CountVectorizer**:\n",
    "    - Use your knowledge of the problem and the text, and your understanding of the tuning parameters, to help you decide what parameters to tune and how to tune them.\n",
    "    - Experiment, and let the data tell you the best approach!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 18.393171,
   "end_time": "2023-02-16T22:13:02.202180",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-02-16T22:12:43.809009",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
